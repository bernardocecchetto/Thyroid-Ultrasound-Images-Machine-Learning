{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import all libraries\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "#from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.python.keras.layers import Dropout, Input\n",
    "from tensorflow.python.keras.layers import MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, GlobalMaxPooling1D, GlobalMaxPooling3D\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import SpecificityAtSensitivity, SensitivityAtSpecificity, BinaryAccuracy, Accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam as Adam\n",
    "import json\n",
    "\n",
    "import keras.backend.tensorflow_backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESSAMENTO DE DADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Carrega dados do arquivo (pr√©-processados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>marks</th>\n",
       "      <th>tirads</th>\n",
       "      <th>malig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[93, 77, 70, 76, 79, 87, 98, 108, 117, 129, 1...</td>\n",
       "      <td>4a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[19, 30, 43, 54, 61, 57, 48, 40, 32, 25, 48, ...</td>\n",
       "      <td>4c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[52, 51, 33, 39, 58, 73, 65, 50, 56, 74, 53, ...</td>\n",
       "      <td>4b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[85, 109, 111, 99, 103, 109, 104, 99, 97, 86,...</td>\n",
       "      <td>4c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[[124, 119, 108, 101, 93, 105, 109, 110, 105, ...</td>\n",
       "      <td>4c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              marks tirads  malig\n",
       "0           0  [[93, 77, 70, 76, 79, 87, 98, 108, 117, 129, 1...     4a      1\n",
       "1           1  [[19, 30, 43, 54, 61, 57, 48, 40, 32, 25, 48, ...     4c      1\n",
       "2           2  [[52, 51, 33, 39, 58, 73, 65, 50, 56, 74, 53, ...     4b      1\n",
       "3           3  [[85, 109, 111, 99, 103, 109, 104, 99, 97, 86,...     4c      1\n",
       "4           4  [[124, 119, 108, 101, 93, 105, 109, 110, 105, ...     4c      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dados=pd.read_csv('df_dados_quadrado.csv')\n",
    "malig=np.ones(len(df_dados),dtype=int)\n",
    "malig[np.where(df_dados['tirads'].values=='2')]=0\n",
    "malig[np.where(df_dados['tirads'].values=='3')]=0\n",
    "df_dados['malig']=malig\n",
    "\n",
    "\n",
    "#for i in range(0,len(df_dados)):\n",
    "#    df_dados['marks'][i]=eval(df_dados['marks'][i])\n",
    "    \n",
    "df_dados.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_three=[]\n",
    "for i in range (452):\n",
    "        image = cv2.imread('C:/Users/Bernardo/TCC/recorte_quadrado/'+str(i)+'.png')\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        gray_three1 = (cv2.merge([gray,gray,gray]))\n",
    "        gray_three.append(gray_three1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 288, 432, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(gray_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\Bernardo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nimg=len(gray_three)\n",
    "nx=224 #np.shape(gray_three)[1] #dimens√£o x\n",
    "ny=224 #np.shape(gray_three)[2] #dimens√£o y\n",
    "\n",
    "X=np.zeros(((nimg,nx,ny,3)))\n",
    "for id_ in range (len(gray_three)):\n",
    "    x_img = gray_three[id_]\n",
    "    x_img = resize(x_img, (nx, ny,3), mode = 'constant', preserve_range = True)    \n",
    "    X[id_,:,:]=x_img/255\n",
    "\n",
    "#exemplo de imagem\n",
    "plt.imshow(X[0,:,:],cmap='Greys')\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df_dados['malig'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 casos benignos\n",
      "361 casos malignos\n",
      "452 CASOS TOTAIS\n"
     ]
    }
   ],
   "source": [
    "print(str(len(np.where(Y==0)[0])) + ' casos benignos')\n",
    "print(str(len(np.where(Y==1)[0])) + ' casos malignos')\n",
    "print(str(len(np.where(Y==1)[0])+len(np.where(Y==0)[0]))+' CASOS TOTAIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2)\n",
    "test_size = (X_valid.shape[0]/X_train.shape[0])\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5422535211267605"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights=class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6224137931034482"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False, input_shape=(nx,ny,3))\n",
    "base_model.trainable = False\n",
    "\n",
    "######################\n",
    "\n",
    "conf = json.loads(base_model.to_json())\n",
    "for l in conf['config']['layers']:\n",
    "    if l['class_name'] == 'BatchNormalization':\n",
    "        l['config']['momentum'] = 0.90\n",
    "        l['config']['trainable']= True\n",
    "\n",
    "m = base_model.from_config(conf['config'])\n",
    "for l in base_model.layers:\n",
    "    m.get_layer(l.name).set_weights(l.get_weights())\n",
    "\n",
    "base_model = m\n",
    "\n",
    "##################\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4)) #diminuir dropout (0.1 ou 0.2)\n",
    "model.add(Dense(100, activation='relu'))#',kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.1)\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))   #testar tangente hiperb√≥lico\n",
    "\n",
    "# ####################Compile model\n",
    "epochs = 100\n",
    "#learning_rate = 0.0001\n",
    "#decay_rate = learning_rate / epochs\n",
    "#adam = Adam(lr=learning_rate, decay=decay_rate)\n",
    "adam = Adam(lr=0.0001)\n",
    "\n",
    "\n",
    "#############################\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "tf.random.set_seed(2)\n",
    "#model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.7048 - accuracy: 0.60 - ETA: 1:02 - loss: 0.8258 - accuracy: 0.45 - ETA: 1:21 - loss: 0.9261 - accuracy: 0.50 - ETA: 1:27 - loss: 0.8732 - accuracy: 0.55 - ETA: 1:30 - loss: 0.7943 - accuracy: 0.56 - ETA: 1:31 - loss: 0.7812 - accuracy: 0.55 - ETA: 1:30 - loss: 0.8149 - accuracy: 0.54 - ETA: 1:28 - loss: 0.7875 - accuracy: 0.51 - ETA: 1:29 - loss: 0.8414 - accuracy: 0.52 - ETA: 1:27 - loss: 0.8926 - accuracy: 0.53 - ETA: 1:26 - loss: 0.8880 - accuracy: 0.50 - ETA: 1:25 - loss: 0.8930 - accuracy: 0.50 - ETA: 1:22 - loss: 0.9007 - accuracy: 0.50 - ETA: 1:21 - loss: 0.8673 - accuracy: 0.52 - ETA: 1:18 - loss: 0.9095 - accuracy: 0.52 - ETA: 1:16 - loss: 0.9133 - accuracy: 0.51 - ETA: 1:13 - loss: 0.9433 - accuracy: 0.52 - ETA: 1:09 - loss: 0.9385 - accuracy: 0.52 - ETA: 1:05 - loss: 0.9401 - accuracy: 0.52 - ETA: 1:01 - loss: 1.0386 - accuracy: 0.51 - ETA: 57s - loss: 1.0554 - accuracy: 0.5095 - ETA: 54s - loss: 1.0313 - accuracy: 0.509 - ETA: 50s - loss: 1.0127 - accuracy: 0.508 - ETA: 46s - loss: 1.0138 - accuracy: 0.504 - ETA: 42s - loss: 1.0057 - accuracy: 0.512 - ETA: 39s - loss: 1.0108 - accuracy: 0.507 - ETA: 35s - loss: 0.9985 - accuracy: 0.503 - ETA: 31s - loss: 0.9739 - accuracy: 0.510 - ETA: 28s - loss: 0.9702 - accuracy: 0.520 - ETA: 24s - loss: 0.9808 - accuracy: 0.513 - ETA: 21s - loss: 0.9839 - accuracy: 0.522 - ETA: 17s - loss: 0.9803 - accuracy: 0.518 - ETA: 13s - loss: 0.9872 - accuracy: 0.518 - ETA: 10s - loss: 0.9862 - accuracy: 0.526 - ETA: 6s - loss: 0.9769 - accuracy: 0.528 - ETA: 3s - loss: 0.9697 - accuracy: 0.53 - ETA: 0s - loss: 0.9719 - accuracy: 0.52 - 133s 4s/step - loss: 0.9719 - accuracy: 0.5291 - val_loss: 0.8666 - val_accuracy: 0.3407\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.0284 - accuracy: 0.60 - ETA: 57s - loss: 0.7632 - accuracy: 0.550 - ETA: 1:13 - loss: 0.7537 - accuracy: 0.60 - ETA: 1:20 - loss: 0.7748 - accuracy: 0.57 - ETA: 1:23 - loss: 1.0692 - accuracy: 0.50 - ETA: 1:23 - loss: 1.0317 - accuracy: 0.51 - ETA: 1:23 - loss: 1.2650 - accuracy: 0.48 - ETA: 1:22 - loss: 1.2873 - accuracy: 0.46 - ETA: 1:20 - loss: 1.3234 - accuracy: 0.47 - ETA: 1:18 - loss: 1.2803 - accuracy: 0.49 - ETA: 1:16 - loss: 1.2931 - accuracy: 0.48 - ETA: 1:14 - loss: 1.2732 - accuracy: 0.47 - ETA: 1:11 - loss: 1.2556 - accuracy: 0.49 - ETA: 1:09 - loss: 1.2354 - accuracy: 0.50 - ETA: 1:06 - loss: 1.2219 - accuracy: 0.49 - ETA: 1:03 - loss: 1.1933 - accuracy: 0.48 - ETA: 1:00 - loss: 1.1368 - accuracy: 0.51 - ETA: 58s - loss: 1.1017 - accuracy: 0.5222 - ETA: 55s - loss: 1.0968 - accuracy: 0.526 - ETA: 52s - loss: 1.0841 - accuracy: 0.525 - ETA: 49s - loss: 1.0596 - accuracy: 0.523 - ETA: 46s - loss: 1.0617 - accuracy: 0.527 - ETA: 43s - loss: 1.0416 - accuracy: 0.526 - ETA: 40s - loss: 1.0203 - accuracy: 0.525 - ETA: 37s - loss: 1.0229 - accuracy: 0.520 - ETA: 34s - loss: 1.0161 - accuracy: 0.515 - ETA: 31s - loss: 1.0099 - accuracy: 0.514 - ETA: 28s - loss: 0.9996 - accuracy: 0.517 - ETA: 25s - loss: 0.9798 - accuracy: 0.524 - ETA: 22s - loss: 0.9687 - accuracy: 0.520 - ETA: 18s - loss: 0.9539 - accuracy: 0.522 - ETA: 15s - loss: 0.9630 - accuracy: 0.521 - ETA: 12s - loss: 0.9507 - accuracy: 0.521 - ETA: 9s - loss: 0.9393 - accuracy: 0.529 - ETA: 6s - loss: 0.9461 - accuracy: 0.52 - ETA: 3s - loss: 0.9367 - accuracy: 0.52 - ETA: 0s - loss: 0.9353 - accuracy: 0.52 - 122s 3s/step - loss: 0.9353 - accuracy: 0.5235 - val_loss: 0.7816 - val_accuracy: 0.4725\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4764 - accuracy: 0.50 - ETA: 57s - loss: 1.0233 - accuracy: 0.400 - ETA: 1:14 - loss: 0.8998 - accuracy: 0.46 - ETA: 1:21 - loss: 0.8732 - accuracy: 0.50 - ETA: 1:24 - loss: 0.7923 - accuracy: 0.58 - ETA: 1:24 - loss: 0.8564 - accuracy: 0.58 - ETA: 1:24 - loss: 0.8018 - accuracy: 0.57 - ETA: 1:23 - loss: 0.7918 - accuracy: 0.56 - ETA: 1:21 - loss: 0.7747 - accuracy: 0.56 - ETA: 1:19 - loss: 0.8120 - accuracy: 0.56 - ETA: 1:17 - loss: 0.7995 - accuracy: 0.55 - ETA: 1:14 - loss: 0.7948 - accuracy: 0.55 - ETA: 1:12 - loss: 0.8434 - accuracy: 0.55 - ETA: 1:09 - loss: 0.8514 - accuracy: 0.55 - ETA: 1:07 - loss: 0.8369 - accuracy: 0.55 - ETA: 1:04 - loss: 0.8304 - accuracy: 0.56 - ETA: 1:01 - loss: 0.8489 - accuracy: 0.55 - ETA: 59s - loss: 0.8477 - accuracy: 0.5556 - ETA: 56s - loss: 0.8235 - accuracy: 0.563 - ETA: 53s - loss: 0.8097 - accuracy: 0.565 - ETA: 50s - loss: 0.8279 - accuracy: 0.561 - ETA: 47s - loss: 0.8451 - accuracy: 0.568 - ETA: 44s - loss: 0.8387 - accuracy: 0.560 - ETA: 41s - loss: 0.8289 - accuracy: 0.562 - ETA: 38s - loss: 0.8423 - accuracy: 0.568 - ETA: 35s - loss: 0.8537 - accuracy: 0.561 - ETA: 32s - loss: 0.8408 - accuracy: 0.566 - ETA: 29s - loss: 0.8517 - accuracy: 0.567 - ETA: 26s - loss: 0.8440 - accuracy: 0.569 - ETA: 22s - loss: 0.8312 - accuracy: 0.576 - ETA: 19s - loss: 0.8421 - accuracy: 0.567 - ETA: 16s - loss: 0.8302 - accuracy: 0.571 - ETA: 13s - loss: 0.8283 - accuracy: 0.572 - ETA: 9s - loss: 0.8239 - accuracy: 0.573 - ETA: 6s - loss: 0.8224 - accuracy: 0.57 - ETA: 3s - loss: 0.8292 - accuracy: 0.56 - ETA: 0s - loss: 0.8281 - accuracy: 0.57 - 126s 3s/step - loss: 0.8281 - accuracy: 0.5706 - val_loss: 0.6736 - val_accuracy: 0.5934\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.0932 - accuracy: 0.40 - ETA: 58s - loss: 0.8710 - accuracy: 0.550 - ETA: 1:15 - loss: 0.8244 - accuracy: 0.53 - ETA: 1:22 - loss: 0.8867 - accuracy: 0.52 - ETA: 1:24 - loss: 0.7817 - accuracy: 0.56 - ETA: 1:25 - loss: 0.8121 - accuracy: 0.56 - ETA: 1:25 - loss: 0.8123 - accuracy: 0.57 - ETA: 1:24 - loss: 0.7508 - accuracy: 0.62 - ETA: 1:22 - loss: 0.7400 - accuracy: 0.62 - ETA: 1:20 - loss: 0.7221 - accuracy: 0.61 - ETA: 1:18 - loss: 0.7314 - accuracy: 0.59 - ETA: 1:15 - loss: 0.7191 - accuracy: 0.59 - ETA: 1:13 - loss: 0.7126 - accuracy: 0.60 - ETA: 1:10 - loss: 0.7009 - accuracy: 0.60 - ETA: 1:08 - loss: 0.6974 - accuracy: 0.60 - ETA: 1:05 - loss: 0.7044 - accuracy: 0.60 - ETA: 1:02 - loss: 0.6947 - accuracy: 0.60 - ETA: 59s - loss: 0.7035 - accuracy: 0.6056 - ETA: 56s - loss: 0.7336 - accuracy: 0.600 - ETA: 53s - loss: 0.7279 - accuracy: 0.595 - ETA: 50s - loss: 0.7246 - accuracy: 0.595 - ETA: 47s - loss: 0.7160 - accuracy: 0.600 - ETA: 44s - loss: 0.7105 - accuracy: 0.600 - ETA: 41s - loss: 0.6913 - accuracy: 0.616 - ETA: 38s - loss: 0.6846 - accuracy: 0.616 - ETA: 35s - loss: 0.6764 - accuracy: 0.615 - ETA: 31s - loss: 0.6637 - accuracy: 0.625 - ETA: 28s - loss: 0.6579 - accuracy: 0.632 - ETA: 25s - loss: 0.6547 - accuracy: 0.631 - ETA: 22s - loss: 0.6735 - accuracy: 0.630 - ETA: 19s - loss: 0.6648 - accuracy: 0.632 - ETA: 16s - loss: 0.6957 - accuracy: 0.631 - ETA: 12s - loss: 0.7400 - accuracy: 0.624 - ETA: 9s - loss: 0.7300 - accuracy: 0.626 - ETA: 6s - loss: 0.7291 - accuracy: 0.62 - ETA: 3s - loss: 0.7216 - accuracy: 0.62 - ETA: 0s - loss: 0.7208 - accuracy: 0.62 - 123s 3s/step - loss: 0.7208 - accuracy: 0.6260 - val_loss: 0.7272 - val_accuracy: 0.5275\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.7221 - accuracy: 0.50 - ETA: 59s - loss: 0.6110 - accuracy: 0.600 - ETA: 1:14 - loss: 0.5976 - accuracy: 0.63 - ETA: 1:25 - loss: 0.6208 - accuracy: 0.67 - ETA: 1:29 - loss: 0.6355 - accuracy: 0.66 - ETA: 1:31 - loss: 0.6629 - accuracy: 0.63 - ETA: 1:30 - loss: 0.6520 - accuracy: 0.61 - ETA: 1:29 - loss: 0.6297 - accuracy: 0.61 - ETA: 1:27 - loss: 0.6290 - accuracy: 0.61 - ETA: 1:26 - loss: 0.6250 - accuracy: 0.63 - ETA: 1:25 - loss: 0.6101 - accuracy: 0.64 - ETA: 1:23 - loss: 0.6674 - accuracy: 0.65 - ETA: 1:21 - loss: 0.6574 - accuracy: 0.63 - ETA: 1:18 - loss: 0.6562 - accuracy: 0.63 - ETA: 1:15 - loss: 0.6517 - accuracy: 0.63 - ETA: 1:11 - loss: 0.6653 - accuracy: 0.62 - ETA: 1:08 - loss: 0.6529 - accuracy: 0.61 - ETA: 1:04 - loss: 0.6803 - accuracy: 0.61 - ETA: 1:01 - loss: 0.6955 - accuracy: 0.60 - ETA: 58s - loss: 0.6819 - accuracy: 0.6050 - ETA: 55s - loss: 0.6819 - accuracy: 0.604 - ETA: 51s - loss: 0.6707 - accuracy: 0.604 - ETA: 48s - loss: 0.6852 - accuracy: 0.608 - ETA: 45s - loss: 0.7020 - accuracy: 0.604 - ETA: 41s - loss: 0.7013 - accuracy: 0.600 - ETA: 38s - loss: 0.7307 - accuracy: 0.596 - ETA: 35s - loss: 0.7464 - accuracy: 0.592 - ETA: 32s - loss: 0.7366 - accuracy: 0.596 - ETA: 28s - loss: 0.7524 - accuracy: 0.596 - ETA: 25s - loss: 0.7454 - accuracy: 0.603 - ETA: 22s - loss: 0.7395 - accuracy: 0.603 - ETA: 18s - loss: 0.7338 - accuracy: 0.606 - ETA: 15s - loss: 0.7302 - accuracy: 0.606 - ETA: 11s - loss: 0.7155 - accuracy: 0.611 - ETA: 7s - loss: 0.7275 - accuracy: 0.608 - ETA: 4s - loss: 0.7193 - accuracy: 0.61 - ETA: 0s - loss: 0.7185 - accuracy: 0.61 - 157s 4s/step - loss: 0.7185 - accuracy: 0.6122 - val_loss: 0.7021 - val_accuracy: 0.5824\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4824 - accuracy: 0.70 - ETA: 1:47 - loss: 0.5058 - accuracy: 0.70 - ETA: 2:18 - loss: 0.6696 - accuracy: 0.63 - ETA: 2:30 - loss: 0.6228 - accuracy: 0.62 - ETA: 2:32 - loss: 0.8418 - accuracy: 0.66 - ETA: 2:32 - loss: 0.7850 - accuracy: 0.68 - ETA: 2:30 - loss: 0.8739 - accuracy: 0.65 - ETA: 2:27 - loss: 0.8228 - accuracy: 0.67 - ETA: 2:23 - loss: 0.7644 - accuracy: 0.70 - ETA: 2:21 - loss: 0.7528 - accuracy: 0.71 - ETA: 2:17 - loss: 0.7692 - accuracy: 0.68 - ETA: 2:12 - loss: 0.7738 - accuracy: 0.68 - ETA: 2:08 - loss: 0.7838 - accuracy: 0.67 - ETA: 2:03 - loss: 0.8461 - accuracy: 0.65 - ETA: 1:58 - loss: 0.8504 - accuracy: 0.63 - ETA: 1:53 - loss: 0.8425 - accuracy: 0.63 - ETA: 1:48 - loss: 0.8267 - accuracy: 0.63 - ETA: 1:42 - loss: 0.8105 - accuracy: 0.65 - ETA: 1:37 - loss: 0.7825 - accuracy: 0.66 - ETA: 1:31 - loss: 0.8066 - accuracy: 0.65 - ETA: 1:26 - loss: 0.7871 - accuracy: 0.65 - ETA: 1:21 - loss: 0.7821 - accuracy: 0.65 - ETA: 1:15 - loss: 0.7923 - accuracy: 0.65 - ETA: 1:10 - loss: 0.7906 - accuracy: 0.65 - ETA: 1:05 - loss: 0.7826 - accuracy: 0.65 - ETA: 59s - loss: 0.7843 - accuracy: 0.6462 - ETA: 54s - loss: 0.7772 - accuracy: 0.644 - ETA: 48s - loss: 0.7642 - accuracy: 0.646 - ETA: 42s - loss: 0.7607 - accuracy: 0.644 - ETA: 37s - loss: 0.7937 - accuracy: 0.640 - ETA: 32s - loss: 0.7915 - accuracy: 0.641 - ETA: 26s - loss: 0.7934 - accuracy: 0.637 - ETA: 21s - loss: 0.7849 - accuracy: 0.633 - ETA: 15s - loss: 0.7843 - accuracy: 0.623 - ETA: 10s - loss: 0.7788 - accuracy: 0.622 - ETA: 5s - loss: 0.7761 - accuracy: 0.616 - ETA: 0s - loss: 0.7751 - accuracy: 0.61 - 201s 5s/step - loss: 0.7751 - accuracy: 0.6177 - val_loss: 0.7051 - val_accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3368 - accuracy: 0.90 - ETA: 1:25 - loss: 0.5794 - accuracy: 0.90 - ETA: 1:50 - loss: 0.5781 - accuracy: 0.83 - ETA: 2:01 - loss: 0.5020 - accuracy: 0.80 - ETA: 2:06 - loss: 0.4944 - accuracy: 0.78 - ETA: 2:09 - loss: 0.5197 - accuracy: 0.73 - ETA: 2:09 - loss: 0.5771 - accuracy: 0.70 - ETA: 2:08 - loss: 0.6298 - accuracy: 0.70 - ETA: 2:04 - loss: 0.6979 - accuracy: 0.68 - ETA: 2:02 - loss: 0.7039 - accuracy: 0.66 - ETA: 1:59 - loss: 0.7085 - accuracy: 0.64 - ETA: 1:56 - loss: 0.7678 - accuracy: 0.63 - ETA: 1:52 - loss: 0.7694 - accuracy: 0.63 - ETA: 1:47 - loss: 0.7811 - accuracy: 0.61 - ETA: 1:43 - loss: 0.8076 - accuracy: 0.62 - ETA: 1:39 - loss: 0.7943 - accuracy: 0.61 - ETA: 1:35 - loss: 0.7731 - accuracy: 0.62 - ETA: 1:30 - loss: 0.7607 - accuracy: 0.61 - ETA: 1:26 - loss: 0.7539 - accuracy: 0.60 - ETA: 1:21 - loss: 0.7510 - accuracy: 0.61 - ETA: 1:16 - loss: 0.7472 - accuracy: 0.61 - ETA: 1:12 - loss: 0.7455 - accuracy: 0.60 - ETA: 1:07 - loss: 0.7676 - accuracy: 0.60 - ETA: 1:02 - loss: 0.7653 - accuracy: 0.60 - ETA: 57s - loss: 0.7646 - accuracy: 0.6040 - ETA: 53s - loss: 0.7850 - accuracy: 0.600 - ETA: 48s - loss: 0.7898 - accuracy: 0.596 - ETA: 43s - loss: 0.7805 - accuracy: 0.596 - ETA: 38s - loss: 0.8006 - accuracy: 0.586 - ETA: 33s - loss: 0.7955 - accuracy: 0.583 - ETA: 29s - loss: 0.7937 - accuracy: 0.590 - ETA: 24s - loss: 0.7816 - accuracy: 0.590 - ETA: 19s - loss: 0.7886 - accuracy: 0.590 - ETA: 14s - loss: 0.7801 - accuracy: 0.600 - ETA: 9s - loss: 0.7718 - accuracy: 0.597 - ETA: 4s - loss: 0.7926 - accuracy: 0.58 - ETA: 0s - loss: 0.7916 - accuracy: 0.59 - 185s 5s/step - loss: 0.7916 - accuracy: 0.5900 - val_loss: 0.7918 - val_accuracy: 0.5495\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.5494 - accuracy: 0.60 - ETA: 1:27 - loss: 0.7490 - accuracy: 0.55 - ETA: 1:53 - loss: 0.7308 - accuracy: 0.53 - ETA: 2:06 - loss: 0.7180 - accuracy: 0.55 - ETA: 2:10 - loss: 0.7805 - accuracy: 0.54 - ETA: 2:10 - loss: 0.7800 - accuracy: 0.58 - ETA: 2:09 - loss: 0.8522 - accuracy: 0.58 - ETA: 2:09 - loss: 0.8162 - accuracy: 0.57 - ETA: 2:06 - loss: 0.8001 - accuracy: 0.55 - ETA: 2:03 - loss: 0.7659 - accuracy: 0.58 - ETA: 1:59 - loss: 0.7796 - accuracy: 0.57 - ETA: 1:56 - loss: 0.7733 - accuracy: 0.57 - ETA: 1:51 - loss: 0.7549 - accuracy: 0.57 - ETA: 1:47 - loss: 0.7423 - accuracy: 0.58 - ETA: 1:43 - loss: 0.7235 - accuracy: 0.59 - ETA: 1:40 - loss: 0.7335 - accuracy: 0.59 - ETA: 1:36 - loss: 0.7167 - accuracy: 0.60 - ETA: 1:32 - loss: 0.7022 - accuracy: 0.60 - ETA: 1:28 - loss: 0.7052 - accuracy: 0.60 - ETA: 1:23 - loss: 0.7122 - accuracy: 0.60 - ETA: 1:19 - loss: 0.7009 - accuracy: 0.60 - ETA: 1:14 - loss: 0.6967 - accuracy: 0.60 - ETA: 1:09 - loss: 0.6844 - accuracy: 0.60 - ETA: 1:04 - loss: 0.6862 - accuracy: 0.60 - ETA: 59s - loss: 0.6928 - accuracy: 0.6120 - ETA: 54s - loss: 0.6962 - accuracy: 0.607 - ETA: 49s - loss: 0.7026 - accuracy: 0.611 - ETA: 44s - loss: 0.7030 - accuracy: 0.607 - ETA: 39s - loss: 0.7117 - accuracy: 0.610 - ETA: 34s - loss: 0.6978 - accuracy: 0.616 - ETA: 29s - loss: 0.7201 - accuracy: 0.612 - ETA: 24s - loss: 0.7431 - accuracy: 0.615 - ETA: 19s - loss: 0.7444 - accuracy: 0.621 - ETA: 14s - loss: 0.7548 - accuracy: 0.623 - ETA: 9s - loss: 0.7490 - accuracy: 0.625 - ETA: 4s - loss: 0.7715 - accuracy: 0.62 - ETA: 0s - loss: 0.7744 - accuracy: 0.62 - 190s 5s/step - loss: 0.7744 - accuracy: 0.6233 - val_loss: 0.7220 - val_accuracy: 0.5824\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.6716 - accuracy: 0.60 - ETA: 1:27 - loss: 0.6818 - accuracy: 0.60 - ETA: 1:53 - loss: 0.9100 - accuracy: 0.60 - ETA: 2:01 - loss: 0.8274 - accuracy: 0.55 - ETA: 2:05 - loss: 0.8446 - accuracy: 0.56 - ETA: 2:07 - loss: 0.9000 - accuracy: 0.56 - ETA: 2:07 - loss: 0.8661 - accuracy: 0.54 - ETA: 2:05 - loss: 0.8329 - accuracy: 0.56 - ETA: 2:03 - loss: 0.7909 - accuracy: 0.57 - ETA: 1:59 - loss: 0.7824 - accuracy: 0.60 - ETA: 1:56 - loss: 0.7524 - accuracy: 0.60 - ETA: 1:52 - loss: 0.8330 - accuracy: 0.60 - ETA: 1:49 - loss: 0.8599 - accuracy: 0.58 - ETA: 1:45 - loss: 0.8242 - accuracy: 0.58 - ETA: 1:41 - loss: 0.8527 - accuracy: 0.58 - ETA: 1:37 - loss: 0.8294 - accuracy: 0.58 - ETA: 1:32 - loss: 0.8016 - accuracy: 0.60 - ETA: 1:28 - loss: 0.7755 - accuracy: 0.60 - ETA: 1:24 - loss: 0.7896 - accuracy: 0.60 - ETA: 1:19 - loss: 0.7691 - accuracy: 0.62 - ETA: 1:15 - loss: 0.7574 - accuracy: 0.62 - ETA: 1:10 - loss: 0.7452 - accuracy: 0.63 - ETA: 1:06 - loss: 0.7488 - accuracy: 0.62 - ETA: 1:01 - loss: 0.7451 - accuracy: 0.62 - ETA: 56s - loss: 0.7393 - accuracy: 0.6240 - ETA: 52s - loss: 0.7476 - accuracy: 0.623 - ETA: 47s - loss: 0.7383 - accuracy: 0.618 - ETA: 42s - loss: 0.7329 - accuracy: 0.625 - ETA: 38s - loss: 0.7244 - accuracy: 0.631 - ETA: 33s - loss: 0.7178 - accuracy: 0.633 - ETA: 28s - loss: 0.7062 - accuracy: 0.641 - ETA: 23s - loss: 0.6976 - accuracy: 0.640 - ETA: 19s - loss: 0.6939 - accuracy: 0.639 - ETA: 14s - loss: 0.7105 - accuracy: 0.632 - ETA: 9s - loss: 0.6969 - accuracy: 0.640 - ETA: 4s - loss: 0.6917 - accuracy: 0.63 - ETA: 0s - loss: 0.6910 - accuracy: 0.63 - 184s 5s/step - loss: 0.6910 - accuracy: 0.6371 - val_loss: 0.7210 - val_accuracy: 0.6264\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.60 - ETA: 1:25 - loss: 0.5416 - accuracy: 0.55 - ETA: 1:51 - loss: 0.5687 - accuracy: 0.63 - ETA: 2:01 - loss: 0.5512 - accuracy: 0.62 - ETA: 2:06 - loss: 0.4901 - accuracy: 0.66 - ETA: 2:07 - loss: 0.5277 - accuracy: 0.65 - ETA: 2:07 - loss: 0.6257 - accuracy: 0.62 - ETA: 2:04 - loss: 0.7334 - accuracy: 0.62 - ETA: 2:02 - loss: 0.6897 - accuracy: 0.64 - ETA: 1:59 - loss: 0.6835 - accuracy: 0.64 - ETA: 1:56 - loss: 0.6764 - accuracy: 0.62 - ETA: 1:52 - loss: 0.6874 - accuracy: 0.62 - ETA: 1:49 - loss: 0.6644 - accuracy: 0.63 - ETA: 1:44 - loss: 0.6732 - accuracy: 0.62 - ETA: 1:40 - loss: 0.6656 - accuracy: 0.62 - ETA: 1:36 - loss: 0.6474 - accuracy: 0.63 - ETA: 1:32 - loss: 0.6317 - accuracy: 0.62 - ETA: 1:28 - loss: 0.6209 - accuracy: 0.63 - ETA: 1:23 - loss: 0.6175 - accuracy: 0.62 - ETA: 1:19 - loss: 0.6135 - accuracy: 0.62 - ETA: 1:15 - loss: 0.6095 - accuracy: 0.63 - ETA: 1:10 - loss: 0.6164 - accuracy: 0.63 - ETA: 1:05 - loss: 0.6394 - accuracy: 0.63 - ETA: 1:01 - loss: 0.6524 - accuracy: 0.62 - ETA: 56s - loss: 0.6516 - accuracy: 0.6280 - ETA: 52s - loss: 0.6338 - accuracy: 0.642 - ETA: 47s - loss: 0.6413 - accuracy: 0.640 - ETA: 42s - loss: 0.6332 - accuracy: 0.639 - ETA: 38s - loss: 0.6267 - accuracy: 0.644 - ETA: 33s - loss: 0.6442 - accuracy: 0.650 - ETA: 28s - loss: 0.6629 - accuracy: 0.648 - ETA: 23s - loss: 0.6792 - accuracy: 0.643 - ETA: 19s - loss: 0.6732 - accuracy: 0.645 - ETA: 14s - loss: 0.6869 - accuracy: 0.635 - ETA: 9s - loss: 0.6918 - accuracy: 0.637 - ETA: 4s - loss: 0.6864 - accuracy: 0.63 - ETA: 0s - loss: 0.6857 - accuracy: 0.63 - 182s 5s/step - loss: 0.6857 - accuracy: 0.6399 - val_loss: 0.7840 - val_accuracy: 0.5604\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.7713 - accuracy: 0.60 - ETA: 1:25 - loss: 0.7992 - accuracy: 0.60 - ETA: 1:50 - loss: 0.6766 - accuracy: 0.63 - ETA: 2:00 - loss: 0.8068 - accuracy: 0.65 - ETA: 2:05 - loss: 0.7483 - accuracy: 0.66 - ETA: 2:06 - loss: 0.7262 - accuracy: 0.68 - ETA: 2:05 - loss: 0.7223 - accuracy: 0.65 - ETA: 2:03 - loss: 0.6883 - accuracy: 0.66 - ETA: 2:01 - loss: 0.6825 - accuracy: 0.66 - ETA: 1:58 - loss: 0.6830 - accuracy: 0.64 - ETA: 1:55 - loss: 0.7205 - accuracy: 0.61 - ETA: 1:51 - loss: 0.7103 - accuracy: 0.61 - ETA: 1:47 - loss: 0.6933 - accuracy: 0.62 - ETA: 1:43 - loss: 0.6976 - accuracy: 0.64 - ETA: 1:39 - loss: 0.6805 - accuracy: 0.64 - ETA: 1:35 - loss: 0.6814 - accuracy: 0.63 - ETA: 1:31 - loss: 0.6715 - accuracy: 0.62 - ETA: 1:27 - loss: 0.6612 - accuracy: 0.62 - ETA: 1:23 - loss: 0.6593 - accuracy: 0.62 - ETA: 1:18 - loss: 0.6556 - accuracy: 0.61 - ETA: 1:14 - loss: 0.6584 - accuracy: 0.61 - ETA: 1:10 - loss: 0.6490 - accuracy: 0.61 - ETA: 1:05 - loss: 0.6518 - accuracy: 0.60 - ETA: 1:01 - loss: 0.6436 - accuracy: 0.62 - ETA: 56s - loss: 0.6698 - accuracy: 0.6200 - ETA: 52s - loss: 0.6716 - accuracy: 0.611 - ETA: 47s - loss: 0.6874 - accuracy: 0.611 - ETA: 43s - loss: 0.6871 - accuracy: 0.614 - ETA: 38s - loss: 0.6755 - accuracy: 0.620 - ETA: 33s - loss: 0.6798 - accuracy: 0.616 - ETA: 28s - loss: 0.6868 - accuracy: 0.619 - ETA: 24s - loss: 0.6748 - accuracy: 0.625 - ETA: 19s - loss: 0.6646 - accuracy: 0.627 - ETA: 14s - loss: 0.6721 - accuracy: 0.632 - ETA: 9s - loss: 0.6906 - accuracy: 0.631 - ETA: 4s - loss: 0.6836 - accuracy: 0.62 - ETA: 0s - loss: 0.6829 - accuracy: 0.62 - 184s 5s/step - loss: 0.6829 - accuracy: 0.6260 - val_loss: 0.7878 - val_accuracy: 0.5934\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4469 - accuracy: 0.70 - ETA: 1:25 - loss: 0.5495 - accuracy: 0.65 - ETA: 1:52 - loss: 0.5872 - accuracy: 0.70 - ETA: 2:02 - loss: 0.5355 - accuracy: 0.70 - ETA: 2:06 - loss: 0.6514 - accuracy: 0.62 - ETA: 2:08 - loss: 0.6807 - accuracy: 0.60 - ETA: 2:07 - loss: 0.6634 - accuracy: 0.61 - ETA: 2:06 - loss: 0.6295 - accuracy: 0.62 - ETA: 2:03 - loss: 0.6066 - accuracy: 0.63 - ETA: 2:00 - loss: 0.5876 - accuracy: 0.64 - ETA: 1:56 - loss: 0.5947 - accuracy: 0.63 - ETA: 1:53 - loss: 0.5898 - accuracy: 0.64 - ETA: 1:49 - loss: 0.5933 - accuracy: 0.63 - ETA: 1:46 - loss: 0.5688 - accuracy: 0.65 - ETA: 1:42 - loss: 0.5570 - accuracy: 0.66 - ETA: 1:38 - loss: 0.5439 - accuracy: 0.67 - ETA: 1:34 - loss: 0.5311 - accuracy: 0.68 - ETA: 1:29 - loss: 0.5193 - accuracy: 0.69 - ETA: 1:25 - loss: 0.5180 - accuracy: 0.69 - ETA: 1:20 - loss: 0.5132 - accuracy: 0.70 - ETA: 1:15 - loss: 0.5163 - accuracy: 0.69 - ETA: 1:11 - loss: 0.5131 - accuracy: 0.70 - ETA: 1:06 - loss: 0.5348 - accuracy: 0.70 - ETA: 1:01 - loss: 0.5323 - accuracy: 0.69 - ETA: 57s - loss: 0.5352 - accuracy: 0.6920 - ETA: 52s - loss: 0.5604 - accuracy: 0.692 - ETA: 47s - loss: 0.6017 - accuracy: 0.688 - ETA: 43s - loss: 0.5971 - accuracy: 0.685 - ETA: 38s - loss: 0.5875 - accuracy: 0.689 - ETA: 33s - loss: 0.5784 - accuracy: 0.696 - ETA: 28s - loss: 0.5725 - accuracy: 0.700 - ETA: 24s - loss: 0.5671 - accuracy: 0.703 - ETA: 19s - loss: 0.5733 - accuracy: 0.703 - ETA: 14s - loss: 0.5697 - accuracy: 0.697 - ETA: 9s - loss: 0.5807 - accuracy: 0.694 - ETA: 4s - loss: 0.5745 - accuracy: 0.69 - ETA: 0s - loss: 0.5741 - accuracy: 0.69 - 184s 5s/step - loss: 0.5741 - accuracy: 0.6981 - val_loss: 0.8296 - val_accuracy: 0.5824\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3451 - accuracy: 0.70 - ETA: 1:29 - loss: 0.5154 - accuracy: 0.65 - ETA: 1:52 - loss: 0.4987 - accuracy: 0.70 - ETA: 2:02 - loss: 0.4705 - accuracy: 0.72 - ETA: 2:06 - loss: 0.5853 - accuracy: 0.64 - ETA: 2:06 - loss: 0.6680 - accuracy: 0.63 - ETA: 2:06 - loss: 0.6566 - accuracy: 0.62 - ETA: 2:05 - loss: 0.6498 - accuracy: 0.62 - ETA: 2:05 - loss: 0.6488 - accuracy: 0.63 - ETA: 2:03 - loss: 0.6467 - accuracy: 0.64 - ETA: 2:00 - loss: 0.6385 - accuracy: 0.64 - ETA: 1:57 - loss: 0.6681 - accuracy: 0.62 - ETA: 1:53 - loss: 0.6654 - accuracy: 0.61 - ETA: 1:50 - loss: 0.6619 - accuracy: 0.61 - ETA: 1:46 - loss: 0.6898 - accuracy: 0.60 - ETA: 1:41 - loss: 0.6776 - accuracy: 0.60 - ETA: 1:37 - loss: 0.6591 - accuracy: 0.61 - ETA: 1:32 - loss: 0.6860 - accuracy: 0.61 - ETA: 1:28 - loss: 0.6877 - accuracy: 0.61 - ETA: 1:23 - loss: 0.6750 - accuracy: 0.61 - ETA: 1:18 - loss: 0.6650 - accuracy: 0.61 - ETA: 1:13 - loss: 0.6603 - accuracy: 0.61 - ETA: 1:08 - loss: 0.6455 - accuracy: 0.61 - ETA: 1:03 - loss: 0.6305 - accuracy: 0.62 - ETA: 59s - loss: 0.6230 - accuracy: 0.6240 - ETA: 54s - loss: 0.6138 - accuracy: 0.623 - ETA: 49s - loss: 0.6211 - accuracy: 0.622 - ETA: 44s - loss: 0.6513 - accuracy: 0.621 - ETA: 39s - loss: 0.6409 - accuracy: 0.617 - ETA: 34s - loss: 0.6490 - accuracy: 0.616 - ETA: 29s - loss: 0.6359 - accuracy: 0.625 - ETA: 24s - loss: 0.6534 - accuracy: 0.621 - ETA: 19s - loss: 0.6493 - accuracy: 0.621 - ETA: 14s - loss: 0.6467 - accuracy: 0.620 - ETA: 9s - loss: 0.6432 - accuracy: 0.625 - ETA: 4s - loss: 0.6369 - accuracy: 0.62 - ETA: 0s - loss: 0.6401 - accuracy: 0.62 - 188s 5s/step - loss: 0.6401 - accuracy: 0.6260 - val_loss: 0.7952 - val_accuracy: 0.5934\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3036 - accuracy: 0.60 - ETA: 1:31 - loss: 0.3283 - accuracy: 0.65 - ETA: 1:56 - loss: 0.4708 - accuracy: 0.63 - ETA: 2:04 - loss: 0.5854 - accuracy: 0.60 - ETA: 2:09 - loss: 0.5103 - accuracy: 0.68 - ETA: 2:10 - loss: 0.5808 - accuracy: 0.65 - ETA: 2:09 - loss: 0.6514 - accuracy: 0.61 - ETA: 2:06 - loss: 0.6113 - accuracy: 0.61 - ETA: 2:04 - loss: 0.6623 - accuracy: 0.60 - ETA: 2:01 - loss: 0.6817 - accuracy: 0.59 - ETA: 1:57 - loss: 0.6963 - accuracy: 0.57 - ETA: 1:54 - loss: 0.6719 - accuracy: 0.58 - ETA: 1:50 - loss: 0.6510 - accuracy: 0.60 - ETA: 1:46 - loss: 0.6791 - accuracy: 0.58 - ETA: 1:42 - loss: 0.6552 - accuracy: 0.58 - ETA: 1:38 - loss: 0.6804 - accuracy: 0.58 - ETA: 1:34 - loss: 0.6552 - accuracy: 0.60 - ETA: 1:29 - loss: 0.6439 - accuracy: 0.61 - ETA: 1:25 - loss: 0.6293 - accuracy: 0.63 - ETA: 1:20 - loss: 0.6202 - accuracy: 0.64 - ETA: 1:15 - loss: 0.6259 - accuracy: 0.63 - ETA: 1:11 - loss: 0.6197 - accuracy: 0.64 - ETA: 1:06 - loss: 0.6200 - accuracy: 0.64 - ETA: 1:02 - loss: 0.6176 - accuracy: 0.64 - ETA: 57s - loss: 0.6090 - accuracy: 0.6560 - ETA: 52s - loss: 0.6030 - accuracy: 0.661 - ETA: 48s - loss: 0.6046 - accuracy: 0.666 - ETA: 43s - loss: 0.5918 - accuracy: 0.671 - ETA: 39s - loss: 0.5846 - accuracy: 0.672 - ETA: 34s - loss: 0.5771 - accuracy: 0.673 - ETA: 29s - loss: 0.5746 - accuracy: 0.674 - ETA: 24s - loss: 0.5735 - accuracy: 0.678 - ETA: 19s - loss: 0.5793 - accuracy: 0.675 - ETA: 14s - loss: 0.5715 - accuracy: 0.679 - ETA: 9s - loss: 0.5759 - accuracy: 0.671 - ETA: 4s - loss: 0.5855 - accuracy: 0.66 - ETA: 0s - loss: 0.5851 - accuracy: 0.66 - 189s 5s/step - loss: 0.5851 - accuracy: 0.6676 - val_loss: 0.8412 - val_accuracy: 0.5604\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3580 - accuracy: 0.80 - ETA: 1:27 - loss: 0.4850 - accuracy: 0.60 - ETA: 1:52 - loss: 0.6021 - accuracy: 0.63 - ETA: 2:01 - loss: 0.5533 - accuracy: 0.60 - ETA: 2:06 - loss: 0.6376 - accuracy: 0.60 - ETA: 2:07 - loss: 0.6483 - accuracy: 0.63 - ETA: 2:06 - loss: 0.6376 - accuracy: 0.64 - ETA: 2:05 - loss: 0.5934 - accuracy: 0.66 - ETA: 2:02 - loss: 0.5752 - accuracy: 0.65 - ETA: 1:59 - loss: 0.5773 - accuracy: 0.67 - ETA: 1:57 - loss: 0.5702 - accuracy: 0.64 - ETA: 1:53 - loss: 0.5558 - accuracy: 0.65 - ETA: 1:49 - loss: 0.5832 - accuracy: 0.63 - ETA: 1:45 - loss: 0.5862 - accuracy: 0.64 - ETA: 1:42 - loss: 0.6240 - accuracy: 0.64 - ETA: 1:39 - loss: 0.6381 - accuracy: 0.65 - ETA: 1:34 - loss: 0.6457 - accuracy: 0.65 - ETA: 1:30 - loss: 0.6295 - accuracy: 0.65 - ETA: 1:24 - loss: 0.6171 - accuracy: 0.66 - ETA: 1:20 - loss: 0.6126 - accuracy: 0.65 - ETA: 1:14 - loss: 0.5919 - accuracy: 0.67 - ETA: 1:09 - loss: 0.6002 - accuracy: 0.67 - ETA: 1:04 - loss: 0.6030 - accuracy: 0.67 - ETA: 59s - loss: 0.6158 - accuracy: 0.6708 - ETA: 54s - loss: 0.6104 - accuracy: 0.676 - ETA: 49s - loss: 0.6126 - accuracy: 0.676 - ETA: 44s - loss: 0.6010 - accuracy: 0.685 - ETA: 39s - loss: 0.6016 - accuracy: 0.678 - ETA: 35s - loss: 0.5914 - accuracy: 0.679 - ETA: 30s - loss: 0.5780 - accuracy: 0.690 - ETA: 26s - loss: 0.5767 - accuracy: 0.693 - ETA: 21s - loss: 0.5780 - accuracy: 0.693 - ETA: 17s - loss: 0.5751 - accuracy: 0.697 - ETA: 12s - loss: 0.5806 - accuracy: 0.694 - ETA: 8s - loss: 0.5736 - accuracy: 0.697 - ETA: 4s - loss: 0.5742 - accuracy: 0.69 - ETA: 0s - loss: 0.5738 - accuracy: 0.69 - 161s 4s/step - loss: 0.5738 - accuracy: 0.6953 - val_loss: 0.7368 - val_accuracy: 0.5934\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.80 - ETA: 1:03 - loss: 0.4586 - accuracy: 0.70 - ETA: 1:22 - loss: 0.4600 - accuracy: 0.73 - ETA: 1:30 - loss: 0.4641 - accuracy: 0.75 - ETA: 1:33 - loss: 0.4830 - accuracy: 0.72 - ETA: 1:34 - loss: 0.5174 - accuracy: 0.70 - ETA: 1:34 - loss: 0.4987 - accuracy: 0.68 - ETA: 1:32 - loss: 0.5777 - accuracy: 0.67 - ETA: 1:30 - loss: 0.5718 - accuracy: 0.66 - ETA: 1:29 - loss: 0.5600 - accuracy: 0.66 - ETA: 1:27 - loss: 0.5797 - accuracy: 0.64 - ETA: 1:24 - loss: 0.5729 - accuracy: 0.62 - ETA: 1:21 - loss: 0.5847 - accuracy: 0.62 - ETA: 1:18 - loss: 0.5691 - accuracy: 0.63 - ETA: 1:15 - loss: 0.5733 - accuracy: 0.64 - ETA: 1:12 - loss: 0.5678 - accuracy: 0.65 - ETA: 1:09 - loss: 0.5595 - accuracy: 0.65 - ETA: 1:06 - loss: 0.6071 - accuracy: 0.65 - ETA: 1:02 - loss: 0.6008 - accuracy: 0.65 - ETA: 59s - loss: 0.6073 - accuracy: 0.6600 - ETA: 56s - loss: 0.5908 - accuracy: 0.661 - ETA: 52s - loss: 0.5860 - accuracy: 0.663 - ETA: 49s - loss: 0.5867 - accuracy: 0.665 - ETA: 46s - loss: 0.5717 - accuracy: 0.679 - ETA: 42s - loss: 0.5669 - accuracy: 0.688 - ETA: 39s - loss: 0.5615 - accuracy: 0.688 - ETA: 35s - loss: 0.5540 - accuracy: 0.692 - ETA: 32s - loss: 0.5507 - accuracy: 0.689 - ETA: 28s - loss: 0.5500 - accuracy: 0.689 - ETA: 25s - loss: 0.5437 - accuracy: 0.693 - ETA: 21s - loss: 0.5333 - accuracy: 0.700 - ETA: 18s - loss: 0.5486 - accuracy: 0.700 - ETA: 14s - loss: 0.5462 - accuracy: 0.703 - ETA: 10s - loss: 0.5363 - accuracy: 0.708 - ETA: 7s - loss: 0.5358 - accuracy: 0.708 - ETA: 3s - loss: 0.5474 - accuracy: 0.70 - ETA: 0s - loss: 0.5470 - accuracy: 0.70 - 139s 4s/step - loss: 0.5470 - accuracy: 0.7064 - val_loss: 0.7211 - val_accuracy: 0.6264\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.5733 - accuracy: 0.70 - ETA: 1:01 - loss: 0.5781 - accuracy: 0.70 - ETA: 1:19 - loss: 0.4870 - accuracy: 0.76 - ETA: 1:26 - loss: 0.5161 - accuracy: 0.75 - ETA: 1:29 - loss: 0.5228 - accuracy: 0.72 - ETA: 1:29 - loss: 0.4983 - accuracy: 0.71 - ETA: 1:28 - loss: 0.4976 - accuracy: 0.72 - ETA: 1:27 - loss: 0.4821 - accuracy: 0.72 - ETA: 1:25 - loss: 0.4488 - accuracy: 0.74 - ETA: 1:23 - loss: 0.4640 - accuracy: 0.74 - ETA: 1:20 - loss: 0.4622 - accuracy: 0.72 - ETA: 1:18 - loss: 0.4600 - accuracy: 0.75 - ETA: 1:16 - loss: 0.4829 - accuracy: 0.73 - ETA: 1:13 - loss: 0.4822 - accuracy: 0.73 - ETA: 1:10 - loss: 0.5297 - accuracy: 0.72 - ETA: 1:07 - loss: 0.5283 - accuracy: 0.71 - ETA: 1:04 - loss: 0.5680 - accuracy: 0.71 - ETA: 1:01 - loss: 0.5925 - accuracy: 0.70 - ETA: 58s - loss: 0.5837 - accuracy: 0.7000 - ETA: 55s - loss: 0.5787 - accuracy: 0.710 - ETA: 52s - loss: 0.5676 - accuracy: 0.714 - ETA: 49s - loss: 0.5702 - accuracy: 0.704 - ETA: 45s - loss: 0.6081 - accuracy: 0.704 - ETA: 42s - loss: 0.5959 - accuracy: 0.704 - ETA: 39s - loss: 0.6164 - accuracy: 0.704 - ETA: 36s - loss: 0.5997 - accuracy: 0.715 - ETA: 33s - loss: 0.5943 - accuracy: 0.711 - ETA: 29s - loss: 0.5962 - accuracy: 0.703 - ETA: 26s - loss: 0.5857 - accuracy: 0.706 - ETA: 23s - loss: 0.5845 - accuracy: 0.710 - ETA: 20s - loss: 0.5832 - accuracy: 0.716 - ETA: 16s - loss: 0.5898 - accuracy: 0.709 - ETA: 13s - loss: 0.5850 - accuracy: 0.706 - ETA: 10s - loss: 0.5787 - accuracy: 0.702 - ETA: 6s - loss: 0.5703 - accuracy: 0.702 - ETA: 3s - loss: 0.5687 - accuracy: 0.70 - ETA: 0s - loss: 0.5722 - accuracy: 0.70 - 128s 3s/step - loss: 0.5722 - accuracy: 0.7036 - val_loss: 0.7403 - val_accuracy: 0.5934\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.8124 - accuracy: 0.80 - ETA: 57s - loss: 0.5863 - accuracy: 0.700 - ETA: 1:15 - loss: 0.5028 - accuracy: 0.66 - ETA: 1:22 - loss: 0.6517 - accuracy: 0.65 - ETA: 1:25 - loss: 0.6279 - accuracy: 0.68 - ETA: 1:25 - loss: 0.6287 - accuracy: 0.66 - ETA: 1:25 - loss: 0.6006 - accuracy: 0.64 - ETA: 1:24 - loss: 0.6633 - accuracy: 0.65 - ETA: 1:22 - loss: 0.6367 - accuracy: 0.65 - ETA: 1:20 - loss: 0.6419 - accuracy: 0.66 - ETA: 1:18 - loss: 0.6303 - accuracy: 0.67 - ETA: 1:16 - loss: 0.6340 - accuracy: 0.65 - ETA: 1:13 - loss: 0.6036 - accuracy: 0.67 - ETA: 1:11 - loss: 0.6101 - accuracy: 0.67 - ETA: 1:08 - loss: 0.5929 - accuracy: 0.68 - ETA: 1:05 - loss: 0.5754 - accuracy: 0.68 - ETA: 1:03 - loss: 0.5975 - accuracy: 0.68 - ETA: 1:00 - loss: 0.5770 - accuracy: 0.69 - ETA: 57s - loss: 0.5644 - accuracy: 0.7000 - ETA: 54s - loss: 0.5730 - accuracy: 0.690 - ETA: 51s - loss: 0.5995 - accuracy: 0.671 - ETA: 47s - loss: 0.5870 - accuracy: 0.681 - ETA: 44s - loss: 0.5740 - accuracy: 0.691 - ETA: 41s - loss: 0.5722 - accuracy: 0.691 - ETA: 38s - loss: 0.5664 - accuracy: 0.696 - ETA: 35s - loss: 0.5714 - accuracy: 0.696 - ETA: 32s - loss: 0.5742 - accuracy: 0.700 - ETA: 29s - loss: 0.5688 - accuracy: 0.696 - ETA: 26s - loss: 0.5656 - accuracy: 0.700 - ETA: 22s - loss: 0.5596 - accuracy: 0.706 - ETA: 19s - loss: 0.5612 - accuracy: 0.700 - ETA: 16s - loss: 0.5500 - accuracy: 0.709 - ETA: 13s - loss: 0.5484 - accuracy: 0.712 - ETA: 10s - loss: 0.5605 - accuracy: 0.708 - ETA: 6s - loss: 0.5578 - accuracy: 0.708 - ETA: 3s - loss: 0.5457 - accuracy: 0.71 - ETA: 0s - loss: 0.5491 - accuracy: 0.71 - 129s 3s/step - loss: 0.5491 - accuracy: 0.7147 - val_loss: 0.6847 - val_accuracy: 0.6703\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.70 - ETA: 58s - loss: 0.3990 - accuracy: 0.700 - ETA: 1:15 - loss: 0.3958 - accuracy: 0.73 - ETA: 1:22 - loss: 0.4304 - accuracy: 0.75 - ETA: 1:25 - loss: 0.3981 - accuracy: 0.80 - ETA: 1:26 - loss: 0.4268 - accuracy: 0.78 - ETA: 1:25 - loss: 0.4257 - accuracy: 0.74 - ETA: 1:24 - loss: 0.4235 - accuracy: 0.73 - ETA: 1:22 - loss: 0.4428 - accuracy: 0.73 - ETA: 1:20 - loss: 0.4314 - accuracy: 0.73 - ETA: 1:18 - loss: 0.4242 - accuracy: 0.71 - ETA: 1:16 - loss: 0.4675 - accuracy: 0.70 - ETA: 1:13 - loss: 0.4992 - accuracy: 0.71 - ETA: 1:11 - loss: 0.5024 - accuracy: 0.71 - ETA: 1:08 - loss: 0.4969 - accuracy: 0.71 - ETA: 1:05 - loss: 0.5113 - accuracy: 0.71 - ETA: 1:02 - loss: 0.5227 - accuracy: 0.71 - ETA: 59s - loss: 0.5504 - accuracy: 0.7111 - ETA: 56s - loss: 0.5432 - accuracy: 0.710 - ETA: 53s - loss: 0.5400 - accuracy: 0.710 - ETA: 50s - loss: 0.5379 - accuracy: 0.714 - ETA: 47s - loss: 0.5415 - accuracy: 0.700 - ETA: 44s - loss: 0.5449 - accuracy: 0.700 - ETA: 41s - loss: 0.5446 - accuracy: 0.687 - ETA: 38s - loss: 0.5406 - accuracy: 0.692 - ETA: 35s - loss: 0.5318 - accuracy: 0.696 - ETA: 32s - loss: 0.5420 - accuracy: 0.700 - ETA: 29s - loss: 0.5328 - accuracy: 0.707 - ETA: 25s - loss: 0.5263 - accuracy: 0.706 - ETA: 22s - loss: 0.5207 - accuracy: 0.713 - ETA: 19s - loss: 0.5262 - accuracy: 0.706 - ETA: 16s - loss: 0.5226 - accuracy: 0.709 - ETA: 13s - loss: 0.5355 - accuracy: 0.709 - ETA: 9s - loss: 0.5292 - accuracy: 0.708 - ETA: 6s - loss: 0.5235 - accuracy: 0.71 - ETA: 3s - loss: 0.5292 - accuracy: 0.70 - ETA: 0s - loss: 0.5289 - accuracy: 0.70 - 125s 3s/step - loss: 0.5289 - accuracy: 0.7091 - val_loss: 0.7915 - val_accuracy: 0.6154\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 1.00 - ETA: 58s - loss: 0.2657 - accuracy: 0.950 - ETA: 1:15 - loss: 0.5032 - accuracy: 0.83 - ETA: 1:22 - loss: 0.4512 - accuracy: 0.85 - ETA: 1:25 - loss: 0.4921 - accuracy: 0.76 - ETA: 1:26 - loss: 0.6125 - accuracy: 0.76 - ETA: 1:25 - loss: 0.5901 - accuracy: 0.77 - ETA: 1:24 - loss: 0.5594 - accuracy: 0.75 - ETA: 1:22 - loss: 0.5591 - accuracy: 0.76 - ETA: 1:20 - loss: 0.5565 - accuracy: 0.76 - ETA: 1:18 - loss: 0.5457 - accuracy: 0.75 - ETA: 1:16 - loss: 0.5329 - accuracy: 0.75 - ETA: 1:13 - loss: 0.5134 - accuracy: 0.76 - ETA: 1:11 - loss: 0.5035 - accuracy: 0.77 - ETA: 1:08 - loss: 0.5100 - accuracy: 0.76 - ETA: 1:06 - loss: 0.4992 - accuracy: 0.76 - ETA: 1:03 - loss: 0.4813 - accuracy: 0.77 - ETA: 1:00 - loss: 0.4767 - accuracy: 0.77 - ETA: 57s - loss: 0.4712 - accuracy: 0.7684 - ETA: 54s - loss: 0.5466 - accuracy: 0.770 - ETA: 51s - loss: 0.5592 - accuracy: 0.766 - ETA: 48s - loss: 0.5509 - accuracy: 0.768 - ETA: 45s - loss: 0.5628 - accuracy: 0.773 - ETA: 42s - loss: 0.5578 - accuracy: 0.770 - ETA: 38s - loss: 0.5488 - accuracy: 0.772 - ETA: 35s - loss: 0.5432 - accuracy: 0.769 - ETA: 32s - loss: 0.5376 - accuracy: 0.763 - ETA: 29s - loss: 0.5294 - accuracy: 0.767 - ETA: 26s - loss: 0.5234 - accuracy: 0.772 - ETA: 22s - loss: 0.5096 - accuracy: 0.780 - ETA: 19s - loss: 0.5118 - accuracy: 0.774 - ETA: 16s - loss: 0.5028 - accuracy: 0.775 - ETA: 13s - loss: 0.5102 - accuracy: 0.775 - ETA: 9s - loss: 0.5125 - accuracy: 0.767 - ETA: 6s - loss: 0.5444 - accuracy: 0.76 - ETA: 3s - loss: 0.5396 - accuracy: 0.76 - ETA: 0s - loss: 0.5392 - accuracy: 0.76 - 126s 3s/step - loss: 0.5392 - accuracy: 0.7673 - val_loss: 0.7694 - val_accuracy: 0.6374\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.5822 - accuracy: 0.50 - ETA: 58s - loss: 0.4765 - accuracy: 0.550 - ETA: 1:15 - loss: 0.4566 - accuracy: 0.63 - ETA: 1:22 - loss: 0.4657 - accuracy: 0.67 - ETA: 1:25 - loss: 0.5168 - accuracy: 0.66 - ETA: 1:26 - loss: 0.5631 - accuracy: 0.68 - ETA: 1:25 - loss: 0.5900 - accuracy: 0.68 - ETA: 1:24 - loss: 0.5702 - accuracy: 0.70 - ETA: 1:23 - loss: 0.5575 - accuracy: 0.70 - ETA: 1:22 - loss: 0.5608 - accuracy: 0.71 - ETA: 1:20 - loss: 0.5515 - accuracy: 0.72 - ETA: 1:17 - loss: 0.5390 - accuracy: 0.74 - ETA: 1:15 - loss: 0.5274 - accuracy: 0.73 - ETA: 1:12 - loss: 0.5345 - accuracy: 0.74 - ETA: 1:09 - loss: 0.5303 - accuracy: 0.73 - ETA: 1:07 - loss: 0.5169 - accuracy: 0.73 - ETA: 1:04 - loss: 0.5189 - accuracy: 0.72 - ETA: 1:01 - loss: 0.5085 - accuracy: 0.72 - ETA: 58s - loss: 0.5007 - accuracy: 0.7263 - ETA: 55s - loss: 0.5038 - accuracy: 0.720 - ETA: 52s - loss: 0.5026 - accuracy: 0.728 - ETA: 49s - loss: 0.4975 - accuracy: 0.722 - ETA: 45s - loss: 0.4994 - accuracy: 0.717 - ETA: 42s - loss: 0.4988 - accuracy: 0.725 - ETA: 39s - loss: 0.4955 - accuracy: 0.724 - ETA: 36s - loss: 0.4912 - accuracy: 0.730 - ETA: 33s - loss: 0.4877 - accuracy: 0.733 - ETA: 29s - loss: 0.4882 - accuracy: 0.728 - ETA: 26s - loss: 0.4816 - accuracy: 0.734 - ETA: 23s - loss: 0.4798 - accuracy: 0.736 - ETA: 19s - loss: 0.4887 - accuracy: 0.729 - ETA: 16s - loss: 0.4943 - accuracy: 0.725 - ETA: 13s - loss: 0.5008 - accuracy: 0.724 - ETA: 10s - loss: 0.4947 - accuracy: 0.726 - ETA: 6s - loss: 0.4879 - accuracy: 0.734 - ETA: 3s - loss: 0.4799 - accuracy: 0.74 - ETA: 0s - loss: 0.4797 - accuracy: 0.74 - 128s 3s/step - loss: 0.4797 - accuracy: 0.7424 - val_loss: 0.7500 - val_accuracy: 0.5824\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4737 - accuracy: 0.70 - ETA: 58s - loss: 0.4923 - accuracy: 0.650 - ETA: 1:16 - loss: 0.4851 - accuracy: 0.66 - ETA: 1:23 - loss: 0.5027 - accuracy: 0.70 - ETA: 1:26 - loss: 0.4816 - accuracy: 0.72 - ETA: 1:26 - loss: 0.4844 - accuracy: 0.70 - ETA: 1:26 - loss: 0.4576 - accuracy: 0.70 - ETA: 1:24 - loss: 0.4503 - accuracy: 0.71 - ETA: 1:23 - loss: 0.4631 - accuracy: 0.72 - ETA: 1:21 - loss: 0.4622 - accuracy: 0.71 - ETA: 1:19 - loss: 0.4495 - accuracy: 0.71 - ETA: 1:16 - loss: 0.4316 - accuracy: 0.73 - ETA: 1:14 - loss: 0.4495 - accuracy: 0.73 - ETA: 1:11 - loss: 0.4688 - accuracy: 0.72 - ETA: 1:08 - loss: 0.4639 - accuracy: 0.73 - ETA: 1:05 - loss: 0.4596 - accuracy: 0.73 - ETA: 1:02 - loss: 0.4746 - accuracy: 0.73 - ETA: 1:00 - loss: 0.4744 - accuracy: 0.72 - ETA: 57s - loss: 0.4701 - accuracy: 0.7263 - ETA: 54s - loss: 0.5244 - accuracy: 0.725 - ETA: 51s - loss: 0.5220 - accuracy: 0.719 - ETA: 47s - loss: 0.5163 - accuracy: 0.718 - ETA: 44s - loss: 0.5341 - accuracy: 0.721 - ETA: 41s - loss: 0.5361 - accuracy: 0.729 - ETA: 38s - loss: 0.5260 - accuracy: 0.728 - ETA: 35s - loss: 0.5267 - accuracy: 0.723 - ETA: 32s - loss: 0.5411 - accuracy: 0.722 - ETA: 29s - loss: 0.5397 - accuracy: 0.721 - ETA: 25s - loss: 0.5375 - accuracy: 0.720 - ETA: 22s - loss: 0.5317 - accuracy: 0.726 - ETA: 19s - loss: 0.5244 - accuracy: 0.729 - ETA: 16s - loss: 0.5167 - accuracy: 0.731 - ETA: 13s - loss: 0.5137 - accuracy: 0.733 - ETA: 9s - loss: 0.5104 - accuracy: 0.726 - ETA: 6s - loss: 0.5024 - accuracy: 0.72 - ETA: 3s - loss: 0.5033 - accuracy: 0.73 - ETA: 0s - loss: 0.5031 - accuracy: 0.73 - 128s 3s/step - loss: 0.5031 - accuracy: 0.7341 - val_loss: 0.7370 - val_accuracy: 0.6484\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 0.90 - ETA: 1:00 - loss: 0.3057 - accuracy: 0.75 - ETA: 1:18 - loss: 0.5116 - accuracy: 0.73 - ETA: 1:27 - loss: 0.5787 - accuracy: 0.75 - ETA: 1:30 - loss: 0.5678 - accuracy: 0.74 - ETA: 1:33 - loss: 0.5707 - accuracy: 0.75 - ETA: 1:33 - loss: 0.5566 - accuracy: 0.72 - ETA: 1:34 - loss: 0.5461 - accuracy: 0.75 - ETA: 1:33 - loss: 0.5197 - accuracy: 0.76 - ETA: 1:30 - loss: 0.4859 - accuracy: 0.78 - ETA: 1:28 - loss: 0.4705 - accuracy: 0.78 - ETA: 1:25 - loss: 0.4656 - accuracy: 0.77 - ETA: 1:22 - loss: 0.5133 - accuracy: 0.74 - ETA: 1:20 - loss: 0.5073 - accuracy: 0.73 - ETA: 1:16 - loss: 0.4966 - accuracy: 0.74 - ETA: 1:13 - loss: 0.5036 - accuracy: 0.72 - ETA: 1:10 - loss: 0.4846 - accuracy: 0.74 - ETA: 1:06 - loss: 0.4742 - accuracy: 0.74 - ETA: 1:03 - loss: 0.4728 - accuracy: 0.74 - ETA: 59s - loss: 0.4967 - accuracy: 0.7300 - ETA: 56s - loss: 0.4889 - accuracy: 0.738 - ETA: 52s - loss: 0.4840 - accuracy: 0.745 - ETA: 48s - loss: 0.4794 - accuracy: 0.747 - ETA: 45s - loss: 0.4750 - accuracy: 0.741 - ETA: 41s - loss: 0.4737 - accuracy: 0.744 - ETA: 38s - loss: 0.4686 - accuracy: 0.746 - ETA: 34s - loss: 0.4643 - accuracy: 0.748 - ETA: 31s - loss: 0.4761 - accuracy: 0.750 - ETA: 27s - loss: 0.4780 - accuracy: 0.748 - ETA: 24s - loss: 0.4845 - accuracy: 0.743 - ETA: 20s - loss: 0.4943 - accuracy: 0.738 - ETA: 17s - loss: 0.4949 - accuracy: 0.734 - ETA: 13s - loss: 0.4922 - accuracy: 0.736 - ETA: 10s - loss: 0.4861 - accuracy: 0.744 - ETA: 6s - loss: 0.4851 - accuracy: 0.745 - ETA: 3s - loss: 0.4970 - accuracy: 0.74 - ETA: 0s - loss: 0.4967 - accuracy: 0.74 - 131s 4s/step - loss: 0.4967 - accuracy: 0.7424 - val_loss: 0.7501 - val_accuracy: 0.6703\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4130 - accuracy: 0.80 - ETA: 57s - loss: 0.3575 - accuracy: 0.800 - ETA: 1:15 - loss: 0.6265 - accuracy: 0.73 - ETA: 1:22 - loss: 0.6117 - accuracy: 0.77 - ETA: 1:24 - loss: 0.6003 - accuracy: 0.78 - ETA: 1:25 - loss: 0.5777 - accuracy: 0.76 - ETA: 1:26 - loss: 0.5743 - accuracy: 0.75 - ETA: 1:25 - loss: 0.5600 - accuracy: 0.73 - ETA: 1:23 - loss: 0.5271 - accuracy: 0.74 - ETA: 1:23 - loss: 0.5244 - accuracy: 0.74 - ETA: 1:21 - loss: 0.5644 - accuracy: 0.72 - ETA: 1:18 - loss: 0.5507 - accuracy: 0.74 - ETA: 1:15 - loss: 0.5466 - accuracy: 0.73 - ETA: 1:13 - loss: 0.5352 - accuracy: 0.73 - ETA: 1:10 - loss: 0.5351 - accuracy: 0.74 - ETA: 1:07 - loss: 0.5162 - accuracy: 0.74 - ETA: 1:04 - loss: 0.5010 - accuracy: 0.74 - ETA: 1:01 - loss: 0.5009 - accuracy: 0.74 - ETA: 58s - loss: 0.4932 - accuracy: 0.7421 - ETA: 54s - loss: 0.4925 - accuracy: 0.740 - ETA: 51s - loss: 0.4914 - accuracy: 0.742 - ETA: 48s - loss: 0.4877 - accuracy: 0.736 - ETA: 45s - loss: 0.5205 - accuracy: 0.739 - ETA: 42s - loss: 0.5207 - accuracy: 0.737 - ETA: 39s - loss: 0.5259 - accuracy: 0.728 - ETA: 35s - loss: 0.5337 - accuracy: 0.730 - ETA: 32s - loss: 0.5313 - accuracy: 0.722 - ETA: 29s - loss: 0.5283 - accuracy: 0.725 - ETA: 26s - loss: 0.5207 - accuracy: 0.727 - ETA: 22s - loss: 0.5267 - accuracy: 0.720 - ETA: 19s - loss: 0.5377 - accuracy: 0.722 - ETA: 16s - loss: 0.5360 - accuracy: 0.721 - ETA: 13s - loss: 0.5273 - accuracy: 0.727 - ETA: 9s - loss: 0.5333 - accuracy: 0.720 - ETA: 6s - loss: 0.5288 - accuracy: 0.72 - ETA: 3s - loss: 0.5313 - accuracy: 0.72 - ETA: 0s - loss: 0.5309 - accuracy: 0.72 - 125s 3s/step - loss: 0.5309 - accuracy: 0.7230 - val_loss: 0.7231 - val_accuracy: 0.6703\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.7657 - accuracy: 0.80 - ETA: 58s - loss: 0.9243 - accuracy: 0.750 - ETA: 1:15 - loss: 0.7409 - accuracy: 0.70 - ETA: 1:22 - loss: 0.6490 - accuracy: 0.77 - ETA: 1:25 - loss: 0.6097 - accuracy: 0.72 - ETA: 1:25 - loss: 0.5803 - accuracy: 0.75 - ETA: 1:25 - loss: 0.5164 - accuracy: 0.78 - ETA: 1:24 - loss: 0.5597 - accuracy: 0.77 - ETA: 1:22 - loss: 0.5462 - accuracy: 0.76 - ETA: 1:20 - loss: 0.5640 - accuracy: 0.76 - ETA: 1:18 - loss: 0.5505 - accuracy: 0.75 - ETA: 1:16 - loss: 0.5475 - accuracy: 0.75 - ETA: 1:13 - loss: 0.5250 - accuracy: 0.74 - ETA: 1:11 - loss: 0.6107 - accuracy: 0.73 - ETA: 1:08 - loss: 0.5807 - accuracy: 0.74 - ETA: 1:05 - loss: 0.5835 - accuracy: 0.74 - ETA: 1:02 - loss: 0.6378 - accuracy: 0.74 - ETA: 1:00 - loss: 0.6356 - accuracy: 0.73 - ETA: 57s - loss: 0.6368 - accuracy: 0.7263 - ETA: 55s - loss: 0.6217 - accuracy: 0.735 - ETA: 52s - loss: 0.6110 - accuracy: 0.733 - ETA: 49s - loss: 0.5944 - accuracy: 0.745 - ETA: 46s - loss: 0.5929 - accuracy: 0.743 - ETA: 43s - loss: 0.6113 - accuracy: 0.741 - ETA: 40s - loss: 0.6039 - accuracy: 0.748 - ETA: 37s - loss: 0.5892 - accuracy: 0.753 - ETA: 33s - loss: 0.5772 - accuracy: 0.759 - ETA: 31s - loss: 0.5736 - accuracy: 0.760 - ETA: 27s - loss: 0.6010 - accuracy: 0.755 - ETA: 24s - loss: 0.5977 - accuracy: 0.760 - ETA: 20s - loss: 0.5942 - accuracy: 0.758 - ETA: 17s - loss: 0.5804 - accuracy: 0.765 - ETA: 13s - loss: 0.5838 - accuracy: 0.763 - ETA: 10s - loss: 0.5718 - accuracy: 0.767 - ETA: 6s - loss: 0.5725 - accuracy: 0.762 - ETA: 3s - loss: 0.5634 - accuracy: 0.76 - ETA: 0s - loss: 0.5630 - accuracy: 0.76 - 133s 4s/step - loss: 0.5630 - accuracy: 0.7645 - val_loss: 0.7021 - val_accuracy: 0.6264\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3662 - accuracy: 0.80 - ETA: 58s - loss: 0.8481 - accuracy: 0.800 - ETA: 1:15 - loss: 0.6567 - accuracy: 0.76 - ETA: 1:22 - loss: 0.5550 - accuracy: 0.77 - ETA: 1:25 - loss: 0.5135 - accuracy: 0.78 - ETA: 1:26 - loss: 0.4794 - accuracy: 0.76 - ETA: 1:25 - loss: 0.4652 - accuracy: 0.77 - ETA: 1:24 - loss: 0.4570 - accuracy: 0.78 - ETA: 1:23 - loss: 0.4571 - accuracy: 0.78 - ETA: 1:21 - loss: 0.4471 - accuracy: 0.80 - ETA: 1:18 - loss: 0.4343 - accuracy: 0.80 - ETA: 1:16 - loss: 0.4219 - accuracy: 0.81 - ETA: 1:13 - loss: 0.4273 - accuracy: 0.80 - ETA: 1:11 - loss: 0.4130 - accuracy: 0.80 - ETA: 1:08 - loss: 0.4065 - accuracy: 0.81 - ETA: 1:05 - loss: 0.3964 - accuracy: 0.82 - ETA: 1:02 - loss: 0.3902 - accuracy: 0.81 - ETA: 59s - loss: 0.3869 - accuracy: 0.8278 - ETA: 56s - loss: 0.3852 - accuracy: 0.826 - ETA: 53s - loss: 0.4000 - accuracy: 0.810 - ETA: 50s - loss: 0.3937 - accuracy: 0.809 - ETA: 47s - loss: 0.3866 - accuracy: 0.813 - ETA: 44s - loss: 0.3833 - accuracy: 0.813 - ETA: 41s - loss: 0.4107 - accuracy: 0.808 - ETA: 38s - loss: 0.4062 - accuracy: 0.808 - ETA: 35s - loss: 0.4083 - accuracy: 0.807 - ETA: 32s - loss: 0.4060 - accuracy: 0.811 - ETA: 29s - loss: 0.4103 - accuracy: 0.807 - ETA: 25s - loss: 0.4096 - accuracy: 0.810 - ETA: 22s - loss: 0.4158 - accuracy: 0.806 - ETA: 19s - loss: 0.4111 - accuracy: 0.806 - ETA: 16s - loss: 0.4166 - accuracy: 0.803 - ETA: 13s - loss: 0.4364 - accuracy: 0.800 - ETA: 9s - loss: 0.4317 - accuracy: 0.800 - ETA: 6s - loss: 0.4252 - accuracy: 0.80 - ETA: 3s - loss: 0.4414 - accuracy: 0.80 - ETA: 0s - loss: 0.4414 - accuracy: 0.80 - 125s 3s/step - loss: 0.4414 - accuracy: 0.8033 - val_loss: 0.7269 - val_accuracy: 0.6484\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.7331 - accuracy: 0.70 - ETA: 58s - loss: 0.5081 - accuracy: 0.750 - ETA: 1:15 - loss: 0.4008 - accuracy: 0.83 - ETA: 1:22 - loss: 0.3876 - accuracy: 0.80 - ETA: 1:25 - loss: 0.3897 - accuracy: 0.78 - ETA: 1:26 - loss: 0.4076 - accuracy: 0.75 - ETA: 1:25 - loss: 0.4424 - accuracy: 0.74 - ETA: 1:24 - loss: 0.4197 - accuracy: 0.73 - ETA: 1:22 - loss: 0.4091 - accuracy: 0.73 - ETA: 1:21 - loss: 0.3988 - accuracy: 0.74 - ETA: 1:18 - loss: 0.4017 - accuracy: 0.73 - ETA: 1:16 - loss: 0.4058 - accuracy: 0.72 - ETA: 1:13 - loss: 0.4349 - accuracy: 0.71 - ETA: 1:11 - loss: 0.4742 - accuracy: 0.70 - ETA: 1:08 - loss: 0.4727 - accuracy: 0.72 - ETA: 1:05 - loss: 0.4611 - accuracy: 0.72 - ETA: 1:02 - loss: 0.4682 - accuracy: 0.72 - ETA: 59s - loss: 0.4672 - accuracy: 0.7222 - ETA: 56s - loss: 0.4615 - accuracy: 0.721 - ETA: 53s - loss: 0.4680 - accuracy: 0.720 - ETA: 50s - loss: 0.4707 - accuracy: 0.723 - ETA: 47s - loss: 0.4620 - accuracy: 0.731 - ETA: 44s - loss: 0.4538 - accuracy: 0.734 - ETA: 41s - loss: 0.4506 - accuracy: 0.745 - ETA: 38s - loss: 0.4570 - accuracy: 0.736 - ETA: 35s - loss: 0.4448 - accuracy: 0.746 - ETA: 32s - loss: 0.4380 - accuracy: 0.751 - ETA: 28s - loss: 0.4324 - accuracy: 0.757 - ETA: 25s - loss: 0.4279 - accuracy: 0.758 - ETA: 22s - loss: 0.4313 - accuracy: 0.760 - ETA: 19s - loss: 0.4309 - accuracy: 0.754 - ETA: 16s - loss: 0.4283 - accuracy: 0.762 - ETA: 13s - loss: 0.4301 - accuracy: 0.763 - ETA: 9s - loss: 0.4311 - accuracy: 0.764 - ETA: 6s - loss: 0.4241 - accuracy: 0.76 - ETA: 3s - loss: 0.4300 - accuracy: 0.76 - ETA: 0s - loss: 0.4339 - accuracy: 0.76 - 128s 3s/step - loss: 0.4339 - accuracy: 0.7673 - val_loss: 0.7068 - val_accuracy: 0.6703\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.90 - ETA: 1:04 - loss: 0.2441 - accuracy: 0.90 - ETA: 1:20 - loss: 0.2902 - accuracy: 0.83 - ETA: 1:27 - loss: 0.2792 - accuracy: 0.85 - ETA: 1:31 - loss: 0.4830 - accuracy: 0.80 - ETA: 1:31 - loss: 0.4966 - accuracy: 0.78 - ETA: 1:30 - loss: 0.4837 - accuracy: 0.80 - ETA: 1:29 - loss: 0.5535 - accuracy: 0.78 - ETA: 1:28 - loss: 0.5792 - accuracy: 0.77 - ETA: 1:25 - loss: 0.5372 - accuracy: 0.80 - ETA: 1:23 - loss: 0.5170 - accuracy: 0.79 - ETA: 1:20 - loss: 0.4946 - accuracy: 0.80 - ETA: 1:18 - loss: 0.5026 - accuracy: 0.80 - ETA: 1:15 - loss: 0.5378 - accuracy: 0.79 - ETA: 1:12 - loss: 0.5368 - accuracy: 0.78 - ETA: 1:09 - loss: 0.5253 - accuracy: 0.77 - ETA: 1:06 - loss: 0.5141 - accuracy: 0.77 - ETA: 1:03 - loss: 0.5265 - accuracy: 0.76 - ETA: 59s - loss: 0.5320 - accuracy: 0.7632 - ETA: 56s - loss: 0.5213 - accuracy: 0.765 - ETA: 53s - loss: 0.5166 - accuracy: 0.761 - ETA: 50s - loss: 0.5120 - accuracy: 0.763 - ETA: 46s - loss: 0.5201 - accuracy: 0.765 - ETA: 43s - loss: 0.5372 - accuracy: 0.766 - ETA: 40s - loss: 0.5470 - accuracy: 0.756 - ETA: 36s - loss: 0.5447 - accuracy: 0.753 - ETA: 33s - loss: 0.5556 - accuracy: 0.748 - ETA: 30s - loss: 0.5659 - accuracy: 0.739 - ETA: 26s - loss: 0.5663 - accuracy: 0.737 - ETA: 23s - loss: 0.5665 - accuracy: 0.733 - ETA: 20s - loss: 0.5617 - accuracy: 0.729 - ETA: 16s - loss: 0.5558 - accuracy: 0.731 - ETA: 13s - loss: 0.5528 - accuracy: 0.733 - ETA: 10s - loss: 0.5493 - accuracy: 0.738 - ETA: 6s - loss: 0.5429 - accuracy: 0.742 - ETA: 3s - loss: 0.5465 - accuracy: 0.73 - ETA: 0s - loss: 0.5462 - accuracy: 0.73 - 129s 3s/step - loss: 0.5462 - accuracy: 0.7396 - val_loss: 0.7621 - val_accuracy: 0.6044\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2417 - accuracy: 0.80 - ETA: 59s - loss: 0.2485 - accuracy: 0.800 - ETA: 1:17 - loss: 0.3223 - accuracy: 0.76 - ETA: 1:26 - loss: 0.4686 - accuracy: 0.77 - ETA: 1:30 - loss: 0.4349 - accuracy: 0.80 - ETA: 1:33 - loss: 0.6568 - accuracy: 0.78 - ETA: 1:33 - loss: 0.6491 - accuracy: 0.78 - ETA: 1:33 - loss: 0.6105 - accuracy: 0.78 - ETA: 1:32 - loss: 0.5672 - accuracy: 0.78 - ETA: 1:30 - loss: 0.5572 - accuracy: 0.79 - ETA: 1:28 - loss: 0.5494 - accuracy: 0.78 - ETA: 1:25 - loss: 0.5763 - accuracy: 0.78 - ETA: 1:22 - loss: 0.5493 - accuracy: 0.79 - ETA: 1:18 - loss: 0.5209 - accuracy: 0.80 - ETA: 1:15 - loss: 0.5239 - accuracy: 0.80 - ETA: 1:11 - loss: 0.5167 - accuracy: 0.79 - ETA: 1:08 - loss: 0.5071 - accuracy: 0.78 - ETA: 1:04 - loss: 0.5050 - accuracy: 0.78 - ETA: 1:01 - loss: 0.4911 - accuracy: 0.78 - ETA: 57s - loss: 0.4879 - accuracy: 0.7900 - ETA: 54s - loss: 0.4762 - accuracy: 0.795 - ETA: 50s - loss: 0.4897 - accuracy: 0.790 - ETA: 47s - loss: 0.5020 - accuracy: 0.787 - ETA: 43s - loss: 0.4977 - accuracy: 0.779 - ETA: 40s - loss: 0.4868 - accuracy: 0.784 - ETA: 37s - loss: 0.4765 - accuracy: 0.788 - ETA: 33s - loss: 0.4716 - accuracy: 0.788 - ETA: 30s - loss: 0.4659 - accuracy: 0.789 - ETA: 27s - loss: 0.4616 - accuracy: 0.786 - ETA: 23s - loss: 0.4959 - accuracy: 0.783 - ETA: 20s - loss: 0.4950 - accuracy: 0.783 - ETA: 16s - loss: 0.5007 - accuracy: 0.778 - ETA: 13s - loss: 0.4957 - accuracy: 0.781 - ETA: 10s - loss: 0.4927 - accuracy: 0.779 - ETA: 6s - loss: 0.4867 - accuracy: 0.780 - ETA: 3s - loss: 0.4808 - accuracy: 0.78 - ETA: 0s - loss: 0.4806 - accuracy: 0.78 - 129s 3s/step - loss: 0.4806 - accuracy: 0.7812 - val_loss: 0.7469 - val_accuracy: 0.6154\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1384 - accuracy: 0.90 - ETA: 58s - loss: 0.2417 - accuracy: 0.900 - ETA: 1:15 - loss: 0.3565 - accuracy: 0.83 - ETA: 1:22 - loss: 0.3057 - accuracy: 0.87 - ETA: 1:25 - loss: 0.3048 - accuracy: 0.86 - ETA: 1:26 - loss: 0.3369 - accuracy: 0.85 - ETA: 1:27 - loss: 0.3271 - accuracy: 0.84 - ETA: 1:27 - loss: 0.3282 - accuracy: 0.82 - ETA: 1:26 - loss: 0.3467 - accuracy: 0.81 - ETA: 1:25 - loss: 0.3350 - accuracy: 0.83 - ETA: 1:23 - loss: 0.3683 - accuracy: 0.82 - ETA: 1:21 - loss: 0.3666 - accuracy: 0.80 - ETA: 1:18 - loss: 0.3634 - accuracy: 0.80 - ETA: 1:15 - loss: 0.3868 - accuracy: 0.80 - ETA: 1:12 - loss: 0.4144 - accuracy: 0.79 - ETA: 1:09 - loss: 0.4144 - accuracy: 0.78 - ETA: 1:06 - loss: 0.4214 - accuracy: 0.79 - ETA: 1:03 - loss: 0.4106 - accuracy: 0.80 - ETA: 59s - loss: 0.4103 - accuracy: 0.8000 - ETA: 56s - loss: 0.4125 - accuracy: 0.785 - ETA: 53s - loss: 0.4170 - accuracy: 0.776 - ETA: 49s - loss: 0.4055 - accuracy: 0.781 - ETA: 46s - loss: 0.4017 - accuracy: 0.782 - ETA: 43s - loss: 0.4036 - accuracy: 0.787 - ETA: 39s - loss: 0.4162 - accuracy: 0.784 - ETA: 36s - loss: 0.4071 - accuracy: 0.792 - ETA: 33s - loss: 0.4037 - accuracy: 0.792 - ETA: 29s - loss: 0.4096 - accuracy: 0.782 - ETA: 26s - loss: 0.4083 - accuracy: 0.786 - ETA: 23s - loss: 0.4073 - accuracy: 0.786 - ETA: 19s - loss: 0.4093 - accuracy: 0.783 - ETA: 16s - loss: 0.4019 - accuracy: 0.787 - ETA: 13s - loss: 0.3971 - accuracy: 0.790 - ETA: 9s - loss: 0.3996 - accuracy: 0.788 - ETA: 6s - loss: 0.3947 - accuracy: 0.78 - ETA: 3s - loss: 0.3983 - accuracy: 0.78 - ETA: 0s - loss: 0.3984 - accuracy: 0.78 - 127s 3s/step - loss: 0.3984 - accuracy: 0.7895 - val_loss: 0.7645 - val_accuracy: 0.6154\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.1138 - accuracy: 0.90 - ETA: 59s - loss: 0.7043 - accuracy: 0.900 - ETA: 1:16 - loss: 0.6745 - accuracy: 0.83 - ETA: 1:24 - loss: 0.5644 - accuracy: 0.85 - ETA: 1:26 - loss: 0.5359 - accuracy: 0.82 - ETA: 1:26 - loss: 0.5422 - accuracy: 0.81 - ETA: 1:26 - loss: 0.4890 - accuracy: 0.82 - ETA: 1:25 - loss: 0.4941 - accuracy: 0.80 - ETA: 1:23 - loss: 0.4683 - accuracy: 0.78 - ETA: 1:21 - loss: 0.4961 - accuracy: 0.78 - ETA: 1:18 - loss: 0.5082 - accuracy: 0.76 - ETA: 1:16 - loss: 0.5830 - accuracy: 0.75 - ETA: 1:13 - loss: 0.5540 - accuracy: 0.76 - ETA: 1:11 - loss: 0.5401 - accuracy: 0.76 - ETA: 1:08 - loss: 0.5186 - accuracy: 0.76 - ETA: 1:05 - loss: 0.5120 - accuracy: 0.76 - ETA: 1:02 - loss: 0.5000 - accuracy: 0.77 - ETA: 59s - loss: 0.4866 - accuracy: 0.7778 - ETA: 56s - loss: 0.4716 - accuracy: 0.789 - ETA: 53s - loss: 0.4911 - accuracy: 0.795 - ETA: 50s - loss: 0.4901 - accuracy: 0.795 - ETA: 47s - loss: 0.4960 - accuracy: 0.795 - ETA: 44s - loss: 0.4863 - accuracy: 0.795 - ETA: 41s - loss: 0.4872 - accuracy: 0.791 - ETA: 38s - loss: 0.4815 - accuracy: 0.788 - ETA: 35s - loss: 0.4755 - accuracy: 0.788 - ETA: 32s - loss: 0.4681 - accuracy: 0.785 - ETA: 28s - loss: 0.4821 - accuracy: 0.782 - ETA: 25s - loss: 0.4747 - accuracy: 0.779 - ETA: 22s - loss: 0.4716 - accuracy: 0.783 - ETA: 19s - loss: 0.4661 - accuracy: 0.777 - ETA: 16s - loss: 0.4610 - accuracy: 0.781 - ETA: 12s - loss: 0.4555 - accuracy: 0.775 - ETA: 9s - loss: 0.4524 - accuracy: 0.770 - ETA: 6s - loss: 0.4520 - accuracy: 0.76 - ETA: 3s - loss: 0.4499 - accuracy: 0.76 - ETA: 0s - loss: 0.4538 - accuracy: 0.76 - 124s 3s/step - loss: 0.4538 - accuracy: 0.7645 - val_loss: 0.7140 - val_accuracy: 0.6264\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4147 - accuracy: 0.70 - ETA: 57s - loss: 0.5162 - accuracy: 0.750 - ETA: 1:14 - loss: 0.5502 - accuracy: 0.73 - ETA: 1:21 - loss: 0.4897 - accuracy: 0.77 - ETA: 1:24 - loss: 0.5913 - accuracy: 0.74 - ETA: 1:25 - loss: 0.5857 - accuracy: 0.73 - ETA: 1:24 - loss: 0.6545 - accuracy: 0.71 - ETA: 1:23 - loss: 0.6227 - accuracy: 0.72 - ETA: 1:22 - loss: 0.5889 - accuracy: 0.72 - ETA: 1:20 - loss: 0.5467 - accuracy: 0.74 - ETA: 1:18 - loss: 0.5303 - accuracy: 0.73 - ETA: 1:15 - loss: 0.5495 - accuracy: 0.73 - ETA: 1:13 - loss: 0.5472 - accuracy: 0.73 - ETA: 1:10 - loss: 0.5306 - accuracy: 0.73 - ETA: 1:08 - loss: 0.5892 - accuracy: 0.72 - ETA: 1:05 - loss: 0.5714 - accuracy: 0.73 - ETA: 1:03 - loss: 0.5679 - accuracy: 0.73 - ETA: 1:00 - loss: 0.5604 - accuracy: 0.71 - ETA: 58s - loss: 0.5579 - accuracy: 0.7263 - ETA: 55s - loss: 0.5467 - accuracy: 0.725 - ETA: 52s - loss: 0.5306 - accuracy: 0.733 - ETA: 49s - loss: 0.5175 - accuracy: 0.740 - ETA: 46s - loss: 0.5110 - accuracy: 0.747 - ETA: 43s - loss: 0.5198 - accuracy: 0.750 - ETA: 40s - loss: 0.5216 - accuracy: 0.740 - ETA: 37s - loss: 0.5107 - accuracy: 0.742 - ETA: 34s - loss: 0.4998 - accuracy: 0.751 - ETA: 30s - loss: 0.4971 - accuracy: 0.753 - ETA: 27s - loss: 0.4906 - accuracy: 0.755 - ETA: 23s - loss: 0.4816 - accuracy: 0.756 - ETA: 20s - loss: 0.4834 - accuracy: 0.754 - ETA: 17s - loss: 0.4777 - accuracy: 0.753 - ETA: 13s - loss: 0.4688 - accuracy: 0.754 - ETA: 10s - loss: 0.4637 - accuracy: 0.755 - ETA: 6s - loss: 0.4542 - accuracy: 0.762 - ETA: 3s - loss: 0.4512 - accuracy: 0.76 - ETA: 0s - loss: 0.4511 - accuracy: 0.76 - 130s 4s/step - loss: 0.4511 - accuracy: 0.7618 - val_loss: 0.6970 - val_accuracy: 0.6374\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.4163 - accuracy: 0.80 - ETA: 58s - loss: 0.5629 - accuracy: 0.700 - ETA: 1:15 - loss: 0.5414 - accuracy: 0.73 - ETA: 1:23 - loss: 0.4979 - accuracy: 0.72 - ETA: 1:25 - loss: 0.5089 - accuracy: 0.74 - ETA: 1:26 - loss: 0.4937 - accuracy: 0.71 - ETA: 1:25 - loss: 0.5193 - accuracy: 0.71 - ETA: 1:24 - loss: 0.5279 - accuracy: 0.67 - ETA: 1:22 - loss: 0.5052 - accuracy: 0.71 - ETA: 1:20 - loss: 0.4815 - accuracy: 0.72 - ETA: 1:18 - loss: 0.4933 - accuracy: 0.70 - ETA: 1:16 - loss: 0.4798 - accuracy: 0.70 - ETA: 1:13 - loss: 0.4514 - accuracy: 0.72 - ETA: 1:11 - loss: 0.4650 - accuracy: 0.72 - ETA: 1:08 - loss: 0.4571 - accuracy: 0.72 - ETA: 1:05 - loss: 0.4631 - accuracy: 0.72 - ETA: 1:02 - loss: 0.4592 - accuracy: 0.71 - ETA: 59s - loss: 0.4530 - accuracy: 0.7167 - ETA: 56s - loss: 0.4419 - accuracy: 0.726 - ETA: 54s - loss: 0.4788 - accuracy: 0.725 - ETA: 50s - loss: 0.4794 - accuracy: 0.723 - ETA: 47s - loss: 0.4743 - accuracy: 0.731 - ETA: 44s - loss: 0.5009 - accuracy: 0.734 - ETA: 41s - loss: 0.4957 - accuracy: 0.741 - ETA: 38s - loss: 0.4865 - accuracy: 0.744 - ETA: 35s - loss: 0.4814 - accuracy: 0.746 - ETA: 32s - loss: 0.4752 - accuracy: 0.748 - ETA: 28s - loss: 0.4621 - accuracy: 0.757 - ETA: 25s - loss: 0.4493 - accuracy: 0.765 - ETA: 22s - loss: 0.4490 - accuracy: 0.766 - ETA: 19s - loss: 0.4600 - accuracy: 0.767 - ETA: 16s - loss: 0.4584 - accuracy: 0.768 - ETA: 12s - loss: 0.4490 - accuracy: 0.775 - ETA: 9s - loss: 0.4515 - accuracy: 0.773 - ETA: 6s - loss: 0.4509 - accuracy: 0.77 - ETA: 3s - loss: 0.4492 - accuracy: 0.77 - ETA: 0s - loss: 0.4491 - accuracy: 0.77 - 124s 3s/step - loss: 0.4491 - accuracy: 0.7729 - val_loss: 0.7702 - val_accuracy: 0.6264\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.0622 - accuracy: 0.60 - ETA: 58s - loss: 0.7224 - accuracy: 0.650 - ETA: 1:15 - loss: 0.5837 - accuracy: 0.66 - ETA: 1:22 - loss: 0.5514 - accuracy: 0.65 - ETA: 1:25 - loss: 0.5062 - accuracy: 0.66 - ETA: 1:25 - loss: 0.4753 - accuracy: 0.70 - ETA: 1:25 - loss: 0.4904 - accuracy: 0.71 - ETA: 1:24 - loss: 0.5100 - accuracy: 0.72 - ETA: 1:22 - loss: 0.4839 - accuracy: 0.75 - ETA: 1:20 - loss: 0.4821 - accuracy: 0.75 - ETA: 1:18 - loss: 0.4577 - accuracy: 0.77 - ETA: 1:15 - loss: 0.4512 - accuracy: 0.77 - ETA: 1:13 - loss: 0.4530 - accuracy: 0.77 - ETA: 1:10 - loss: 0.4499 - accuracy: 0.77 - ETA: 1:08 - loss: 0.4429 - accuracy: 0.77 - ETA: 1:05 - loss: 0.4468 - accuracy: 0.76 - ETA: 1:02 - loss: 0.4298 - accuracy: 0.78 - ETA: 59s - loss: 0.4297 - accuracy: 0.7833 - ETA: 56s - loss: 0.4267 - accuracy: 0.778 - ETA: 53s - loss: 0.4223 - accuracy: 0.780 - ETA: 50s - loss: 0.4236 - accuracy: 0.776 - ETA: 47s - loss: 0.4330 - accuracy: 0.777 - ETA: 44s - loss: 0.4266 - accuracy: 0.769 - ETA: 41s - loss: 0.4173 - accuracy: 0.775 - ETA: 38s - loss: 0.4139 - accuracy: 0.784 - ETA: 35s - loss: 0.4351 - accuracy: 0.773 - ETA: 32s - loss: 0.4568 - accuracy: 0.774 - ETA: 29s - loss: 0.4462 - accuracy: 0.782 - ETA: 25s - loss: 0.4460 - accuracy: 0.779 - ETA: 22s - loss: 0.4489 - accuracy: 0.776 - ETA: 19s - loss: 0.4623 - accuracy: 0.774 - ETA: 16s - loss: 0.4729 - accuracy: 0.775 - ETA: 12s - loss: 0.4818 - accuracy: 0.769 - ETA: 9s - loss: 0.4726 - accuracy: 0.776 - ETA: 6s - loss: 0.4711 - accuracy: 0.77 - ETA: 3s - loss: 0.4649 - accuracy: 0.78 - ETA: 0s - loss: 0.4647 - accuracy: 0.78 - 124s 3s/step - loss: 0.4647 - accuracy: 0.7812 - val_loss: 0.7508 - val_accuracy: 0.6264\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.90 - ETA: 57s - loss: 0.2050 - accuracy: 0.900 - ETA: 1:15 - loss: 0.3262 - accuracy: 0.76 - ETA: 1:22 - loss: 0.4214 - accuracy: 0.75 - ETA: 1:25 - loss: 0.5020 - accuracy: 0.74 - ETA: 1:26 - loss: 0.4815 - accuracy: 0.71 - ETA: 1:25 - loss: 0.4716 - accuracy: 0.72 - ETA: 1:25 - loss: 0.4750 - accuracy: 0.73 - ETA: 1:23 - loss: 0.4709 - accuracy: 0.72 - ETA: 1:21 - loss: 0.5057 - accuracy: 0.71 - ETA: 1:19 - loss: 0.5090 - accuracy: 0.70 - ETA: 1:16 - loss: 0.4978 - accuracy: 0.70 - ETA: 1:13 - loss: 0.4833 - accuracy: 0.70 - ETA: 1:11 - loss: 0.4697 - accuracy: 0.71 - ETA: 1:08 - loss: 0.4624 - accuracy: 0.71 - ETA: 1:06 - loss: 0.4505 - accuracy: 0.71 - ETA: 1:03 - loss: 0.4512 - accuracy: 0.72 - ETA: 1:00 - loss: 0.4416 - accuracy: 0.72 - ETA: 57s - loss: 0.4295 - accuracy: 0.7368 - ETA: 54s - loss: 0.4172 - accuracy: 0.750 - ETA: 50s - loss: 0.4256 - accuracy: 0.752 - ETA: 47s - loss: 0.4143 - accuracy: 0.763 - ETA: 44s - loss: 0.4107 - accuracy: 0.765 - ETA: 41s - loss: 0.4087 - accuracy: 0.762 - ETA: 38s - loss: 0.4035 - accuracy: 0.772 - ETA: 35s - loss: 0.3978 - accuracy: 0.773 - ETA: 32s - loss: 0.4084 - accuracy: 0.774 - ETA: 29s - loss: 0.4091 - accuracy: 0.767 - ETA: 25s - loss: 0.4036 - accuracy: 0.772 - ETA: 22s - loss: 0.4097 - accuracy: 0.773 - ETA: 19s - loss: 0.4080 - accuracy: 0.774 - ETA: 16s - loss: 0.4002 - accuracy: 0.778 - ETA: 12s - loss: 0.3952 - accuracy: 0.778 - ETA: 9s - loss: 0.4069 - accuracy: 0.770 - ETA: 6s - loss: 0.4010 - accuracy: 0.77 - ETA: 3s - loss: 0.4001 - accuracy: 0.77 - ETA: 0s - loss: 0.4002 - accuracy: 0.77 - 125s 3s/step - loss: 0.4002 - accuracy: 0.7729 - val_loss: 0.7068 - val_accuracy: 0.6484\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 1.00 - ETA: 1:04 - loss: 0.4256 - accuracy: 0.85 - ETA: 1:25 - loss: 0.3936 - accuracy: 0.83 - ETA: 1:31 - loss: 0.3969 - accuracy: 0.80 - ETA: 1:32 - loss: 0.3521 - accuracy: 0.84 - ETA: 1:31 - loss: 0.3543 - accuracy: 0.85 - ETA: 1:30 - loss: 0.3453 - accuracy: 0.84 - ETA: 1:28 - loss: 0.3907 - accuracy: 0.81 - ETA: 1:26 - loss: 0.3800 - accuracy: 0.83 - ETA: 1:23 - loss: 0.3544 - accuracy: 0.84 - ETA: 1:21 - loss: 0.3418 - accuracy: 0.84 - ETA: 1:18 - loss: 0.3949 - accuracy: 0.84 - ETA: 1:16 - loss: 0.3877 - accuracy: 0.84 - ETA: 1:13 - loss: 0.3783 - accuracy: 0.84 - ETA: 1:10 - loss: 0.3808 - accuracy: 0.83 - ETA: 1:07 - loss: 0.3810 - accuracy: 0.82 - ETA: 1:04 - loss: 0.4087 - accuracy: 0.81 - ETA: 1:01 - loss: 0.4027 - accuracy: 0.82 - ETA: 57s - loss: 0.4051 - accuracy: 0.8158 - ETA: 54s - loss: 0.3986 - accuracy: 0.815 - ETA: 51s - loss: 0.3985 - accuracy: 0.823 - ETA: 48s - loss: 0.4033 - accuracy: 0.827 - ETA: 45s - loss: 0.3946 - accuracy: 0.826 - ETA: 42s - loss: 0.3972 - accuracy: 0.825 - ETA: 38s - loss: 0.4141 - accuracy: 0.820 - ETA: 35s - loss: 0.4027 - accuracy: 0.826 - ETA: 32s - loss: 0.3920 - accuracy: 0.829 - ETA: 29s - loss: 0.3925 - accuracy: 0.828 - ETA: 26s - loss: 0.3897 - accuracy: 0.827 - ETA: 22s - loss: 0.3927 - accuracy: 0.823 - ETA: 19s - loss: 0.4032 - accuracy: 0.812 - ETA: 16s - loss: 0.4030 - accuracy: 0.806 - ETA: 13s - loss: 0.3962 - accuracy: 0.809 - ETA: 9s - loss: 0.3934 - accuracy: 0.811 - ETA: 6s - loss: 0.3968 - accuracy: 0.81 - ETA: 3s - loss: 0.4072 - accuracy: 0.80 - ETA: 0s - loss: 0.4072 - accuracy: 0.80 - 125s 3s/step - loss: 0.4072 - accuracy: 0.8089 - val_loss: 0.7418 - val_accuracy: 0.5714\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3146 - accuracy: 0.90 - ETA: 1:02 - loss: 0.3035 - accuracy: 0.90 - ETA: 1:22 - loss: 0.3299 - accuracy: 0.80 - ETA: 1:29 - loss: 0.3069 - accuracy: 0.82 - ETA: 1:31 - loss: 0.3952 - accuracy: 0.78 - ETA: 1:32 - loss: 0.5148 - accuracy: 0.76 - ETA: 1:32 - loss: 0.4821 - accuracy: 0.78 - ETA: 1:30 - loss: 0.4443 - accuracy: 0.80 - ETA: 1:28 - loss: 0.4331 - accuracy: 0.80 - ETA: 1:26 - loss: 0.4217 - accuracy: 0.80 - ETA: 1:23 - loss: 0.4345 - accuracy: 0.78 - ETA: 1:20 - loss: 0.4138 - accuracy: 0.79 - ETA: 1:17 - loss: 0.4010 - accuracy: 0.80 - ETA: 1:14 - loss: 0.3795 - accuracy: 0.80 - ETA: 1:11 - loss: 0.3749 - accuracy: 0.81 - ETA: 1:08 - loss: 0.3679 - accuracy: 0.81 - ETA: 1:05 - loss: 0.3625 - accuracy: 0.81 - ETA: 1:01 - loss: 0.3555 - accuracy: 0.81 - ETA: 58s - loss: 0.3670 - accuracy: 0.8053 - ETA: 55s - loss: 0.3565 - accuracy: 0.810 - ETA: 52s - loss: 0.3571 - accuracy: 0.800 - ETA: 49s - loss: 0.3568 - accuracy: 0.804 - ETA: 45s - loss: 0.3764 - accuracy: 0.808 - ETA: 42s - loss: 0.3734 - accuracy: 0.808 - ETA: 39s - loss: 0.3729 - accuracy: 0.804 - ETA: 36s - loss: 0.3705 - accuracy: 0.807 - ETA: 32s - loss: 0.3761 - accuracy: 0.807 - ETA: 29s - loss: 0.3747 - accuracy: 0.807 - ETA: 26s - loss: 0.3703 - accuracy: 0.806 - ETA: 23s - loss: 0.3716 - accuracy: 0.810 - ETA: 19s - loss: 0.3737 - accuracy: 0.806 - ETA: 16s - loss: 0.3729 - accuracy: 0.803 - ETA: 13s - loss: 0.3682 - accuracy: 0.809 - ETA: 9s - loss: 0.3636 - accuracy: 0.808 - ETA: 6s - loss: 0.3589 - accuracy: 0.81 - ETA: 3s - loss: 0.3617 - accuracy: 0.81 - ETA: 0s - loss: 0.3618 - accuracy: 0.81 - 126s 3s/step - loss: 0.3618 - accuracy: 0.8172 - val_loss: 0.7234 - val_accuracy: 0.6484\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2549 - accuracy: 1.00 - ETA: 57s - loss: 0.1944 - accuracy: 1.000 - ETA: 1:15 - loss: 0.2357 - accuracy: 0.93 - ETA: 1:22 - loss: 0.2939 - accuracy: 0.87 - ETA: 1:26 - loss: 0.3195 - accuracy: 0.86 - ETA: 1:27 - loss: 0.3402 - accuracy: 0.85 - ETA: 1:26 - loss: 0.3119 - accuracy: 0.87 - ETA: 1:25 - loss: 0.3158 - accuracy: 0.86 - ETA: 1:23 - loss: 0.2903 - accuracy: 0.87 - ETA: 1:21 - loss: 0.3234 - accuracy: 0.87 - ETA: 1:19 - loss: 0.3045 - accuracy: 0.87 - ETA: 1:17 - loss: 0.2857 - accuracy: 0.88 - ETA: 1:14 - loss: 0.2875 - accuracy: 0.86 - ETA: 1:11 - loss: 0.2918 - accuracy: 0.86 - ETA: 1:09 - loss: 0.2882 - accuracy: 0.85 - ETA: 1:06 - loss: 0.2802 - accuracy: 0.86 - ETA: 1:03 - loss: 0.2735 - accuracy: 0.86 - ETA: 1:00 - loss: 0.2992 - accuracy: 0.86 - ETA: 57s - loss: 0.3138 - accuracy: 0.8526 - ETA: 54s - loss: 0.3161 - accuracy: 0.855 - ETA: 51s - loss: 0.3199 - accuracy: 0.847 - ETA: 48s - loss: 0.3114 - accuracy: 0.854 - ETA: 44s - loss: 0.3148 - accuracy: 0.847 - ETA: 41s - loss: 0.3210 - accuracy: 0.845 - ETA: 38s - loss: 0.3145 - accuracy: 0.852 - ETA: 35s - loss: 0.3118 - accuracy: 0.853 - ETA: 32s - loss: 0.3101 - accuracy: 0.855 - ETA: 29s - loss: 0.3070 - accuracy: 0.853 - ETA: 25s - loss: 0.3090 - accuracy: 0.851 - ETA: 22s - loss: 0.3144 - accuracy: 0.846 - ETA: 19s - loss: 0.3195 - accuracy: 0.848 - ETA: 16s - loss: 0.3227 - accuracy: 0.846 - ETA: 12s - loss: 0.3213 - accuracy: 0.848 - ETA: 9s - loss: 0.3208 - accuracy: 0.847 - ETA: 6s - loss: 0.3216 - accuracy: 0.84 - ETA: 3s - loss: 0.3202 - accuracy: 0.84 - ETA: 0s - loss: 0.3204 - accuracy: 0.84 - 124s 3s/step - loss: 0.3204 - accuracy: 0.8476 - val_loss: 0.7425 - val_accuracy: 0.6044\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3899 - accuracy: 0.70 - ETA: 57s - loss: 0.4460 - accuracy: 0.750 - ETA: 1:15 - loss: 0.4157 - accuracy: 0.76 - ETA: 1:22 - loss: 0.4100 - accuracy: 0.72 - ETA: 1:25 - loss: 0.3986 - accuracy: 0.72 - ETA: 1:26 - loss: 0.3643 - accuracy: 0.76 - ETA: 1:25 - loss: 0.3513 - accuracy: 0.77 - ETA: 1:24 - loss: 0.3337 - accuracy: 0.80 - ETA: 1:23 - loss: 0.4378 - accuracy: 0.80 - ETA: 1:21 - loss: 0.4482 - accuracy: 0.79 - ETA: 1:18 - loss: 0.4329 - accuracy: 0.80 - ETA: 1:16 - loss: 0.4253 - accuracy: 0.79 - ETA: 1:13 - loss: 0.4096 - accuracy: 0.80 - ETA: 1:11 - loss: 0.4021 - accuracy: 0.80 - ETA: 1:08 - loss: 0.4143 - accuracy: 0.80 - ETA: 1:05 - loss: 0.4035 - accuracy: 0.80 - ETA: 1:02 - loss: 0.3927 - accuracy: 0.81 - ETA: 59s - loss: 0.4070 - accuracy: 0.8111 - ETA: 56s - loss: 0.3983 - accuracy: 0.815 - ETA: 53s - loss: 0.3864 - accuracy: 0.820 - ETA: 50s - loss: 0.3781 - accuracy: 0.819 - ETA: 47s - loss: 0.3661 - accuracy: 0.827 - ETA: 44s - loss: 0.3693 - accuracy: 0.826 - ETA: 41s - loss: 0.3656 - accuracy: 0.829 - ETA: 38s - loss: 0.3630 - accuracy: 0.828 - ETA: 35s - loss: 0.3598 - accuracy: 0.826 - ETA: 32s - loss: 0.3552 - accuracy: 0.825 - ETA: 29s - loss: 0.3459 - accuracy: 0.828 - ETA: 26s - loss: 0.3433 - accuracy: 0.831 - ETA: 23s - loss: 0.3477 - accuracy: 0.826 - ETA: 19s - loss: 0.3525 - accuracy: 0.825 - ETA: 16s - loss: 0.3462 - accuracy: 0.828 - ETA: 13s - loss: 0.3436 - accuracy: 0.827 - ETA: 10s - loss: 0.3409 - accuracy: 0.829 - ETA: 6s - loss: 0.3455 - accuracy: 0.831 - ETA: 3s - loss: 0.3556 - accuracy: 0.82 - ETA: 0s - loss: 0.3557 - accuracy: 0.82 - 128s 3s/step - loss: 0.3557 - accuracy: 0.8283 - val_loss: 0.7501 - val_accuracy: 0.6154\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2941 - accuracy: 0.90 - ETA: 1:04 - loss: 0.2304 - accuracy: 0.90 - ETA: 1:21 - loss: 0.3222 - accuracy: 0.86 - ETA: 1:26 - loss: 0.3213 - accuracy: 0.82 - ETA: 1:28 - loss: 0.3385 - accuracy: 0.82 - ETA: 1:28 - loss: 0.3220 - accuracy: 0.78 - ETA: 1:27 - loss: 0.3225 - accuracy: 0.78 - ETA: 1:25 - loss: 0.4207 - accuracy: 0.78 - ETA: 1:23 - loss: 0.4016 - accuracy: 0.80 - ETA: 1:21 - loss: 0.3721 - accuracy: 0.82 - ETA: 1:19 - loss: 0.3658 - accuracy: 0.81 - ETA: 1:16 - loss: 0.3728 - accuracy: 0.82 - ETA: 1:14 - loss: 0.4267 - accuracy: 0.82 - ETA: 1:11 - loss: 0.4103 - accuracy: 0.82 - ETA: 1:08 - loss: 0.4297 - accuracy: 0.80 - ETA: 1:05 - loss: 0.4280 - accuracy: 0.80 - ETA: 1:02 - loss: 0.4594 - accuracy: 0.79 - ETA: 59s - loss: 0.4768 - accuracy: 0.7778 - ETA: 56s - loss: 0.4729 - accuracy: 0.778 - ETA: 53s - loss: 0.4611 - accuracy: 0.785 - ETA: 50s - loss: 0.4642 - accuracy: 0.785 - ETA: 47s - loss: 0.4716 - accuracy: 0.777 - ETA: 44s - loss: 0.4732 - accuracy: 0.778 - ETA: 41s - loss: 0.4734 - accuracy: 0.779 - ETA: 38s - loss: 0.4633 - accuracy: 0.780 - ETA: 35s - loss: 0.4518 - accuracy: 0.784 - ETA: 32s - loss: 0.4507 - accuracy: 0.777 - ETA: 28s - loss: 0.4614 - accuracy: 0.775 - ETA: 25s - loss: 0.4494 - accuracy: 0.782 - ETA: 22s - loss: 0.4569 - accuracy: 0.783 - ETA: 19s - loss: 0.4483 - accuracy: 0.780 - ETA: 16s - loss: 0.4411 - accuracy: 0.781 - ETA: 12s - loss: 0.4492 - accuracy: 0.778 - ETA: 9s - loss: 0.4453 - accuracy: 0.779 - ETA: 6s - loss: 0.4378 - accuracy: 0.78 - ETA: 3s - loss: 0.4350 - accuracy: 0.78 - ETA: 0s - loss: 0.4391 - accuracy: 0.78 - 124s 3s/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.6675 - val_accuracy: 0.6484\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2793 - accuracy: 0.80 - ETA: 58s - loss: 0.2407 - accuracy: 0.850 - ETA: 1:15 - loss: 0.3543 - accuracy: 0.73 - ETA: 1:22 - loss: 0.3480 - accuracy: 0.72 - ETA: 1:25 - loss: 0.3492 - accuracy: 0.76 - ETA: 1:25 - loss: 0.3177 - accuracy: 0.78 - ETA: 1:25 - loss: 0.3249 - accuracy: 0.78 - ETA: 1:24 - loss: 0.3215 - accuracy: 0.80 - ETA: 1:22 - loss: 0.3078 - accuracy: 0.81 - ETA: 1:20 - loss: 0.2913 - accuracy: 0.82 - ETA: 1:18 - loss: 0.2870 - accuracy: 0.82 - ETA: 1:16 - loss: 0.3118 - accuracy: 0.80 - ETA: 1:14 - loss: 0.3127 - accuracy: 0.80 - ETA: 1:12 - loss: 0.3318 - accuracy: 0.79 - ETA: 1:09 - loss: 0.3230 - accuracy: 0.80 - ETA: 1:06 - loss: 0.3473 - accuracy: 0.79 - ETA: 1:03 - loss: 0.3450 - accuracy: 0.79 - ETA: 1:00 - loss: 0.3362 - accuracy: 0.80 - ETA: 57s - loss: 0.3363 - accuracy: 0.7947 - ETA: 54s - loss: 0.3291 - accuracy: 0.800 - ETA: 51s - loss: 0.3274 - accuracy: 0.800 - ETA: 48s - loss: 0.3724 - accuracy: 0.795 - ETA: 45s - loss: 0.3724 - accuracy: 0.800 - ETA: 42s - loss: 0.3635 - accuracy: 0.804 - ETA: 38s - loss: 0.3593 - accuracy: 0.808 - ETA: 35s - loss: 0.3537 - accuracy: 0.807 - ETA: 32s - loss: 0.3567 - accuracy: 0.807 - ETA: 29s - loss: 0.3604 - accuracy: 0.803 - ETA: 26s - loss: 0.3836 - accuracy: 0.803 - ETA: 23s - loss: 0.3773 - accuracy: 0.803 - ETA: 19s - loss: 0.3744 - accuracy: 0.809 - ETA: 16s - loss: 0.3789 - accuracy: 0.809 - ETA: 13s - loss: 0.3834 - accuracy: 0.806 - ETA: 10s - loss: 0.3770 - accuracy: 0.811 - ETA: 6s - loss: 0.3805 - accuracy: 0.811 - ETA: 3s - loss: 0.3777 - accuracy: 0.81 - ETA: 0s - loss: 0.3819 - accuracy: 0.81 - 130s 4s/step - loss: 0.3819 - accuracy: 0.8116 - val_loss: 0.6828 - val_accuracy: 0.6703\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4499 - accuracy: 0.80 - ETA: 1:00 - loss: 0.3893 - accuracy: 0.75 - ETA: 1:16 - loss: 0.3706 - accuracy: 0.76 - ETA: 1:22 - loss: 0.3938 - accuracy: 0.77 - ETA: 1:25 - loss: 0.3433 - accuracy: 0.82 - ETA: 1:26 - loss: 0.3075 - accuracy: 0.85 - ETA: 1:25 - loss: 0.2944 - accuracy: 0.84 - ETA: 1:24 - loss: 0.2693 - accuracy: 0.85 - ETA: 1:22 - loss: 0.3289 - accuracy: 0.84 - ETA: 1:20 - loss: 0.3551 - accuracy: 0.84 - ETA: 1:18 - loss: 0.3696 - accuracy: 0.82 - ETA: 1:16 - loss: 0.4636 - accuracy: 0.81 - ETA: 1:13 - loss: 0.4434 - accuracy: 0.81 - ETA: 1:11 - loss: 0.4503 - accuracy: 0.82 - ETA: 1:08 - loss: 0.4330 - accuracy: 0.82 - ETA: 1:05 - loss: 0.4210 - accuracy: 0.83 - ETA: 1:02 - loss: 0.4043 - accuracy: 0.84 - ETA: 59s - loss: 0.3939 - accuracy: 0.8444 - ETA: 56s - loss: 0.3865 - accuracy: 0.842 - ETA: 53s - loss: 0.3905 - accuracy: 0.840 - ETA: 50s - loss: 0.3900 - accuracy: 0.838 - ETA: 47s - loss: 0.3867 - accuracy: 0.836 - ETA: 44s - loss: 0.3905 - accuracy: 0.830 - ETA: 41s - loss: 0.3971 - accuracy: 0.825 - ETA: 38s - loss: 0.4002 - accuracy: 0.824 - ETA: 35s - loss: 0.4258 - accuracy: 0.815 - ETA: 31s - loss: 0.4268 - accuracy: 0.814 - ETA: 28s - loss: 0.4226 - accuracy: 0.810 - ETA: 25s - loss: 0.4222 - accuracy: 0.803 - ETA: 22s - loss: 0.4151 - accuracy: 0.803 - ETA: 19s - loss: 0.4116 - accuracy: 0.803 - ETA: 16s - loss: 0.4089 - accuracy: 0.806 - ETA: 12s - loss: 0.4103 - accuracy: 0.809 - ETA: 9s - loss: 0.4026 - accuracy: 0.814 - ETA: 6s - loss: 0.4223 - accuracy: 0.81 - ETA: 3s - loss: 0.4132 - accuracy: 0.81 - ETA: 0s - loss: 0.4132 - accuracy: 0.81 - 124s 3s/step - loss: 0.4132 - accuracy: 0.8172 - val_loss: 0.7487 - val_accuracy: 0.6374\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1506 - accuracy: 0.90 - ETA: 57s - loss: 0.2691 - accuracy: 0.900 - ETA: 1:14 - loss: 0.2497 - accuracy: 0.90 - ETA: 1:21 - loss: 0.2589 - accuracy: 0.90 - ETA: 1:24 - loss: 0.2839 - accuracy: 0.90 - ETA: 1:24 - loss: 0.2702 - accuracy: 0.90 - ETA: 1:24 - loss: 0.2990 - accuracy: 0.87 - ETA: 1:23 - loss: 0.2896 - accuracy: 0.87 - ETA: 1:21 - loss: 0.3041 - accuracy: 0.85 - ETA: 1:19 - loss: 0.2961 - accuracy: 0.85 - ETA: 1:17 - loss: 0.2858 - accuracy: 0.85 - ETA: 1:15 - loss: 0.3184 - accuracy: 0.85 - ETA: 1:12 - loss: 0.3225 - accuracy: 0.84 - ETA: 1:10 - loss: 0.3280 - accuracy: 0.84 - ETA: 1:07 - loss: 0.3159 - accuracy: 0.85 - ETA: 1:04 - loss: 0.3244 - accuracy: 0.84 - ETA: 1:02 - loss: 0.3221 - accuracy: 0.84 - ETA: 59s - loss: 0.3214 - accuracy: 0.8500 - ETA: 56s - loss: 0.3191 - accuracy: 0.857 - ETA: 53s - loss: 0.3136 - accuracy: 0.860 - ETA: 50s - loss: 0.3075 - accuracy: 0.857 - ETA: 47s - loss: 0.2993 - accuracy: 0.863 - ETA: 44s - loss: 0.3058 - accuracy: 0.852 - ETA: 41s - loss: 0.3057 - accuracy: 0.850 - ETA: 37s - loss: 0.3076 - accuracy: 0.844 - ETA: 34s - loss: 0.3053 - accuracy: 0.850 - ETA: 31s - loss: 0.3030 - accuracy: 0.844 - ETA: 28s - loss: 0.3018 - accuracy: 0.850 - ETA: 25s - loss: 0.3111 - accuracy: 0.844 - ETA: 22s - loss: 0.3107 - accuracy: 0.840 - ETA: 19s - loss: 0.3049 - accuracy: 0.845 - ETA: 15s - loss: 0.3045 - accuracy: 0.843 - ETA: 12s - loss: 0.2994 - accuracy: 0.848 - ETA: 9s - loss: 0.3031 - accuracy: 0.850 - ETA: 6s - loss: 0.3258 - accuracy: 0.84 - ETA: 3s - loss: 0.3242 - accuracy: 0.84 - ETA: 0s - loss: 0.3244 - accuracy: 0.84 - 123s 3s/step - loss: 0.3244 - accuracy: 0.8449 - val_loss: 0.7422 - val_accuracy: 0.6703\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2561 - accuracy: 0.90 - ETA: 58s - loss: 0.2984 - accuracy: 0.800 - ETA: 1:15 - loss: 0.2972 - accuracy: 0.76 - ETA: 1:21 - loss: 0.2904 - accuracy: 0.80 - ETA: 1:24 - loss: 0.2810 - accuracy: 0.80 - ETA: 1:25 - loss: 0.2538 - accuracy: 0.83 - ETA: 1:24 - loss: 0.2269 - accuracy: 0.85 - ETA: 1:23 - loss: 0.2432 - accuracy: 0.83 - ETA: 1:22 - loss: 0.2704 - accuracy: 0.82 - ETA: 1:20 - loss: 0.2570 - accuracy: 0.83 - ETA: 1:17 - loss: 0.2643 - accuracy: 0.81 - ETA: 1:15 - loss: 0.2672 - accuracy: 0.82 - ETA: 1:12 - loss: 0.2810 - accuracy: 0.82 - ETA: 1:10 - loss: 0.2905 - accuracy: 0.81 - ETA: 1:07 - loss: 0.2944 - accuracy: 0.80 - ETA: 1:05 - loss: 0.3006 - accuracy: 0.81 - ETA: 1:02 - loss: 0.2920 - accuracy: 0.81 - ETA: 59s - loss: 0.2904 - accuracy: 0.8167 - ETA: 56s - loss: 0.2821 - accuracy: 0.821 - ETA: 53s - loss: 0.2771 - accuracy: 0.820 - ETA: 50s - loss: 0.3014 - accuracy: 0.814 - ETA: 47s - loss: 0.2978 - accuracy: 0.818 - ETA: 44s - loss: 0.2921 - accuracy: 0.821 - ETA: 41s - loss: 0.2923 - accuracy: 0.825 - ETA: 38s - loss: 0.2965 - accuracy: 0.828 - ETA: 34s - loss: 0.2986 - accuracy: 0.830 - ETA: 31s - loss: 0.2945 - accuracy: 0.833 - ETA: 28s - loss: 0.2930 - accuracy: 0.825 - ETA: 25s - loss: 0.2992 - accuracy: 0.827 - ETA: 22s - loss: 0.3025 - accuracy: 0.826 - ETA: 19s - loss: 0.3115 - accuracy: 0.822 - ETA: 16s - loss: 0.3139 - accuracy: 0.818 - ETA: 12s - loss: 0.3145 - accuracy: 0.815 - ETA: 9s - loss: 0.3118 - accuracy: 0.817 - ETA: 6s - loss: 0.3147 - accuracy: 0.82 - ETA: 3s - loss: 0.3089 - accuracy: 0.82 - ETA: 0s - loss: 0.3091 - accuracy: 0.82 - 123s 3s/step - loss: 0.3091 - accuracy: 0.8255 - val_loss: 0.6975 - val_accuracy: 0.6923\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.1608 - accuracy: 0.90 - ETA: 57s - loss: 0.1631 - accuracy: 0.900 - ETA: 1:14 - loss: 0.1664 - accuracy: 0.93 - ETA: 1:22 - loss: 0.3779 - accuracy: 0.90 - ETA: 1:25 - loss: 0.3941 - accuracy: 0.88 - ETA: 1:26 - loss: 0.4234 - accuracy: 0.85 - ETA: 1:25 - loss: 0.3785 - accuracy: 0.85 - ETA: 1:24 - loss: 0.3820 - accuracy: 0.86 - ETA: 1:22 - loss: 0.3633 - accuracy: 0.86 - ETA: 1:20 - loss: 0.3453 - accuracy: 0.87 - ETA: 1:18 - loss: 0.3373 - accuracy: 0.87 - ETA: 1:16 - loss: 0.3293 - accuracy: 0.87 - ETA: 1:13 - loss: 0.3302 - accuracy: 0.87 - ETA: 1:11 - loss: 0.3476 - accuracy: 0.85 - ETA: 1:08 - loss: 0.3493 - accuracy: 0.86 - ETA: 1:05 - loss: 0.3722 - accuracy: 0.85 - ETA: 1:02 - loss: 0.3637 - accuracy: 0.86 - ETA: 59s - loss: 0.3537 - accuracy: 0.8667 - ETA: 56s - loss: 0.3459 - accuracy: 0.868 - ETA: 53s - loss: 0.3397 - accuracy: 0.865 - ETA: 50s - loss: 0.3359 - accuracy: 0.861 - ETA: 47s - loss: 0.3478 - accuracy: 0.863 - ETA: 44s - loss: 0.3742 - accuracy: 0.856 - ETA: 41s - loss: 0.3655 - accuracy: 0.862 - ETA: 38s - loss: 0.3584 - accuracy: 0.864 - ETA: 35s - loss: 0.3523 - accuracy: 0.861 - ETA: 32s - loss: 0.3502 - accuracy: 0.859 - ETA: 28s - loss: 0.3419 - accuracy: 0.864 - ETA: 25s - loss: 0.3388 - accuracy: 0.862 - ETA: 22s - loss: 0.3313 - accuracy: 0.863 - ETA: 19s - loss: 0.3271 - accuracy: 0.867 - ETA: 16s - loss: 0.3273 - accuracy: 0.865 - ETA: 12s - loss: 0.3360 - accuracy: 0.860 - ETA: 9s - loss: 0.3322 - accuracy: 0.861 - ETA: 6s - loss: 0.3263 - accuracy: 0.86 - ETA: 3s - loss: 0.3265 - accuracy: 0.86 - ETA: 0s - loss: 0.3266 - accuracy: 0.86 - 124s 3s/step - loss: 0.3266 - accuracy: 0.8643 - val_loss: 0.7658 - val_accuracy: 0.6264\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2550 - accuracy: 0.80 - ETA: 57s - loss: 0.4460 - accuracy: 0.850 - ETA: 1:14 - loss: 0.3783 - accuracy: 0.86 - ETA: 1:21 - loss: 0.3029 - accuracy: 0.90 - ETA: 1:24 - loss: 0.4276 - accuracy: 0.86 - ETA: 1:25 - loss: 0.4282 - accuracy: 0.83 - ETA: 1:24 - loss: 0.4130 - accuracy: 0.84 - ETA: 1:23 - loss: 0.3759 - accuracy: 0.85 - ETA: 1:22 - loss: 0.3442 - accuracy: 0.86 - ETA: 1:20 - loss: 0.3419 - accuracy: 0.86 - ETA: 1:18 - loss: 0.3423 - accuracy: 0.84 - ETA: 1:15 - loss: 0.3377 - accuracy: 0.82 - ETA: 1:13 - loss: 0.3252 - accuracy: 0.83 - ETA: 1:10 - loss: 0.3184 - accuracy: 0.82 - ETA: 1:08 - loss: 0.3208 - accuracy: 0.81 - ETA: 1:05 - loss: 0.3447 - accuracy: 0.81 - ETA: 1:03 - loss: 0.3457 - accuracy: 0.81 - ETA: 1:00 - loss: 0.3403 - accuracy: 0.82 - ETA: 57s - loss: 0.3345 - accuracy: 0.8211 - ETA: 54s - loss: 0.3324 - accuracy: 0.820 - ETA: 51s - loss: 0.3317 - accuracy: 0.819 - ETA: 48s - loss: 0.3236 - accuracy: 0.822 - ETA: 45s - loss: 0.3262 - accuracy: 0.817 - ETA: 42s - loss: 0.3261 - accuracy: 0.820 - ETA: 39s - loss: 0.3262 - accuracy: 0.820 - ETA: 35s - loss: 0.3198 - accuracy: 0.823 - ETA: 32s - loss: 0.3164 - accuracy: 0.825 - ETA: 29s - loss: 0.3182 - accuracy: 0.821 - ETA: 26s - loss: 0.3509 - accuracy: 0.820 - ETA: 22s - loss: 0.3430 - accuracy: 0.823 - ETA: 19s - loss: 0.3386 - accuracy: 0.825 - ETA: 16s - loss: 0.3399 - accuracy: 0.828 - ETA: 13s - loss: 0.3394 - accuracy: 0.830 - ETA: 9s - loss: 0.3384 - accuracy: 0.823 - ETA: 6s - loss: 0.3401 - accuracy: 0.82 - ETA: 3s - loss: 0.3369 - accuracy: 0.82 - ETA: 0s - loss: 0.3370 - accuracy: 0.82 - 125s 3s/step - loss: 0.3370 - accuracy: 0.8283 - val_loss: 0.7265 - val_accuracy: 0.6593\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4038 - accuracy: 0.90 - ETA: 57s - loss: 0.3879 - accuracy: 0.900 - ETA: 1:14 - loss: 0.3106 - accuracy: 0.90 - ETA: 1:21 - loss: 0.3873 - accuracy: 0.85 - ETA: 1:26 - loss: 0.3572 - accuracy: 0.82 - ETA: 1:27 - loss: 0.3294 - accuracy: 0.85 - ETA: 1:26 - loss: 0.3116 - accuracy: 0.85 - ETA: 1:25 - loss: 0.2866 - accuracy: 0.87 - ETA: 1:23 - loss: 0.2820 - accuracy: 0.87 - ETA: 1:21 - loss: 0.2751 - accuracy: 0.88 - ETA: 1:19 - loss: 0.2637 - accuracy: 0.89 - ETA: 1:16 - loss: 0.2697 - accuracy: 0.86 - ETA: 1:13 - loss: 0.2741 - accuracy: 0.86 - ETA: 1:11 - loss: 0.2682 - accuracy: 0.86 - ETA: 1:08 - loss: 0.2827 - accuracy: 0.87 - ETA: 1:05 - loss: 0.2754 - accuracy: 0.87 - ETA: 1:02 - loss: 0.2762 - accuracy: 0.87 - ETA: 59s - loss: 0.2677 - accuracy: 0.8778 - ETA: 56s - loss: 0.2654 - accuracy: 0.878 - ETA: 53s - loss: 0.2647 - accuracy: 0.880 - ETA: 50s - loss: 0.2636 - accuracy: 0.881 - ETA: 47s - loss: 0.2588 - accuracy: 0.881 - ETA: 44s - loss: 0.2735 - accuracy: 0.878 - ETA: 41s - loss: 0.2811 - accuracy: 0.875 - ETA: 38s - loss: 0.2767 - accuracy: 0.876 - ETA: 35s - loss: 0.2850 - accuracy: 0.873 - ETA: 32s - loss: 0.2851 - accuracy: 0.866 - ETA: 28s - loss: 0.2810 - accuracy: 0.867 - ETA: 25s - loss: 0.2846 - accuracy: 0.862 - ETA: 22s - loss: 0.2853 - accuracy: 0.863 - ETA: 19s - loss: 0.2922 - accuracy: 0.861 - ETA: 16s - loss: 0.2891 - accuracy: 0.862 - ETA: 12s - loss: 0.2998 - accuracy: 0.863 - ETA: 9s - loss: 0.3015 - accuracy: 0.861 - ETA: 6s - loss: 0.3011 - accuracy: 0.86 - ETA: 3s - loss: 0.2972 - accuracy: 0.86 - ETA: 0s - loss: 0.2974 - accuracy: 0.86 - 124s 3s/step - loss: 0.2974 - accuracy: 0.8670 - val_loss: 0.7061 - val_accuracy: 0.6484\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3551 - accuracy: 0.80 - ETA: 57s - loss: 0.2214 - accuracy: 0.900 - ETA: 1:14 - loss: 0.2426 - accuracy: 0.86 - ETA: 1:21 - loss: 0.2305 - accuracy: 0.87 - ETA: 1:24 - loss: 0.2131 - accuracy: 0.88 - ETA: 1:25 - loss: 0.2283 - accuracy: 0.85 - ETA: 1:24 - loss: 0.2565 - accuracy: 0.84 - ETA: 1:23 - loss: 0.2350 - accuracy: 0.86 - ETA: 1:22 - loss: 0.2267 - accuracy: 0.87 - ETA: 1:20 - loss: 0.2237 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2380 - accuracy: 0.85 - ETA: 1:15 - loss: 0.2448 - accuracy: 0.86 - ETA: 1:13 - loss: 0.2461 - accuracy: 0.86 - ETA: 1:10 - loss: 0.2392 - accuracy: 0.87 - ETA: 1:07 - loss: 0.2381 - accuracy: 0.87 - ETA: 1:05 - loss: 0.2401 - accuracy: 0.86 - ETA: 1:02 - loss: 0.2510 - accuracy: 0.86 - ETA: 59s - loss: 0.2515 - accuracy: 0.8611 - ETA: 56s - loss: 0.2528 - accuracy: 0.863 - ETA: 53s - loss: 0.2578 - accuracy: 0.860 - ETA: 50s - loss: 0.2548 - accuracy: 0.861 - ETA: 47s - loss: 0.2690 - accuracy: 0.859 - ETA: 44s - loss: 0.2673 - accuracy: 0.856 - ETA: 41s - loss: 0.2696 - accuracy: 0.858 - ETA: 38s - loss: 0.2687 - accuracy: 0.864 - ETA: 35s - loss: 0.2627 - accuracy: 0.869 - ETA: 31s - loss: 0.2580 - accuracy: 0.870 - ETA: 28s - loss: 0.2515 - accuracy: 0.875 - ETA: 25s - loss: 0.2475 - accuracy: 0.875 - ETA: 22s - loss: 0.2586 - accuracy: 0.876 - ETA: 19s - loss: 0.2603 - accuracy: 0.874 - ETA: 16s - loss: 0.2872 - accuracy: 0.868 - ETA: 12s - loss: 0.2884 - accuracy: 0.866 - ETA: 9s - loss: 0.2885 - accuracy: 0.864 - ETA: 6s - loss: 0.2833 - accuracy: 0.86 - ETA: 3s - loss: 0.2792 - accuracy: 0.86 - ETA: 0s - loss: 0.2794 - accuracy: 0.86 - 124s 3s/step - loss: 0.2794 - accuracy: 0.8698 - val_loss: 0.7624 - val_accuracy: 0.6154\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 1.00 - ETA: 57s - loss: 0.3690 - accuracy: 0.900 - ETA: 1:15 - loss: 0.3810 - accuracy: 0.86 - ETA: 1:22 - loss: 0.3407 - accuracy: 0.85 - ETA: 1:25 - loss: 0.3823 - accuracy: 0.84 - ETA: 1:26 - loss: 0.3675 - accuracy: 0.85 - ETA: 1:25 - loss: 0.3639 - accuracy: 0.84 - ETA: 1:24 - loss: 0.4227 - accuracy: 0.82 - ETA: 1:22 - loss: 0.3874 - accuracy: 0.84 - ETA: 1:20 - loss: 0.3897 - accuracy: 0.85 - ETA: 1:18 - loss: 0.4092 - accuracy: 0.84 - ETA: 1:16 - loss: 0.3908 - accuracy: 0.85 - ETA: 1:13 - loss: 0.3844 - accuracy: 0.85 - ETA: 1:10 - loss: 0.3772 - accuracy: 0.85 - ETA: 1:08 - loss: 0.3699 - accuracy: 0.84 - ETA: 1:05 - loss: 0.3698 - accuracy: 0.85 - ETA: 1:02 - loss: 0.3569 - accuracy: 0.85 - ETA: 59s - loss: 0.3427 - accuracy: 0.8667 - ETA: 56s - loss: 0.3547 - accuracy: 0.863 - ETA: 53s - loss: 0.3613 - accuracy: 0.860 - ETA: 50s - loss: 0.3660 - accuracy: 0.857 - ETA: 47s - loss: 0.3628 - accuracy: 0.850 - ETA: 44s - loss: 0.3621 - accuracy: 0.852 - ETA: 41s - loss: 0.3635 - accuracy: 0.850 - ETA: 38s - loss: 0.3584 - accuracy: 0.856 - ETA: 35s - loss: 0.3538 - accuracy: 0.853 - ETA: 32s - loss: 0.3527 - accuracy: 0.855 - ETA: 29s - loss: 0.3520 - accuracy: 0.857 - ETA: 25s - loss: 0.3468 - accuracy: 0.862 - ETA: 22s - loss: 0.3470 - accuracy: 0.860 - ETA: 19s - loss: 0.3434 - accuracy: 0.864 - ETA: 16s - loss: 0.3407 - accuracy: 0.859 - ETA: 12s - loss: 0.3428 - accuracy: 0.857 - ETA: 9s - loss: 0.3350 - accuracy: 0.861 - ETA: 6s - loss: 0.3408 - accuracy: 0.85 - ETA: 3s - loss: 0.3439 - accuracy: 0.85 - ETA: 0s - loss: 0.3440 - accuracy: 0.85 - 124s 3s/step - loss: 0.3440 - accuracy: 0.8532 - val_loss: 0.7757 - val_accuracy: 0.5934\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 1.00 - ETA: 58s - loss: 0.1806 - accuracy: 0.950 - ETA: 1:15 - loss: 0.1836 - accuracy: 0.93 - ETA: 1:22 - loss: 0.2071 - accuracy: 0.90 - ETA: 1:25 - loss: 0.1963 - accuracy: 0.92 - ETA: 1:25 - loss: 0.2003 - accuracy: 0.90 - ETA: 1:25 - loss: 0.2075 - accuracy: 0.90 - ETA: 1:24 - loss: 0.3101 - accuracy: 0.88 - ETA: 1:22 - loss: 0.3052 - accuracy: 0.87 - ETA: 1:20 - loss: 0.2866 - accuracy: 0.89 - ETA: 1:18 - loss: 0.2861 - accuracy: 0.88 - ETA: 1:15 - loss: 0.2980 - accuracy: 0.88 - ETA: 1:13 - loss: 0.3040 - accuracy: 0.88 - ETA: 1:10 - loss: 0.3133 - accuracy: 0.87 - ETA: 1:08 - loss: 0.3030 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2931 - accuracy: 0.88 - ETA: 1:02 - loss: 0.2893 - accuracy: 0.88 - ETA: 59s - loss: 0.2931 - accuracy: 0.8778 - ETA: 56s - loss: 0.2975 - accuracy: 0.884 - ETA: 53s - loss: 0.2951 - accuracy: 0.885 - ETA: 50s - loss: 0.2941 - accuracy: 0.885 - ETA: 47s - loss: 0.2869 - accuracy: 0.890 - ETA: 44s - loss: 0.2828 - accuracy: 0.891 - ETA: 41s - loss: 0.2788 - accuracy: 0.895 - ETA: 38s - loss: 0.2873 - accuracy: 0.892 - ETA: 35s - loss: 0.2893 - accuracy: 0.892 - ETA: 31s - loss: 0.2810 - accuracy: 0.896 - ETA: 28s - loss: 0.2858 - accuracy: 0.896 - ETA: 25s - loss: 0.2850 - accuracy: 0.900 - ETA: 22s - loss: 0.2815 - accuracy: 0.896 - ETA: 19s - loss: 0.2796 - accuracy: 0.893 - ETA: 16s - loss: 0.2805 - accuracy: 0.890 - ETA: 13s - loss: 0.2771 - accuracy: 0.890 - ETA: 9s - loss: 0.2846 - accuracy: 0.882 - ETA: 6s - loss: 0.2791 - accuracy: 0.88 - ETA: 3s - loss: 0.2764 - accuracy: 0.88 - ETA: 0s - loss: 0.2813 - accuracy: 0.88 - 125s 3s/step - loss: 0.2813 - accuracy: 0.8809 - val_loss: 0.7738 - val_accuracy: 0.6374\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.60 - ETA: 1:00 - loss: 0.3657 - accuracy: 0.70 - ETA: 1:19 - loss: 0.3612 - accuracy: 0.73 - ETA: 1:27 - loss: 0.4011 - accuracy: 0.77 - ETA: 1:30 - loss: 0.3602 - accuracy: 0.82 - ETA: 1:31 - loss: 0.3383 - accuracy: 0.81 - ETA: 1:30 - loss: 0.3350 - accuracy: 0.82 - ETA: 1:29 - loss: 0.3279 - accuracy: 0.82 - ETA: 1:28 - loss: 0.3180 - accuracy: 0.80 - ETA: 1:27 - loss: 0.2938 - accuracy: 0.82 - ETA: 1:25 - loss: 0.2937 - accuracy: 0.80 - ETA: 1:23 - loss: 0.2814 - accuracy: 0.81 - ETA: 1:20 - loss: 0.3040 - accuracy: 0.80 - ETA: 1:16 - loss: 0.3226 - accuracy: 0.79 - ETA: 1:13 - loss: 0.3285 - accuracy: 0.79 - ETA: 1:09 - loss: 0.3199 - accuracy: 0.80 - ETA: 1:06 - loss: 0.3214 - accuracy: 0.80 - ETA: 1:03 - loss: 0.3173 - accuracy: 0.80 - ETA: 59s - loss: 0.3178 - accuracy: 0.8000 - ETA: 56s - loss: 0.3136 - accuracy: 0.805 - ETA: 53s - loss: 0.3103 - accuracy: 0.809 - ETA: 49s - loss: 0.3006 - accuracy: 0.818 - ETA: 46s - loss: 0.3032 - accuracy: 0.821 - ETA: 43s - loss: 0.2958 - accuracy: 0.829 - ETA: 40s - loss: 0.2866 - accuracy: 0.836 - ETA: 36s - loss: 0.2977 - accuracy: 0.826 - ETA: 33s - loss: 0.2930 - accuracy: 0.833 - ETA: 30s - loss: 0.3047 - accuracy: 0.825 - ETA: 26s - loss: 0.3088 - accuracy: 0.820 - ETA: 23s - loss: 0.3033 - accuracy: 0.823 - ETA: 20s - loss: 0.3041 - accuracy: 0.825 - ETA: 16s - loss: 0.3025 - accuracy: 0.828 - ETA: 13s - loss: 0.2977 - accuracy: 0.830 - ETA: 10s - loss: 0.2948 - accuracy: 0.829 - ETA: 6s - loss: 0.3052 - accuracy: 0.828 - ETA: 3s - loss: 0.3074 - accuracy: 0.82 - ETA: 0s - loss: 0.3076 - accuracy: 0.82 - 129s 3s/step - loss: 0.3076 - accuracy: 0.8255 - val_loss: 0.7682 - val_accuracy: 0.6593\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.6664 - accuracy: 0.80 - ETA: 58s - loss: 0.4438 - accuracy: 0.850 - ETA: 1:15 - loss: 0.3271 - accuracy: 0.90 - ETA: 1:22 - loss: 0.3333 - accuracy: 0.92 - ETA: 1:24 - loss: 0.3142 - accuracy: 0.94 - ETA: 1:25 - loss: 0.3408 - accuracy: 0.90 - ETA: 1:25 - loss: 0.3572 - accuracy: 0.90 - ETA: 1:24 - loss: 0.3329 - accuracy: 0.90 - ETA: 1:23 - loss: 0.3164 - accuracy: 0.90 - ETA: 1:21 - loss: 0.2962 - accuracy: 0.90 - ETA: 1:18 - loss: 0.3057 - accuracy: 0.88 - ETA: 1:16 - loss: 0.3015 - accuracy: 0.87 - ETA: 1:13 - loss: 0.3328 - accuracy: 0.85 - ETA: 1:11 - loss: 0.3236 - accuracy: 0.85 - ETA: 1:08 - loss: 0.3089 - accuracy: 0.86 - ETA: 1:05 - loss: 0.2967 - accuracy: 0.86 - ETA: 1:02 - loss: 0.2891 - accuracy: 0.86 - ETA: 59s - loss: 0.2841 - accuracy: 0.8667 - ETA: 56s - loss: 0.2884 - accuracy: 0.857 - ETA: 53s - loss: 0.2820 - accuracy: 0.860 - ETA: 50s - loss: 0.2808 - accuracy: 0.861 - ETA: 47s - loss: 0.3073 - accuracy: 0.854 - ETA: 44s - loss: 0.3080 - accuracy: 0.852 - ETA: 41s - loss: 0.3041 - accuracy: 0.854 - ETA: 38s - loss: 0.3116 - accuracy: 0.848 - ETA: 35s - loss: 0.3055 - accuracy: 0.853 - ETA: 31s - loss: 0.3348 - accuracy: 0.848 - ETA: 28s - loss: 0.3395 - accuracy: 0.842 - ETA: 25s - loss: 0.3306 - accuracy: 0.848 - ETA: 22s - loss: 0.3288 - accuracy: 0.846 - ETA: 19s - loss: 0.3305 - accuracy: 0.848 - ETA: 16s - loss: 0.3317 - accuracy: 0.846 - ETA: 12s - loss: 0.3292 - accuracy: 0.845 - ETA: 9s - loss: 0.3264 - accuracy: 0.850 - ETA: 6s - loss: 0.3233 - accuracy: 0.85 - ETA: 3s - loss: 0.3222 - accuracy: 0.85 - ETA: 0s - loss: 0.3224 - accuracy: 0.85 - 123s 3s/step - loss: 0.3224 - accuracy: 0.8532 - val_loss: 0.7758 - val_accuracy: 0.6703\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 1.00 - ETA: 57s - loss: 0.2155 - accuracy: 0.950 - ETA: 1:14 - loss: 0.2390 - accuracy: 0.90 - ETA: 1:21 - loss: 0.2295 - accuracy: 0.90 - ETA: 1:24 - loss: 0.2397 - accuracy: 0.88 - ETA: 1:25 - loss: 0.2464 - accuracy: 0.88 - ETA: 1:25 - loss: 0.2585 - accuracy: 0.87 - ETA: 1:24 - loss: 0.2323 - accuracy: 0.88 - ETA: 1:22 - loss: 0.3209 - accuracy: 0.87 - ETA: 1:20 - loss: 0.3181 - accuracy: 0.88 - ETA: 1:18 - loss: 0.3180 - accuracy: 0.85 - ETA: 1:15 - loss: 0.3101 - accuracy: 0.85 - ETA: 1:13 - loss: 0.3110 - accuracy: 0.85 - ETA: 1:10 - loss: 0.3045 - accuracy: 0.86 - ETA: 1:07 - loss: 0.2982 - accuracy: 0.86 - ETA: 1:05 - loss: 0.2870 - accuracy: 0.87 - ETA: 1:02 - loss: 0.2817 - accuracy: 0.87 - ETA: 59s - loss: 0.2853 - accuracy: 0.8833 - ETA: 56s - loss: 0.2858 - accuracy: 0.878 - ETA: 53s - loss: 0.3204 - accuracy: 0.870 - ETA: 50s - loss: 0.3130 - accuracy: 0.876 - ETA: 47s - loss: 0.3037 - accuracy: 0.881 - ETA: 44s - loss: 0.3009 - accuracy: 0.882 - ETA: 41s - loss: 0.3017 - accuracy: 0.879 - ETA: 38s - loss: 0.2983 - accuracy: 0.880 - ETA: 35s - loss: 0.2958 - accuracy: 0.880 - ETA: 31s - loss: 0.2989 - accuracy: 0.881 - ETA: 28s - loss: 0.3010 - accuracy: 0.875 - ETA: 25s - loss: 0.3129 - accuracy: 0.862 - ETA: 22s - loss: 0.3071 - accuracy: 0.860 - ETA: 19s - loss: 0.3090 - accuracy: 0.864 - ETA: 16s - loss: 0.3089 - accuracy: 0.856 - ETA: 12s - loss: 0.3180 - accuracy: 0.854 - ETA: 9s - loss: 0.3163 - accuracy: 0.858 - ETA: 6s - loss: 0.3241 - accuracy: 0.85 - ETA: 3s - loss: 0.3297 - accuracy: 0.84 - ETA: 0s - loss: 0.3298 - accuracy: 0.84 - 123s 3s/step - loss: 0.3298 - accuracy: 0.8476 - val_loss: 0.6855 - val_accuracy: 0.6484\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4691 - accuracy: 0.80 - ETA: 58s - loss: 1.3285 - accuracy: 0.650 - ETA: 1:15 - loss: 0.9507 - accuracy: 0.73 - ETA: 1:22 - loss: 0.7343 - accuracy: 0.80 - ETA: 1:25 - loss: 0.6956 - accuracy: 0.80 - ETA: 1:26 - loss: 0.6399 - accuracy: 0.80 - ETA: 1:25 - loss: 0.5769 - accuracy: 0.80 - ETA: 1:24 - loss: 0.5394 - accuracy: 0.82 - ETA: 1:23 - loss: 0.5143 - accuracy: 0.81 - ETA: 1:21 - loss: 0.5136 - accuracy: 0.81 - ETA: 1:19 - loss: 0.4803 - accuracy: 0.80 - ETA: 1:16 - loss: 0.4750 - accuracy: 0.80 - ETA: 1:13 - loss: 0.4732 - accuracy: 0.80 - ETA: 1:11 - loss: 0.4654 - accuracy: 0.80 - ETA: 1:08 - loss: 0.4451 - accuracy: 0.82 - ETA: 1:05 - loss: 0.4458 - accuracy: 0.81 - ETA: 1:02 - loss: 0.4286 - accuracy: 0.82 - ETA: 59s - loss: 0.4265 - accuracy: 0.8333 - ETA: 56s - loss: 0.4118 - accuracy: 0.842 - ETA: 53s - loss: 0.3968 - accuracy: 0.850 - ETA: 50s - loss: 0.3926 - accuracy: 0.857 - ETA: 47s - loss: 0.3795 - accuracy: 0.863 - ETA: 44s - loss: 0.3686 - accuracy: 0.869 - ETA: 41s - loss: 0.3702 - accuracy: 0.866 - ETA: 38s - loss: 0.3701 - accuracy: 0.864 - ETA: 35s - loss: 0.3716 - accuracy: 0.865 - ETA: 32s - loss: 0.3748 - accuracy: 0.863 - ETA: 28s - loss: 0.3686 - accuracy: 0.864 - ETA: 25s - loss: 0.3625 - accuracy: 0.865 - ETA: 22s - loss: 0.3625 - accuracy: 0.863 - ETA: 19s - loss: 0.3566 - accuracy: 0.864 - ETA: 16s - loss: 0.3539 - accuracy: 0.865 - ETA: 12s - loss: 0.3481 - accuracy: 0.869 - ETA: 9s - loss: 0.3445 - accuracy: 0.870 - ETA: 6s - loss: 0.3380 - accuracy: 0.87 - ETA: 3s - loss: 0.3357 - accuracy: 0.87 - ETA: 0s - loss: 0.3358 - accuracy: 0.87 - 124s 3s/step - loss: 0.3358 - accuracy: 0.8753 - val_loss: 0.7878 - val_accuracy: 0.6484\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1567 - accuracy: 1.00 - ETA: 59s - loss: 0.2299 - accuracy: 0.900 - ETA: 1:16 - loss: 0.2282 - accuracy: 0.86 - ETA: 1:23 - loss: 0.2387 - accuracy: 0.85 - ETA: 1:26 - loss: 0.2099 - accuracy: 0.86 - ETA: 1:26 - loss: 0.2063 - accuracy: 0.86 - ETA: 1:25 - loss: 0.1959 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2092 - accuracy: 0.87 - ETA: 1:23 - loss: 0.2124 - accuracy: 0.88 - ETA: 1:21 - loss: 0.3004 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2853 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2712 - accuracy: 0.88 - ETA: 1:13 - loss: 0.2614 - accuracy: 0.88 - ETA: 1:11 - loss: 0.2607 - accuracy: 0.88 - ETA: 1:08 - loss: 0.2546 - accuracy: 0.88 - ETA: 1:06 - loss: 0.2525 - accuracy: 0.88 - ETA: 1:03 - loss: 0.2619 - accuracy: 0.88 - ETA: 1:00 - loss: 0.2539 - accuracy: 0.88 - ETA: 57s - loss: 0.2460 - accuracy: 0.8947 - ETA: 54s - loss: 0.2436 - accuracy: 0.895 - ETA: 50s - loss: 0.3042 - accuracy: 0.881 - ETA: 47s - loss: 0.2955 - accuracy: 0.881 - ETA: 44s - loss: 0.2861 - accuracy: 0.887 - ETA: 41s - loss: 0.2922 - accuracy: 0.887 - ETA: 38s - loss: 0.2867 - accuracy: 0.892 - ETA: 35s - loss: 0.2813 - accuracy: 0.892 - ETA: 32s - loss: 0.2784 - accuracy: 0.892 - ETA: 29s - loss: 0.2877 - accuracy: 0.892 - ETA: 26s - loss: 0.2909 - accuracy: 0.886 - ETA: 22s - loss: 0.2867 - accuracy: 0.886 - ETA: 19s - loss: 0.2928 - accuracy: 0.880 - ETA: 16s - loss: 0.2934 - accuracy: 0.871 - ETA: 13s - loss: 0.2912 - accuracy: 0.872 - ETA: 9s - loss: 0.2879 - accuracy: 0.873 - ETA: 6s - loss: 0.2954 - accuracy: 0.86 - ETA: 3s - loss: 0.2886 - accuracy: 0.87 - ETA: 0s - loss: 0.2888 - accuracy: 0.87 - 128s 3s/step - loss: 0.2888 - accuracy: 0.8726 - val_loss: 0.7794 - val_accuracy: 0.6593\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.7465 - accuracy: 0.80 - ETA: 57s - loss: 0.4411 - accuracy: 0.850 - ETA: 1:15 - loss: 0.5805 - accuracy: 0.80 - ETA: 1:22 - loss: 0.5539 - accuracy: 0.80 - ETA: 1:25 - loss: 0.5110 - accuracy: 0.82 - ETA: 1:25 - loss: 0.4534 - accuracy: 0.85 - ETA: 1:26 - loss: 0.4230 - accuracy: 0.85 - ETA: 1:24 - loss: 0.4095 - accuracy: 0.86 - ETA: 1:23 - loss: 0.4158 - accuracy: 0.86 - ETA: 1:21 - loss: 0.4756 - accuracy: 0.87 - ETA: 1:19 - loss: 0.4421 - accuracy: 0.88 - ETA: 1:16 - loss: 0.4167 - accuracy: 0.88 - ETA: 1:13 - loss: 0.4170 - accuracy: 0.87 - ETA: 1:11 - loss: 0.3997 - accuracy: 0.87 - ETA: 1:08 - loss: 0.3769 - accuracy: 0.88 - ETA: 1:05 - loss: 0.3589 - accuracy: 0.89 - ETA: 1:02 - loss: 0.3423 - accuracy: 0.90 - ETA: 59s - loss: 0.3338 - accuracy: 0.8944 - ETA: 57s - loss: 0.3278 - accuracy: 0.889 - ETA: 54s - loss: 0.3176 - accuracy: 0.890 - ETA: 51s - loss: 0.3086 - accuracy: 0.890 - ETA: 48s - loss: 0.2973 - accuracy: 0.895 - ETA: 45s - loss: 0.3002 - accuracy: 0.891 - ETA: 42s - loss: 0.2924 - accuracy: 0.895 - ETA: 39s - loss: 0.2958 - accuracy: 0.896 - ETA: 36s - loss: 0.3052 - accuracy: 0.896 - ETA: 33s - loss: 0.3130 - accuracy: 0.892 - ETA: 29s - loss: 0.3163 - accuracy: 0.889 - ETA: 26s - loss: 0.3116 - accuracy: 0.886 - ETA: 23s - loss: 0.3053 - accuracy: 0.890 - ETA: 19s - loss: 0.3016 - accuracy: 0.887 - ETA: 16s - loss: 0.3000 - accuracy: 0.884 - ETA: 13s - loss: 0.3088 - accuracy: 0.884 - ETA: 9s - loss: 0.3061 - accuracy: 0.888 - ETA: 6s - loss: 0.3023 - accuracy: 0.88 - ETA: 3s - loss: 0.2952 - accuracy: 0.88 - ETA: 0s - loss: 0.3000 - accuracy: 0.88 - 127s 3s/step - loss: 0.3000 - accuracy: 0.8864 - val_loss: 0.7405 - val_accuracy: 0.6813\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 0.90 - ETA: 57s - loss: 0.1632 - accuracy: 0.900 - ETA: 1:14 - loss: 0.2059 - accuracy: 0.83 - ETA: 1:21 - loss: 0.2221 - accuracy: 0.82 - ETA: 1:24 - loss: 0.2194 - accuracy: 0.82 - ETA: 1:25 - loss: 0.2433 - accuracy: 0.83 - ETA: 1:24 - loss: 0.3157 - accuracy: 0.82 - ETA: 1:23 - loss: 0.4477 - accuracy: 0.82 - ETA: 1:22 - loss: 0.4152 - accuracy: 0.84 - ETA: 1:20 - loss: 0.4260 - accuracy: 0.84 - ETA: 1:18 - loss: 0.4064 - accuracy: 0.83 - ETA: 1:15 - loss: 0.3825 - accuracy: 0.85 - ETA: 1:13 - loss: 0.3803 - accuracy: 0.83 - ETA: 1:11 - loss: 0.3580 - accuracy: 0.85 - ETA: 1:08 - loss: 0.3436 - accuracy: 0.85 - ETA: 1:06 - loss: 0.3327 - accuracy: 0.85 - ETA: 1:04 - loss: 0.3227 - accuracy: 0.85 - ETA: 1:01 - loss: 0.3209 - accuracy: 0.85 - ETA: 59s - loss: 0.3135 - accuracy: 0.8526 - ETA: 56s - loss: 0.3081 - accuracy: 0.855 - ETA: 53s - loss: 0.3062 - accuracy: 0.852 - ETA: 50s - loss: 0.3012 - accuracy: 0.854 - ETA: 47s - loss: 0.2930 - accuracy: 0.860 - ETA: 43s - loss: 0.2910 - accuracy: 0.862 - ETA: 40s - loss: 0.2855 - accuracy: 0.868 - ETA: 36s - loss: 0.2862 - accuracy: 0.861 - ETA: 33s - loss: 0.2915 - accuracy: 0.855 - ETA: 30s - loss: 0.2913 - accuracy: 0.857 - ETA: 26s - loss: 0.2962 - accuracy: 0.858 - ETA: 23s - loss: 0.2911 - accuracy: 0.863 - ETA: 20s - loss: 0.2859 - accuracy: 0.864 - ETA: 16s - loss: 0.2982 - accuracy: 0.862 - ETA: 13s - loss: 0.3036 - accuracy: 0.863 - ETA: 10s - loss: 0.3004 - accuracy: 0.861 - ETA: 6s - loss: 0.3053 - accuracy: 0.854 - ETA: 3s - loss: 0.3001 - accuracy: 0.85 - ETA: 0s - loss: 0.3050 - accuracy: 0.85 - 128s 3s/step - loss: 0.3050 - accuracy: 0.8560 - val_loss: 0.6865 - val_accuracy: 0.6703\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2068 - accuracy: 1.00 - ETA: 58s - loss: 0.4256 - accuracy: 0.850 - ETA: 1:14 - loss: 0.3330 - accuracy: 0.90 - ETA: 1:21 - loss: 0.2987 - accuracy: 0.87 - ETA: 1:24 - loss: 0.2835 - accuracy: 0.86 - ETA: 1:25 - loss: 0.3031 - accuracy: 0.85 - ETA: 1:25 - loss: 0.3875 - accuracy: 0.81 - ETA: 1:23 - loss: 0.4043 - accuracy: 0.81 - ETA: 1:22 - loss: 0.3828 - accuracy: 0.82 - ETA: 1:20 - loss: 0.3605 - accuracy: 0.84 - ETA: 1:18 - loss: 0.3443 - accuracy: 0.84 - ETA: 1:15 - loss: 0.3357 - accuracy: 0.85 - ETA: 1:13 - loss: 0.3596 - accuracy: 0.83 - ETA: 1:10 - loss: 0.3411 - accuracy: 0.84 - ETA: 1:08 - loss: 0.3306 - accuracy: 0.84 - ETA: 1:05 - loss: 0.3171 - accuracy: 0.85 - ETA: 1:02 - loss: 0.3051 - accuracy: 0.85 - ETA: 59s - loss: 0.2967 - accuracy: 0.8556 - ETA: 56s - loss: 0.2918 - accuracy: 0.857 - ETA: 54s - loss: 0.2852 - accuracy: 0.860 - ETA: 51s - loss: 0.3380 - accuracy: 0.857 - ETA: 48s - loss: 0.3272 - accuracy: 0.863 - ETA: 45s - loss: 0.3184 - accuracy: 0.865 - ETA: 42s - loss: 0.3265 - accuracy: 0.862 - ETA: 39s - loss: 0.3350 - accuracy: 0.856 - ETA: 35s - loss: 0.3273 - accuracy: 0.857 - ETA: 32s - loss: 0.3182 - accuracy: 0.863 - ETA: 29s - loss: 0.3186 - accuracy: 0.853 - ETA: 26s - loss: 0.3133 - accuracy: 0.858 - ETA: 23s - loss: 0.3167 - accuracy: 0.860 - ETA: 19s - loss: 0.3126 - accuracy: 0.864 - ETA: 16s - loss: 0.3106 - accuracy: 0.865 - ETA: 13s - loss: 0.3231 - accuracy: 0.860 - ETA: 9s - loss: 0.3294 - accuracy: 0.861 - ETA: 6s - loss: 0.3261 - accuracy: 0.86 - ETA: 3s - loss: 0.3240 - accuracy: 0.86 - ETA: 0s - loss: 0.3242 - accuracy: 0.86 - 127s 3s/step - loss: 0.3242 - accuracy: 0.8615 - val_loss: 0.7834 - val_accuracy: 0.6484\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 1.00 - ETA: 58s - loss: 0.2774 - accuracy: 0.850 - ETA: 1:15 - loss: 0.2278 - accuracy: 0.86 - ETA: 1:22 - loss: 0.1902 - accuracy: 0.90 - ETA: 1:24 - loss: 0.2027 - accuracy: 0.92 - ETA: 1:25 - loss: 0.1956 - accuracy: 0.91 - ETA: 1:25 - loss: 0.1850 - accuracy: 0.92 - ETA: 1:24 - loss: 0.1800 - accuracy: 0.93 - ETA: 1:22 - loss: 0.1901 - accuracy: 0.93 - ETA: 1:20 - loss: 0.1851 - accuracy: 0.94 - ETA: 1:18 - loss: 0.1879 - accuracy: 0.92 - ETA: 1:16 - loss: 0.1867 - accuracy: 0.91 - ETA: 1:13 - loss: 0.1808 - accuracy: 0.92 - ETA: 1:10 - loss: 0.1752 - accuracy: 0.92 - ETA: 1:08 - loss: 0.1723 - accuracy: 0.93 - ETA: 1:05 - loss: 0.1808 - accuracy: 0.93 - ETA: 1:02 - loss: 0.1866 - accuracy: 0.94 - ETA: 59s - loss: 0.1900 - accuracy: 0.9278 - ETA: 56s - loss: 0.1862 - accuracy: 0.931 - ETA: 53s - loss: 0.1885 - accuracy: 0.930 - ETA: 50s - loss: 0.2014 - accuracy: 0.923 - ETA: 47s - loss: 0.2018 - accuracy: 0.918 - ETA: 44s - loss: 0.2027 - accuracy: 0.917 - ETA: 41s - loss: 0.2088 - accuracy: 0.916 - ETA: 38s - loss: 0.2146 - accuracy: 0.912 - ETA: 35s - loss: 0.2128 - accuracy: 0.911 - ETA: 31s - loss: 0.2343 - accuracy: 0.907 - ETA: 28s - loss: 0.2367 - accuracy: 0.903 - ETA: 25s - loss: 0.2383 - accuracy: 0.900 - ETA: 22s - loss: 0.2327 - accuracy: 0.903 - ETA: 19s - loss: 0.2285 - accuracy: 0.906 - ETA: 16s - loss: 0.2282 - accuracy: 0.906 - ETA: 12s - loss: 0.2273 - accuracy: 0.906 - ETA: 9s - loss: 0.2264 - accuracy: 0.908 - ETA: 6s - loss: 0.2277 - accuracy: 0.90 - ETA: 3s - loss: 0.2450 - accuracy: 0.90 - ETA: 0s - loss: 0.2453 - accuracy: 0.90 - 124s 3s/step - loss: 0.2453 - accuracy: 0.9003 - val_loss: 0.7767 - val_accuracy: 0.6264\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1672 - accuracy: 1.00 - ETA: 57s - loss: 0.1800 - accuracy: 1.000 - ETA: 1:14 - loss: 0.2992 - accuracy: 0.93 - ETA: 1:21 - loss: 0.3621 - accuracy: 0.90 - ETA: 1:24 - loss: 0.4137 - accuracy: 0.86 - ETA: 1:25 - loss: 0.5122 - accuracy: 0.83 - ETA: 1:24 - loss: 0.5099 - accuracy: 0.82 - ETA: 1:23 - loss: 0.4933 - accuracy: 0.83 - ETA: 1:22 - loss: 0.4601 - accuracy: 0.83 - ETA: 1:20 - loss: 0.4350 - accuracy: 0.85 - ETA: 1:18 - loss: 0.4197 - accuracy: 0.85 - ETA: 1:15 - loss: 0.3985 - accuracy: 0.85 - ETA: 1:13 - loss: 0.3818 - accuracy: 0.86 - ETA: 1:11 - loss: 0.3660 - accuracy: 0.86 - ETA: 1:08 - loss: 0.3628 - accuracy: 0.86 - ETA: 1:06 - loss: 0.3546 - accuracy: 0.85 - ETA: 1:03 - loss: 0.3401 - accuracy: 0.86 - ETA: 1:00 - loss: 0.3238 - accuracy: 0.87 - ETA: 57s - loss: 0.3113 - accuracy: 0.8789 - ETA: 54s - loss: 0.3175 - accuracy: 0.865 - ETA: 51s - loss: 0.3058 - accuracy: 0.871 - ETA: 49s - loss: 0.2984 - accuracy: 0.877 - ETA: 46s - loss: 0.2960 - accuracy: 0.873 - ETA: 43s - loss: 0.2906 - accuracy: 0.879 - ETA: 39s - loss: 0.2896 - accuracy: 0.880 - ETA: 36s - loss: 0.2920 - accuracy: 0.869 - ETA: 33s - loss: 0.2868 - accuracy: 0.874 - ETA: 29s - loss: 0.2986 - accuracy: 0.860 - ETA: 26s - loss: 0.3006 - accuracy: 0.862 - ETA: 23s - loss: 0.3477 - accuracy: 0.860 - ETA: 19s - loss: 0.3446 - accuracy: 0.861 - ETA: 16s - loss: 0.3358 - accuracy: 0.865 - ETA: 13s - loss: 0.3414 - accuracy: 0.863 - ETA: 9s - loss: 0.3387 - accuracy: 0.867 - ETA: 6s - loss: 0.3326 - accuracy: 0.86 - ETA: 3s - loss: 0.3327 - accuracy: 0.86 - ETA: 0s - loss: 0.3328 - accuracy: 0.86 - 127s 3s/step - loss: 0.3328 - accuracy: 0.8670 - val_loss: 0.7226 - val_accuracy: 0.6484\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.70 - ETA: 57s - loss: 0.1601 - accuracy: 0.850 - ETA: 1:14 - loss: 0.1473 - accuracy: 0.86 - ETA: 1:21 - loss: 0.1956 - accuracy: 0.87 - ETA: 1:24 - loss: 0.2070 - accuracy: 0.84 - ETA: 1:25 - loss: 0.2059 - accuracy: 0.86 - ETA: 1:25 - loss: 0.2614 - accuracy: 0.85 - ETA: 1:24 - loss: 0.2545 - accuracy: 0.85 - ETA: 1:23 - loss: 0.2532 - accuracy: 0.83 - ETA: 1:21 - loss: 0.2483 - accuracy: 0.85 - ETA: 1:19 - loss: 0.2495 - accuracy: 0.85 - ETA: 1:16 - loss: 0.2472 - accuracy: 0.86 - ETA: 1:14 - loss: 0.2368 - accuracy: 0.87 - ETA: 1:11 - loss: 0.2357 - accuracy: 0.87 - ETA: 1:08 - loss: 0.2444 - accuracy: 0.87 - ETA: 1:06 - loss: 0.2380 - accuracy: 0.88 - ETA: 1:03 - loss: 0.2373 - accuracy: 0.87 - ETA: 1:00 - loss: 0.2339 - accuracy: 0.87 - ETA: 57s - loss: 0.2268 - accuracy: 0.8789 - ETA: 54s - loss: 0.2260 - accuracy: 0.880 - ETA: 51s - loss: 0.2224 - accuracy: 0.881 - ETA: 47s - loss: 0.2165 - accuracy: 0.886 - ETA: 44s - loss: 0.2121 - accuracy: 0.891 - ETA: 41s - loss: 0.2147 - accuracy: 0.879 - ETA: 38s - loss: 0.2164 - accuracy: 0.876 - ETA: 35s - loss: 0.2134 - accuracy: 0.880 - ETA: 32s - loss: 0.2125 - accuracy: 0.881 - ETA: 28s - loss: 0.2104 - accuracy: 0.885 - ETA: 25s - loss: 0.2151 - accuracy: 0.886 - ETA: 22s - loss: 0.2248 - accuracy: 0.883 - ETA: 19s - loss: 0.2287 - accuracy: 0.887 - ETA: 16s - loss: 0.2298 - accuracy: 0.887 - ETA: 12s - loss: 0.2325 - accuracy: 0.887 - ETA: 9s - loss: 0.2334 - accuracy: 0.888 - ETA: 6s - loss: 0.2368 - accuracy: 0.88 - ETA: 3s - loss: 0.2379 - accuracy: 0.87 - ETA: 0s - loss: 0.2382 - accuracy: 0.87 - 124s 3s/step - loss: 0.2382 - accuracy: 0.8781 - val_loss: 0.7582 - val_accuracy: 0.6703\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.8490 - accuracy: 0.90 - ETA: 57s - loss: 0.5411 - accuracy: 0.850 - ETA: 1:14 - loss: 0.4017 - accuracy: 0.90 - ETA: 1:21 - loss: 0.3327 - accuracy: 0.90 - ETA: 1:24 - loss: 0.4041 - accuracy: 0.86 - ETA: 1:24 - loss: 0.3869 - accuracy: 0.83 - ETA: 1:24 - loss: 0.3670 - accuracy: 0.84 - ETA: 1:23 - loss: 0.4425 - accuracy: 0.85 - ETA: 1:21 - loss: 0.5461 - accuracy: 0.81 - ETA: 1:19 - loss: 0.5268 - accuracy: 0.82 - ETA: 1:17 - loss: 0.5226 - accuracy: 0.80 - ETA: 1:14 - loss: 0.4933 - accuracy: 0.81 - ETA: 1:12 - loss: 0.4691 - accuracy: 0.83 - ETA: 1:09 - loss: 0.4506 - accuracy: 0.83 - ETA: 1:06 - loss: 0.4453 - accuracy: 0.84 - ETA: 1:04 - loss: 0.4350 - accuracy: 0.84 - ETA: 1:01 - loss: 0.4324 - accuracy: 0.85 - ETA: 58s - loss: 0.4112 - accuracy: 0.8611 - ETA: 55s - loss: 0.3940 - accuracy: 0.863 - ETA: 52s - loss: 0.3878 - accuracy: 0.860 - ETA: 49s - loss: 0.3746 - accuracy: 0.861 - ETA: 46s - loss: 0.3641 - accuracy: 0.868 - ETA: 43s - loss: 0.3537 - accuracy: 0.873 - ETA: 40s - loss: 0.3512 - accuracy: 0.870 - ETA: 37s - loss: 0.3507 - accuracy: 0.868 - ETA: 34s - loss: 0.3495 - accuracy: 0.869 - ETA: 31s - loss: 0.3401 - accuracy: 0.874 - ETA: 28s - loss: 0.3348 - accuracy: 0.878 - ETA: 25s - loss: 0.3319 - accuracy: 0.879 - ETA: 22s - loss: 0.3283 - accuracy: 0.880 - ETA: 19s - loss: 0.3583 - accuracy: 0.877 - ETA: 16s - loss: 0.3511 - accuracy: 0.881 - ETA: 12s - loss: 0.3453 - accuracy: 0.878 - ETA: 9s - loss: 0.3442 - accuracy: 0.879 - ETA: 6s - loss: 0.3424 - accuracy: 0.87 - ETA: 3s - loss: 0.3411 - accuracy: 0.87 - ETA: 0s - loss: 0.3458 - accuracy: 0.87 - 123s 3s/step - loss: 0.3458 - accuracy: 0.8753 - val_loss: 0.7469 - val_accuracy: 0.6593\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.90 - ETA: 57s - loss: 0.2268 - accuracy: 0.950 - ETA: 1:14 - loss: 0.2010 - accuracy: 0.96 - ETA: 1:21 - loss: 0.2905 - accuracy: 0.95 - ETA: 1:25 - loss: 0.2707 - accuracy: 0.94 - ETA: 1:25 - loss: 0.2537 - accuracy: 0.95 - ETA: 1:25 - loss: 0.2647 - accuracy: 0.92 - ETA: 1:24 - loss: 0.2611 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2449 - accuracy: 0.91 - ETA: 1:20 - loss: 0.2331 - accuracy: 0.91 - ETA: 1:18 - loss: 0.2331 - accuracy: 0.91 - ETA: 1:16 - loss: 0.2611 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2527 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2565 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2624 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2557 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2486 - accuracy: 0.91 - ETA: 59s - loss: 0.2411 - accuracy: 0.9167 - ETA: 56s - loss: 0.2390 - accuracy: 0.915 - ETA: 53s - loss: 0.2392 - accuracy: 0.905 - ETA: 50s - loss: 0.2498 - accuracy: 0.890 - ETA: 47s - loss: 0.2582 - accuracy: 0.886 - ETA: 44s - loss: 0.2571 - accuracy: 0.887 - ETA: 41s - loss: 0.2514 - accuracy: 0.887 - ETA: 38s - loss: 0.2422 - accuracy: 0.892 - ETA: 35s - loss: 0.2562 - accuracy: 0.888 - ETA: 32s - loss: 0.2512 - accuracy: 0.888 - ETA: 28s - loss: 0.2658 - accuracy: 0.885 - ETA: 25s - loss: 0.2609 - accuracy: 0.889 - ETA: 22s - loss: 0.2591 - accuracy: 0.886 - ETA: 19s - loss: 0.2564 - accuracy: 0.887 - ETA: 16s - loss: 0.2511 - accuracy: 0.887 - ETA: 12s - loss: 0.2532 - accuracy: 0.881 - ETA: 9s - loss: 0.2501 - accuracy: 0.885 - ETA: 6s - loss: 0.2457 - accuracy: 0.88 - ETA: 3s - loss: 0.2549 - accuracy: 0.88 - ETA: 0s - loss: 0.2552 - accuracy: 0.88 - 124s 3s/step - loss: 0.2552 - accuracy: 0.8809 - val_loss: 0.7901 - val_accuracy: 0.6044\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1870 - accuracy: 0.90 - ETA: 58s - loss: 0.2407 - accuracy: 0.800 - ETA: 1:15 - loss: 0.2759 - accuracy: 0.80 - ETA: 1:22 - loss: 0.3067 - accuracy: 0.85 - ETA: 1:24 - loss: 0.2760 - accuracy: 0.88 - ETA: 1:25 - loss: 0.2592 - accuracy: 0.86 - ETA: 1:25 - loss: 0.2556 - accuracy: 0.87 - ETA: 1:23 - loss: 0.2324 - accuracy: 0.88 - ETA: 1:22 - loss: 0.2281 - accuracy: 0.88 - ETA: 1:20 - loss: 0.2207 - accuracy: 0.90 - ETA: 1:18 - loss: 0.2084 - accuracy: 0.90 - ETA: 1:15 - loss: 0.2079 - accuracy: 0.90 - ETA: 1:13 - loss: 0.2185 - accuracy: 0.90 - ETA: 1:10 - loss: 0.2264 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2349 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2312 - accuracy: 0.88 - ETA: 1:02 - loss: 0.2222 - accuracy: 0.89 - ETA: 59s - loss: 0.2234 - accuracy: 0.8889 - ETA: 56s - loss: 0.2251 - accuracy: 0.884 - ETA: 53s - loss: 0.2178 - accuracy: 0.890 - ETA: 50s - loss: 0.2132 - accuracy: 0.895 - ETA: 47s - loss: 0.2199 - accuracy: 0.900 - ETA: 44s - loss: 0.2359 - accuracy: 0.895 - ETA: 41s - loss: 0.2391 - accuracy: 0.900 - ETA: 38s - loss: 0.2647 - accuracy: 0.896 - ETA: 35s - loss: 0.2590 - accuracy: 0.900 - ETA: 31s - loss: 0.2590 - accuracy: 0.900 - ETA: 28s - loss: 0.2556 - accuracy: 0.896 - ETA: 25s - loss: 0.2528 - accuracy: 0.896 - ETA: 22s - loss: 0.2584 - accuracy: 0.893 - ETA: 19s - loss: 0.2619 - accuracy: 0.893 - ETA: 16s - loss: 0.2549 - accuracy: 0.896 - ETA: 12s - loss: 0.2515 - accuracy: 0.897 - ETA: 9s - loss: 0.2512 - accuracy: 0.897 - ETA: 6s - loss: 0.2465 - accuracy: 0.90 - ETA: 3s - loss: 0.2569 - accuracy: 0.90 - ETA: 0s - loss: 0.2572 - accuracy: 0.90 - 123s 3s/step - loss: 0.2572 - accuracy: 0.9003 - val_loss: 0.7682 - val_accuracy: 0.6593\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3080 - accuracy: 0.90 - ETA: 59s - loss: 0.2191 - accuracy: 0.950 - ETA: 1:18 - loss: 0.2051 - accuracy: 0.93 - ETA: 1:25 - loss: 0.2594 - accuracy: 0.92 - ETA: 1:29 - loss: 0.2211 - accuracy: 0.94 - ETA: 1:30 - loss: 0.2472 - accuracy: 0.91 - ETA: 1:30 - loss: 0.2263 - accuracy: 0.91 - ETA: 1:29 - loss: 0.2421 - accuracy: 0.90 - ETA: 1:27 - loss: 0.2305 - accuracy: 0.91 - ETA: 1:25 - loss: 0.2165 - accuracy: 0.92 - ETA: 1:22 - loss: 0.2075 - accuracy: 0.91 - ETA: 1:20 - loss: 0.2166 - accuracy: 0.91 - ETA: 1:17 - loss: 0.2238 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2144 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2121 - accuracy: 0.90 - ETA: 1:07 - loss: 0.2221 - accuracy: 0.90 - ETA: 1:04 - loss: 0.2149 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2207 - accuracy: 0.90 - ETA: 58s - loss: 0.2260 - accuracy: 0.8895 - ETA: 55s - loss: 0.2179 - accuracy: 0.895 - ETA: 52s - loss: 0.2172 - accuracy: 0.885 - ETA: 48s - loss: 0.2136 - accuracy: 0.886 - ETA: 45s - loss: 0.2178 - accuracy: 0.882 - ETA: 42s - loss: 0.2253 - accuracy: 0.879 - ETA: 39s - loss: 0.2218 - accuracy: 0.884 - ETA: 35s - loss: 0.2371 - accuracy: 0.880 - ETA: 32s - loss: 0.2343 - accuracy: 0.885 - ETA: 29s - loss: 0.2307 - accuracy: 0.885 - ETA: 26s - loss: 0.2281 - accuracy: 0.886 - ETA: 22s - loss: 0.2273 - accuracy: 0.890 - ETA: 19s - loss: 0.2271 - accuracy: 0.887 - ETA: 16s - loss: 0.2248 - accuracy: 0.890 - ETA: 13s - loss: 0.2248 - accuracy: 0.890 - ETA: 9s - loss: 0.2291 - accuracy: 0.888 - ETA: 6s - loss: 0.2295 - accuracy: 0.88 - ETA: 3s - loss: 0.2343 - accuracy: 0.88 - ETA: 0s - loss: 0.2346 - accuracy: 0.88 - 125s 3s/step - loss: 0.2346 - accuracy: 0.8809 - val_loss: 0.7823 - val_accuracy: 0.6923\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 1.00 - ETA: 57s - loss: 0.1249 - accuracy: 0.950 - ETA: 1:15 - loss: 0.1079 - accuracy: 0.96 - ETA: 1:21 - loss: 0.1204 - accuracy: 0.95 - ETA: 1:24 - loss: 0.1241 - accuracy: 0.94 - ETA: 1:24 - loss: 0.1438 - accuracy: 0.93 - ETA: 1:24 - loss: 0.2272 - accuracy: 0.90 - ETA: 1:23 - loss: 0.2036 - accuracy: 0.91 - ETA: 1:21 - loss: 0.2167 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2153 - accuracy: 0.90 - ETA: 1:17 - loss: 0.2085 - accuracy: 0.90 - ETA: 1:15 - loss: 0.2170 - accuracy: 0.90 - ETA: 1:13 - loss: 0.2111 - accuracy: 0.90 - ETA: 1:10 - loss: 0.2231 - accuracy: 0.88 - ETA: 1:07 - loss: 0.2289 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2247 - accuracy: 0.88 - ETA: 1:02 - loss: 0.2654 - accuracy: 0.88 - ETA: 59s - loss: 0.2722 - accuracy: 0.8833 - ETA: 56s - loss: 0.2698 - accuracy: 0.884 - ETA: 53s - loss: 0.2844 - accuracy: 0.885 - ETA: 50s - loss: 0.2860 - accuracy: 0.876 - ETA: 47s - loss: 0.2812 - accuracy: 0.877 - ETA: 44s - loss: 0.2949 - accuracy: 0.869 - ETA: 41s - loss: 0.2984 - accuracy: 0.866 - ETA: 38s - loss: 0.2898 - accuracy: 0.872 - ETA: 35s - loss: 0.2814 - accuracy: 0.876 - ETA: 31s - loss: 0.2853 - accuracy: 0.874 - ETA: 28s - loss: 0.2819 - accuracy: 0.875 - ETA: 25s - loss: 0.2769 - accuracy: 0.879 - ETA: 22s - loss: 0.2717 - accuracy: 0.883 - ETA: 19s - loss: 0.2689 - accuracy: 0.883 - ETA: 15s - loss: 0.2641 - accuracy: 0.887 - ETA: 12s - loss: 0.2608 - accuracy: 0.887 - ETA: 9s - loss: 0.2581 - accuracy: 0.888 - ETA: 6s - loss: 0.2522 - accuracy: 0.89 - ETA: 3s - loss: 0.2493 - accuracy: 0.89 - ETA: 0s - loss: 0.2496 - accuracy: 0.89 - 123s 3s/step - loss: 0.2496 - accuracy: 0.8947 - val_loss: 0.7066 - val_accuracy: 0.6484\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.90 - ETA: 56s - loss: 0.1247 - accuracy: 0.900 - ETA: 1:13 - loss: 0.1783 - accuracy: 0.83 - ETA: 1:19 - loss: 0.2009 - accuracy: 0.80 - ETA: 1:22 - loss: 0.3596 - accuracy: 0.78 - ETA: 1:23 - loss: 0.3413 - accuracy: 0.80 - ETA: 1:22 - loss: 0.3116 - accuracy: 0.82 - ETA: 1:22 - loss: 0.3650 - accuracy: 0.83 - ETA: 1:20 - loss: 0.3480 - accuracy: 0.84 - ETA: 1:18 - loss: 0.3305 - accuracy: 0.86 - ETA: 1:16 - loss: 0.3175 - accuracy: 0.85 - ETA: 1:14 - loss: 0.2964 - accuracy: 0.86 - ETA: 1:11 - loss: 0.3005 - accuracy: 0.87 - ETA: 1:09 - loss: 0.2822 - accuracy: 0.88 - ETA: 1:06 - loss: 0.2770 - accuracy: 0.88 - ETA: 1:04 - loss: 0.2725 - accuracy: 0.87 - ETA: 1:01 - loss: 0.2782 - accuracy: 0.87 - ETA: 58s - loss: 0.2695 - accuracy: 0.8778 - ETA: 55s - loss: 0.2675 - accuracy: 0.873 - ETA: 52s - loss: 0.2606 - accuracy: 0.875 - ETA: 49s - loss: 0.2610 - accuracy: 0.876 - ETA: 46s - loss: 0.2573 - accuracy: 0.877 - ETA: 43s - loss: 0.2568 - accuracy: 0.873 - ETA: 40s - loss: 0.2518 - accuracy: 0.875 - ETA: 37s - loss: 0.2513 - accuracy: 0.876 - ETA: 34s - loss: 0.2461 - accuracy: 0.876 - ETA: 32s - loss: 0.2433 - accuracy: 0.874 - ETA: 29s - loss: 0.2415 - accuracy: 0.878 - ETA: 25s - loss: 0.2388 - accuracy: 0.879 - ETA: 22s - loss: 0.2433 - accuracy: 0.876 - ETA: 19s - loss: 0.2383 - accuracy: 0.880 - ETA: 16s - loss: 0.2340 - accuracy: 0.881 - ETA: 13s - loss: 0.2436 - accuracy: 0.878 - ETA: 10s - loss: 0.2384 - accuracy: 0.882 - ETA: 6s - loss: 0.2423 - accuracy: 0.880 - ETA: 3s - loss: 0.2394 - accuracy: 0.88 - ETA: 0s - loss: 0.2398 - accuracy: 0.88 - 129s 3s/step - loss: 0.2398 - accuracy: 0.8837 - val_loss: 0.7396 - val_accuracy: 0.6484\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2358 - accuracy: 0.80 - ETA: 1:04 - loss: 0.1891 - accuracy: 0.90 - ETA: 1:22 - loss: 0.2463 - accuracy: 0.86 - ETA: 1:30 - loss: 0.2611 - accuracy: 0.87 - ETA: 1:32 - loss: 0.2314 - accuracy: 0.88 - ETA: 1:33 - loss: 0.2489 - accuracy: 0.85 - ETA: 1:33 - loss: 0.2388 - accuracy: 0.85 - ETA: 1:32 - loss: 0.2552 - accuracy: 0.87 - ETA: 1:30 - loss: 0.2550 - accuracy: 0.86 - ETA: 1:29 - loss: 0.2515 - accuracy: 0.87 - ETA: 1:26 - loss: 0.2524 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2462 - accuracy: 0.88 - ETA: 1:22 - loss: 0.2497 - accuracy: 0.86 - ETA: 1:19 - loss: 0.2502 - accuracy: 0.85 - ETA: 1:16 - loss: 0.2392 - accuracy: 0.86 - ETA: 1:13 - loss: 0.2509 - accuracy: 0.85 - ETA: 1:10 - loss: 0.2448 - accuracy: 0.85 - ETA: 1:07 - loss: 0.2514 - accuracy: 0.85 - ETA: 1:04 - loss: 0.2439 - accuracy: 0.85 - ETA: 1:01 - loss: 0.2363 - accuracy: 0.86 - ETA: 58s - loss: 0.2344 - accuracy: 0.8714 - ETA: 54s - loss: 0.2377 - accuracy: 0.872 - ETA: 51s - loss: 0.2410 - accuracy: 0.869 - ETA: 47s - loss: 0.2558 - accuracy: 0.866 - ETA: 44s - loss: 0.2499 - accuracy: 0.868 - ETA: 40s - loss: 0.2473 - accuracy: 0.869 - ETA: 36s - loss: 0.2463 - accuracy: 0.870 - ETA: 33s - loss: 0.2461 - accuracy: 0.875 - ETA: 29s - loss: 0.2448 - accuracy: 0.875 - ETA: 25s - loss: 0.2520 - accuracy: 0.873 - ETA: 22s - loss: 0.2463 - accuracy: 0.877 - ETA: 18s - loss: 0.2438 - accuracy: 0.881 - ETA: 14s - loss: 0.2459 - accuracy: 0.878 - ETA: 11s - loss: 0.2400 - accuracy: 0.882 - ETA: 7s - loss: 0.2434 - accuracy: 0.880 - ETA: 3s - loss: 0.2388 - accuracy: 0.88 - ETA: 0s - loss: 0.2391 - accuracy: 0.88 - 142s 4s/step - loss: 0.2391 - accuracy: 0.8837 - val_loss: 0.7067 - val_accuracy: 0.6813\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2117 - accuracy: 0.80 - ETA: 1:04 - loss: 0.1883 - accuracy: 0.80 - ETA: 1:23 - loss: 0.2750 - accuracy: 0.73 - ETA: 1:30 - loss: 0.2848 - accuracy: 0.75 - ETA: 1:35 - loss: 0.2645 - accuracy: 0.80 - ETA: 1:36 - loss: 0.3266 - accuracy: 0.81 - ETA: 1:36 - loss: 0.2880 - accuracy: 0.84 - ETA: 1:36 - loss: 0.2650 - accuracy: 0.86 - ETA: 1:35 - loss: 0.2583 - accuracy: 0.85 - ETA: 1:34 - loss: 0.2485 - accuracy: 0.87 - ETA: 1:31 - loss: 0.2499 - accuracy: 0.88 - ETA: 1:29 - loss: 0.2424 - accuracy: 0.88 - ETA: 1:26 - loss: 0.2294 - accuracy: 0.89 - ETA: 1:23 - loss: 0.2193 - accuracy: 0.90 - ETA: 1:20 - loss: 0.2105 - accuracy: 0.90 - ETA: 1:16 - loss: 0.2076 - accuracy: 0.90 - ETA: 1:13 - loss: 0.2087 - accuracy: 0.90 - ETA: 1:09 - loss: 0.1996 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2138 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2090 - accuracy: 0.91 - ETA: 59s - loss: 0.2140 - accuracy: 0.9095 - ETA: 55s - loss: 0.2189 - accuracy: 0.904 - ETA: 52s - loss: 0.2317 - accuracy: 0.904 - ETA: 48s - loss: 0.2278 - accuracy: 0.908 - ETA: 44s - loss: 0.2274 - accuracy: 0.904 - ETA: 41s - loss: 0.2214 - accuracy: 0.907 - ETA: 37s - loss: 0.2180 - accuracy: 0.911 - ETA: 33s - loss: 0.2161 - accuracy: 0.910 - ETA: 30s - loss: 0.2152 - accuracy: 0.910 - ETA: 26s - loss: 0.2148 - accuracy: 0.910 - ETA: 22s - loss: 0.2200 - accuracy: 0.906 - ETA: 18s - loss: 0.2184 - accuracy: 0.906 - ETA: 15s - loss: 0.2194 - accuracy: 0.906 - ETA: 11s - loss: 0.2154 - accuracy: 0.908 - ETA: 7s - loss: 0.2151 - accuracy: 0.908 - ETA: 3s - loss: 0.2118 - accuracy: 0.91 - ETA: 0s - loss: 0.2122 - accuracy: 0.91 - 144s 4s/step - loss: 0.2122 - accuracy: 0.9114 - val_loss: 0.7594 - val_accuracy: 0.6813\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.9130 - accuracy: 0.70 - ETA: 1:04 - loss: 0.5293 - accuracy: 0.75 - ETA: 1:24 - loss: 0.3865 - accuracy: 0.80 - ETA: 1:31 - loss: 0.3772 - accuracy: 0.77 - ETA: 1:35 - loss: 0.4142 - accuracy: 0.78 - ETA: 1:38 - loss: 0.3793 - accuracy: 0.78 - ETA: 1:39 - loss: 0.3475 - accuracy: 0.78 - ETA: 1:38 - loss: 0.3793 - accuracy: 0.78 - ETA: 1:36 - loss: 0.3588 - accuracy: 0.80 - ETA: 1:34 - loss: 0.3658 - accuracy: 0.81 - ETA: 1:32 - loss: 0.3415 - accuracy: 0.81 - ETA: 1:29 - loss: 0.3334 - accuracy: 0.81 - ETA: 1:26 - loss: 0.3208 - accuracy: 0.82 - ETA: 1:23 - loss: 0.3091 - accuracy: 0.82 - ETA: 1:20 - loss: 0.2963 - accuracy: 0.84 - ETA: 1:16 - loss: 0.3098 - accuracy: 0.83 - ETA: 1:13 - loss: 0.3170 - accuracy: 0.83 - ETA: 1:09 - loss: 0.3072 - accuracy: 0.83 - ETA: 1:06 - loss: 0.3051 - accuracy: 0.82 - ETA: 1:02 - loss: 0.2969 - accuracy: 0.83 - ETA: 59s - loss: 0.2898 - accuracy: 0.8381 - ETA: 55s - loss: 0.3214 - accuracy: 0.831 - ETA: 51s - loss: 0.3181 - accuracy: 0.834 - ETA: 48s - loss: 0.3191 - accuracy: 0.825 - ETA: 44s - loss: 0.3142 - accuracy: 0.824 - ETA: 40s - loss: 0.3093 - accuracy: 0.826 - ETA: 37s - loss: 0.3000 - accuracy: 0.833 - ETA: 33s - loss: 0.3062 - accuracy: 0.835 - ETA: 29s - loss: 0.3050 - accuracy: 0.834 - ETA: 25s - loss: 0.3000 - accuracy: 0.836 - ETA: 22s - loss: 0.2944 - accuracy: 0.838 - ETA: 18s - loss: 0.2923 - accuracy: 0.840 - ETA: 14s - loss: 0.3005 - accuracy: 0.839 - ETA: 11s - loss: 0.3003 - accuracy: 0.841 - ETA: 7s - loss: 0.2985 - accuracy: 0.842 - ETA: 3s - loss: 0.2984 - accuracy: 0.84 - ETA: 0s - loss: 0.3039 - accuracy: 0.83 - 140s 4s/step - loss: 0.3039 - accuracy: 0.8393 - val_loss: 0.6864 - val_accuracy: 0.7033\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1617 - accuracy: 0.80 - ETA: 1:05 - loss: 0.1340 - accuracy: 0.90 - ETA: 1:26 - loss: 0.1403 - accuracy: 0.90 - ETA: 1:34 - loss: 0.2396 - accuracy: 0.90 - ETA: 1:37 - loss: 0.3495 - accuracy: 0.88 - ETA: 1:38 - loss: 0.3200 - accuracy: 0.90 - ETA: 1:38 - loss: 0.2931 - accuracy: 0.90 - ETA: 1:37 - loss: 0.2846 - accuracy: 0.88 - ETA: 1:35 - loss: 0.2924 - accuracy: 0.87 - ETA: 1:33 - loss: 0.2802 - accuracy: 0.88 - ETA: 1:30 - loss: 0.2694 - accuracy: 0.87 - ETA: 1:28 - loss: 0.2519 - accuracy: 0.88 - ETA: 1:25 - loss: 0.2392 - accuracy: 0.89 - ETA: 1:22 - loss: 0.2366 - accuracy: 0.89 - ETA: 1:19 - loss: 0.2350 - accuracy: 0.88 - ETA: 1:16 - loss: 0.2335 - accuracy: 0.88 - ETA: 1:13 - loss: 0.2437 - accuracy: 0.88 - ETA: 1:09 - loss: 0.2406 - accuracy: 0.88 - ETA: 1:05 - loss: 0.2316 - accuracy: 0.88 - ETA: 1:02 - loss: 0.2376 - accuracy: 0.88 - ETA: 58s - loss: 0.2302 - accuracy: 0.8905 - ETA: 54s - loss: 0.2261 - accuracy: 0.890 - ETA: 51s - loss: 0.2429 - accuracy: 0.887 - ETA: 47s - loss: 0.2439 - accuracy: 0.883 - ETA: 43s - loss: 0.2513 - accuracy: 0.876 - ETA: 40s - loss: 0.2498 - accuracy: 0.876 - ETA: 36s - loss: 0.2647 - accuracy: 0.874 - ETA: 32s - loss: 0.2646 - accuracy: 0.878 - ETA: 29s - loss: 0.2580 - accuracy: 0.882 - ETA: 25s - loss: 0.2545 - accuracy: 0.886 - ETA: 21s - loss: 0.2490 - accuracy: 0.890 - ETA: 18s - loss: 0.2436 - accuracy: 0.893 - ETA: 14s - loss: 0.2420 - accuracy: 0.897 - ETA: 10s - loss: 0.2406 - accuracy: 0.897 - ETA: 7s - loss: 0.2358 - accuracy: 0.900 - ETA: 3s - loss: 0.2316 - accuracy: 0.90 - ETA: 0s - loss: 0.2319 - accuracy: 0.90 - 140s 4s/step - loss: 0.2319 - accuracy: 0.9030 - val_loss: 0.7100 - val_accuracy: 0.6813\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1708 - accuracy: 1.00 - ETA: 1:00 - loss: 0.3494 - accuracy: 0.95 - ETA: 1:16 - loss: 0.2505 - accuracy: 0.96 - ETA: 1:23 - loss: 0.2304 - accuracy: 0.95 - ETA: 1:25 - loss: 0.2545 - accuracy: 0.94 - ETA: 1:26 - loss: 0.2534 - accuracy: 0.93 - ETA: 1:25 - loss: 0.2316 - accuracy: 0.94 - ETA: 1:24 - loss: 0.2237 - accuracy: 0.92 - ETA: 1:22 - loss: 0.2053 - accuracy: 0.93 - ETA: 1:21 - loss: 0.2045 - accuracy: 0.93 - ETA: 1:18 - loss: 0.2030 - accuracy: 0.92 - ETA: 1:16 - loss: 0.2079 - accuracy: 0.92 - ETA: 1:13 - loss: 0.1976 - accuracy: 0.93 - ETA: 1:11 - loss: 0.1968 - accuracy: 0.92 - ETA: 1:08 - loss: 0.1933 - accuracy: 0.93 - ETA: 1:05 - loss: 0.1869 - accuracy: 0.93 - ETA: 1:02 - loss: 0.1815 - accuracy: 0.93 - ETA: 59s - loss: 0.1771 - accuracy: 0.9389 - ETA: 56s - loss: 0.1741 - accuracy: 0.936 - ETA: 53s - loss: 0.1705 - accuracy: 0.940 - ETA: 50s - loss: 0.1692 - accuracy: 0.938 - ETA: 47s - loss: 0.1887 - accuracy: 0.936 - ETA: 44s - loss: 0.1972 - accuracy: 0.921 - ETA: 41s - loss: 0.2002 - accuracy: 0.920 - ETA: 38s - loss: 0.1972 - accuracy: 0.920 - ETA: 35s - loss: 0.1996 - accuracy: 0.915 - ETA: 32s - loss: 0.2011 - accuracy: 0.914 - ETA: 28s - loss: 0.2063 - accuracy: 0.910 - ETA: 25s - loss: 0.2047 - accuracy: 0.913 - ETA: 22s - loss: 0.2161 - accuracy: 0.906 - ETA: 19s - loss: 0.2144 - accuracy: 0.906 - ETA: 16s - loss: 0.2130 - accuracy: 0.906 - ETA: 12s - loss: 0.2102 - accuracy: 0.906 - ETA: 9s - loss: 0.2071 - accuracy: 0.905 - ETA: 6s - loss: 0.2076 - accuracy: 0.90 - ETA: 3s - loss: 0.2062 - accuracy: 0.90 - ETA: 0s - loss: 0.2066 - accuracy: 0.90 - 124s 3s/step - loss: 0.2066 - accuracy: 0.9086 - val_loss: 0.7143 - val_accuracy: 0.6264\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2308 - accuracy: 0.80 - ETA: 58s - loss: 0.1536 - accuracy: 0.900 - ETA: 1:15 - loss: 0.1267 - accuracy: 0.93 - ETA: 1:21 - loss: 0.1269 - accuracy: 0.95 - ETA: 1:24 - loss: 0.1292 - accuracy: 0.92 - ETA: 1:25 - loss: 0.1420 - accuracy: 0.91 - ETA: 1:24 - loss: 0.1321 - accuracy: 0.92 - ETA: 1:23 - loss: 0.1408 - accuracy: 0.91 - ETA: 1:21 - loss: 0.1916 - accuracy: 0.90 - ETA: 1:19 - loss: 0.1904 - accuracy: 0.90 - ETA: 1:17 - loss: 0.1827 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2207 - accuracy: 0.90 - ETA: 1:12 - loss: 0.2256 - accuracy: 0.89 - ETA: 1:09 - loss: 0.2145 - accuracy: 0.90 - ETA: 1:06 - loss: 0.2056 - accuracy: 0.90 - ETA: 1:04 - loss: 0.2441 - accuracy: 0.89 - ETA: 1:01 - loss: 0.2535 - accuracy: 0.88 - ETA: 58s - loss: 0.2460 - accuracy: 0.8944 - ETA: 55s - loss: 0.2369 - accuracy: 0.900 - ETA: 52s - loss: 0.2423 - accuracy: 0.900 - ETA: 49s - loss: 0.2428 - accuracy: 0.904 - ETA: 46s - loss: 0.2500 - accuracy: 0.904 - ETA: 43s - loss: 0.2482 - accuracy: 0.900 - ETA: 40s - loss: 0.2465 - accuracy: 0.900 - ETA: 37s - loss: 0.2424 - accuracy: 0.904 - ETA: 34s - loss: 0.2354 - accuracy: 0.907 - ETA: 31s - loss: 0.2384 - accuracy: 0.907 - ETA: 28s - loss: 0.2388 - accuracy: 0.907 - ETA: 25s - loss: 0.2402 - accuracy: 0.906 - ETA: 22s - loss: 0.2458 - accuracy: 0.906 - ETA: 19s - loss: 0.2461 - accuracy: 0.903 - ETA: 15s - loss: 0.2496 - accuracy: 0.900 - ETA: 12s - loss: 0.2473 - accuracy: 0.903 - ETA: 9s - loss: 0.2418 - accuracy: 0.905 - ETA: 6s - loss: 0.2430 - accuracy: 0.90 - ETA: 3s - loss: 0.2412 - accuracy: 0.90 - ETA: 0s - loss: 0.2415 - accuracy: 0.90 - 123s 3s/step - loss: 0.2415 - accuracy: 0.9030 - val_loss: 0.7996 - val_accuracy: 0.7143\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 1.00 - ETA: 1:01 - loss: 0.0957 - accuracy: 1.00 - ETA: 1:19 - loss: 0.1159 - accuracy: 1.00 - ETA: 1:26 - loss: 0.1140 - accuracy: 1.00 - ETA: 1:29 - loss: 0.1064 - accuracy: 1.00 - ETA: 1:29 - loss: 0.0970 - accuracy: 1.00 - ETA: 1:28 - loss: 0.1373 - accuracy: 0.95 - ETA: 1:26 - loss: 0.1343 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1402 - accuracy: 0.96 - ETA: 1:21 - loss: 0.1308 - accuracy: 0.97 - ETA: 1:19 - loss: 0.1307 - accuracy: 0.96 - ETA: 1:16 - loss: 0.1297 - accuracy: 0.95 - ETA: 1:13 - loss: 0.1396 - accuracy: 0.95 - ETA: 1:11 - loss: 0.1902 - accuracy: 0.94 - ETA: 1:08 - loss: 0.1864 - accuracy: 0.94 - ETA: 1:05 - loss: 0.1783 - accuracy: 0.95 - ETA: 1:02 - loss: 0.1853 - accuracy: 0.93 - ETA: 59s - loss: 0.1782 - accuracy: 0.9389 - ETA: 56s - loss: 0.1784 - accuracy: 0.936 - ETA: 53s - loss: 0.1750 - accuracy: 0.935 - ETA: 50s - loss: 0.1764 - accuracy: 0.928 - ETA: 47s - loss: 0.1745 - accuracy: 0.927 - ETA: 44s - loss: 0.1804 - accuracy: 0.921 - ETA: 40s - loss: 0.1758 - accuracy: 0.925 - ETA: 37s - loss: 0.1735 - accuracy: 0.928 - ETA: 34s - loss: 0.1758 - accuracy: 0.923 - ETA: 31s - loss: 0.1718 - accuracy: 0.925 - ETA: 28s - loss: 0.1841 - accuracy: 0.917 - ETA: 25s - loss: 0.1814 - accuracy: 0.917 - ETA: 22s - loss: 0.1881 - accuracy: 0.913 - ETA: 19s - loss: 0.1853 - accuracy: 0.916 - ETA: 15s - loss: 0.1825 - accuracy: 0.918 - ETA: 12s - loss: 0.1892 - accuracy: 0.921 - ETA: 9s - loss: 0.1862 - accuracy: 0.923 - ETA: 6s - loss: 0.1834 - accuracy: 0.92 - ETA: 3s - loss: 0.1847 - accuracy: 0.92 - ETA: 0s - loss: 0.1851 - accuracy: 0.92 - 123s 3s/step - loss: 0.1851 - accuracy: 0.9252 - val_loss: 0.7139 - val_accuracy: 0.6923\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.6072 - accuracy: 0.90 - ETA: 58s - loss: 0.4342 - accuracy: 0.850 - ETA: 1:15 - loss: 0.3422 - accuracy: 0.86 - ETA: 1:22 - loss: 0.4386 - accuracy: 0.87 - ETA: 1:25 - loss: 0.3709 - accuracy: 0.90 - ETA: 1:25 - loss: 0.3350 - accuracy: 0.91 - ETA: 1:25 - loss: 0.3287 - accuracy: 0.91 - ETA: 1:23 - loss: 0.3002 - accuracy: 0.92 - ETA: 1:22 - loss: 0.2746 - accuracy: 0.93 - ETA: 1:20 - loss: 0.2627 - accuracy: 0.94 - ETA: 1:17 - loss: 0.2468 - accuracy: 0.93 - ETA: 1:15 - loss: 0.2363 - accuracy: 0.92 - ETA: 1:12 - loss: 0.2735 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2974 - accuracy: 0.90 - ETA: 1:07 - loss: 0.2919 - accuracy: 0.90 - ETA: 1:04 - loss: 0.3229 - accuracy: 0.90 - ETA: 1:01 - loss: 0.3190 - accuracy: 0.90 - ETA: 58s - loss: 0.3071 - accuracy: 0.9111 - ETA: 55s - loss: 0.2920 - accuracy: 0.915 - ETA: 52s - loss: 0.2987 - accuracy: 0.905 - ETA: 49s - loss: 0.2926 - accuracy: 0.904 - ETA: 46s - loss: 0.2837 - accuracy: 0.904 - ETA: 43s - loss: 0.2836 - accuracy: 0.904 - ETA: 40s - loss: 0.2746 - accuracy: 0.908 - ETA: 37s - loss: 0.2692 - accuracy: 0.908 - ETA: 34s - loss: 0.2660 - accuracy: 0.911 - ETA: 31s - loss: 0.2620 - accuracy: 0.911 - ETA: 28s - loss: 0.2595 - accuracy: 0.907 - ETA: 25s - loss: 0.2547 - accuracy: 0.906 - ETA: 22s - loss: 0.2516 - accuracy: 0.906 - ETA: 18s - loss: 0.2747 - accuracy: 0.903 - ETA: 15s - loss: 0.2774 - accuracy: 0.900 - ETA: 12s - loss: 0.2741 - accuracy: 0.903 - ETA: 9s - loss: 0.2720 - accuracy: 0.902 - ETA: 6s - loss: 0.2681 - accuracy: 0.90 - ETA: 3s - loss: 0.2647 - accuracy: 0.90 - ETA: 0s - loss: 0.2649 - accuracy: 0.90 - 122s 3s/step - loss: 0.2649 - accuracy: 0.9030 - val_loss: 0.7700 - val_accuracy: 0.6593\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2862 - accuracy: 0.80 - ETA: 59s - loss: 0.2124 - accuracy: 0.850 - ETA: 1:15 - loss: 0.1828 - accuracy: 0.86 - ETA: 1:22 - loss: 0.1657 - accuracy: 0.90 - ETA: 1:24 - loss: 0.1864 - accuracy: 0.88 - ETA: 1:25 - loss: 0.1871 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2223 - accuracy: 0.87 - ETA: 1:23 - loss: 0.2027 - accuracy: 0.87 - ETA: 1:21 - loss: 0.2096 - accuracy: 0.86 - ETA: 1:20 - loss: 0.2305 - accuracy: 0.87 - ETA: 1:19 - loss: 0.2256 - accuracy: 0.87 - ETA: 1:16 - loss: 0.2439 - accuracy: 0.87 - ETA: 1:14 - loss: 0.2309 - accuracy: 0.87 - ETA: 1:11 - loss: 0.2214 - accuracy: 0.87 - ETA: 1:08 - loss: 0.2335 - accuracy: 0.87 - ETA: 1:05 - loss: 0.2477 - accuracy: 0.87 - ETA: 1:02 - loss: 0.2350 - accuracy: 0.88 - ETA: 59s - loss: 0.2294 - accuracy: 0.8833 - ETA: 56s - loss: 0.2186 - accuracy: 0.889 - ETA: 53s - loss: 0.2114 - accuracy: 0.895 - ETA: 50s - loss: 0.2027 - accuracy: 0.900 - ETA: 47s - loss: 0.2005 - accuracy: 0.900 - ETA: 44s - loss: 0.2074 - accuracy: 0.900 - ETA: 41s - loss: 0.2013 - accuracy: 0.904 - ETA: 37s - loss: 0.1988 - accuracy: 0.904 - ETA: 34s - loss: 0.1999 - accuracy: 0.907 - ETA: 31s - loss: 0.1965 - accuracy: 0.911 - ETA: 28s - loss: 0.1993 - accuracy: 0.907 - ETA: 25s - loss: 0.1981 - accuracy: 0.910 - ETA: 22s - loss: 0.1965 - accuracy: 0.913 - ETA: 19s - loss: 0.1938 - accuracy: 0.912 - ETA: 15s - loss: 0.1901 - accuracy: 0.912 - ETA: 12s - loss: 0.1884 - accuracy: 0.915 - ETA: 9s - loss: 0.1902 - accuracy: 0.914 - ETA: 6s - loss: 0.1883 - accuracy: 0.91 - ETA: 3s - loss: 0.1911 - accuracy: 0.91 - ETA: 0s - loss: 0.1915 - accuracy: 0.91 - 122s 3s/step - loss: 0.1915 - accuracy: 0.9169 - val_loss: 0.7980 - val_accuracy: 0.7143\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3700 - accuracy: 0.90 - ETA: 56s - loss: 0.2563 - accuracy: 0.900 - ETA: 1:13 - loss: 0.2264 - accuracy: 0.90 - ETA: 1:20 - loss: 0.1911 - accuracy: 0.90 - ETA: 1:23 - loss: 0.1823 - accuracy: 0.88 - ETA: 1:23 - loss: 0.1764 - accuracy: 0.88 - ETA: 1:23 - loss: 0.1723 - accuracy: 0.90 - ETA: 1:22 - loss: 0.1727 - accuracy: 0.91 - ETA: 1:21 - loss: 0.1730 - accuracy: 0.90 - ETA: 1:19 - loss: 0.1645 - accuracy: 0.91 - ETA: 1:17 - loss: 0.1837 - accuracy: 0.90 - ETA: 1:15 - loss: 0.1822 - accuracy: 0.90 - ETA: 1:13 - loss: 0.1872 - accuracy: 0.90 - ETA: 1:10 - loss: 0.1829 - accuracy: 0.90 - ETA: 1:07 - loss: 0.1838 - accuracy: 0.90 - ETA: 1:04 - loss: 0.1800 - accuracy: 0.90 - ETA: 1:01 - loss: 0.1755 - accuracy: 0.90 - ETA: 58s - loss: 0.1746 - accuracy: 0.9111 - ETA: 55s - loss: 0.1722 - accuracy: 0.910 - ETA: 52s - loss: 0.1829 - accuracy: 0.910 - ETA: 49s - loss: 0.1833 - accuracy: 0.914 - ETA: 46s - loss: 0.1815 - accuracy: 0.918 - ETA: 43s - loss: 0.1810 - accuracy: 0.917 - ETA: 40s - loss: 0.1810 - accuracy: 0.912 - ETA: 37s - loss: 0.1845 - accuracy: 0.904 - ETA: 34s - loss: 0.1813 - accuracy: 0.907 - ETA: 31s - loss: 0.1767 - accuracy: 0.911 - ETA: 28s - loss: 0.1751 - accuracy: 0.914 - ETA: 25s - loss: 0.1729 - accuracy: 0.917 - ETA: 22s - loss: 0.1684 - accuracy: 0.920 - ETA: 18s - loss: 0.1668 - accuracy: 0.922 - ETA: 15s - loss: 0.1722 - accuracy: 0.921 - ETA: 12s - loss: 0.1726 - accuracy: 0.924 - ETA: 9s - loss: 0.1716 - accuracy: 0.923 - ETA: 6s - loss: 0.1754 - accuracy: 0.91 - ETA: 3s - loss: 0.1762 - accuracy: 0.91 - ETA: 0s - loss: 0.1767 - accuracy: 0.91 - 121s 3s/step - loss: 0.1767 - accuracy: 0.9141 - val_loss: 0.7859 - val_accuracy: 0.6264\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4311 - accuracy: 0.50 - ETA: 56s - loss: 0.2823 - accuracy: 0.750 - ETA: 1:12 - loss: 0.2509 - accuracy: 0.80 - ETA: 1:19 - loss: 0.3183 - accuracy: 0.75 - ETA: 1:22 - loss: 0.3438 - accuracy: 0.76 - ETA: 1:23 - loss: 0.3014 - accuracy: 0.80 - ETA: 1:23 - loss: 0.2701 - accuracy: 0.82 - ETA: 1:22 - loss: 0.2715 - accuracy: 0.83 - ETA: 1:20 - loss: 0.2467 - accuracy: 0.85 - ETA: 1:18 - loss: 0.2458 - accuracy: 0.86 - ETA: 1:16 - loss: 0.2365 - accuracy: 0.87 - ETA: 1:14 - loss: 0.2215 - accuracy: 0.88 - ETA: 1:12 - loss: 0.2240 - accuracy: 0.88 - ETA: 1:10 - loss: 0.2185 - accuracy: 0.87 - ETA: 1:08 - loss: 0.2160 - accuracy: 0.87 - ETA: 1:05 - loss: 0.2090 - accuracy: 0.88 - ETA: 1:02 - loss: 0.2106 - accuracy: 0.87 - ETA: 59s - loss: 0.2026 - accuracy: 0.8778 - ETA: 56s - loss: 0.1979 - accuracy: 0.884 - ETA: 53s - loss: 0.1950 - accuracy: 0.890 - ETA: 50s - loss: 0.1937 - accuracy: 0.890 - ETA: 47s - loss: 0.1909 - accuracy: 0.890 - ETA: 44s - loss: 0.1849 - accuracy: 0.895 - ETA: 41s - loss: 0.1871 - accuracy: 0.895 - ETA: 38s - loss: 0.1834 - accuracy: 0.900 - ETA: 35s - loss: 0.1808 - accuracy: 0.903 - ETA: 32s - loss: 0.1772 - accuracy: 0.907 - ETA: 28s - loss: 0.1828 - accuracy: 0.907 - ETA: 25s - loss: 0.1800 - accuracy: 0.906 - ETA: 22s - loss: 0.1794 - accuracy: 0.906 - ETA: 19s - loss: 0.1798 - accuracy: 0.903 - ETA: 16s - loss: 0.1816 - accuracy: 0.903 - ETA: 13s - loss: 0.1775 - accuracy: 0.906 - ETA: 9s - loss: 0.1742 - accuracy: 0.908 - ETA: 6s - loss: 0.1803 - accuracy: 0.90 - ETA: 3s - loss: 0.1765 - accuracy: 0.90 - ETA: 0s - loss: 0.1769 - accuracy: 0.90 - 128s 3s/step - loss: 0.1769 - accuracy: 0.9058 - val_loss: 0.7701 - val_accuracy: 0.6703\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2382 - accuracy: 1.00 - ETA: 56s - loss: 0.2707 - accuracy: 1.000 - ETA: 1:12 - loss: 0.2402 - accuracy: 0.93 - ETA: 1:20 - loss: 0.2667 - accuracy: 0.87 - ETA: 1:22 - loss: 0.2912 - accuracy: 0.88 - ETA: 1:23 - loss: 0.3245 - accuracy: 0.88 - ETA: 1:23 - loss: 0.2901 - accuracy: 0.88 - ETA: 1:22 - loss: 0.2666 - accuracy: 0.90 - ETA: 1:20 - loss: 0.2464 - accuracy: 0.91 - ETA: 1:18 - loss: 0.2246 - accuracy: 0.92 - ETA: 1:16 - loss: 0.2682 - accuracy: 0.91 - ETA: 1:14 - loss: 0.2473 - accuracy: 0.92 - ETA: 1:11 - loss: 0.2408 - accuracy: 0.92 - ETA: 1:09 - loss: 0.2312 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2420 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2326 - accuracy: 0.93 - ETA: 1:01 - loss: 0.2343 - accuracy: 0.91 - ETA: 58s - loss: 0.2270 - accuracy: 0.9222 - ETA: 55s - loss: 0.2486 - accuracy: 0.921 - ETA: 52s - loss: 0.2420 - accuracy: 0.925 - ETA: 49s - loss: 0.2452 - accuracy: 0.923 - ETA: 46s - loss: 0.2537 - accuracy: 0.922 - ETA: 43s - loss: 0.2462 - accuracy: 0.921 - ETA: 40s - loss: 0.2473 - accuracy: 0.916 - ETA: 37s - loss: 0.2519 - accuracy: 0.912 - ETA: 34s - loss: 0.2469 - accuracy: 0.911 - ETA: 31s - loss: 0.2413 - accuracy: 0.914 - ETA: 28s - loss: 0.2758 - accuracy: 0.910 - ETA: 25s - loss: 0.2711 - accuracy: 0.910 - ETA: 21s - loss: 0.2668 - accuracy: 0.910 - ETA: 18s - loss: 0.2671 - accuracy: 0.906 - ETA: 15s - loss: 0.2623 - accuracy: 0.906 - ETA: 12s - loss: 0.2594 - accuracy: 0.906 - ETA: 9s - loss: 0.2553 - accuracy: 0.905 - ETA: 6s - loss: 0.2531 - accuracy: 0.90 - ETA: 3s - loss: 0.2505 - accuracy: 0.90 - ETA: 0s - loss: 0.2507 - accuracy: 0.90 - 121s 3s/step - loss: 0.2507 - accuracy: 0.9030 - val_loss: 0.7527 - val_accuracy: 0.6484\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2948 - accuracy: 0.80 - ETA: 56s - loss: 0.2683 - accuracy: 0.850 - ETA: 1:13 - loss: 0.1883 - accuracy: 0.90 - ETA: 1:20 - loss: 0.1725 - accuracy: 0.90 - ETA: 1:22 - loss: 0.1632 - accuracy: 0.90 - ETA: 1:23 - loss: 0.1519 - accuracy: 0.91 - ETA: 1:23 - loss: 0.1635 - accuracy: 0.91 - ETA: 1:21 - loss: 0.1516 - accuracy: 0.92 - ETA: 1:20 - loss: 0.1769 - accuracy: 0.91 - ETA: 1:18 - loss: 0.1674 - accuracy: 0.91 - ETA: 1:16 - loss: 0.1626 - accuracy: 0.91 - ETA: 1:14 - loss: 0.1583 - accuracy: 0.92 - ETA: 1:11 - loss: 0.1537 - accuracy: 0.93 - ETA: 1:08 - loss: 0.1483 - accuracy: 0.93 - ETA: 1:06 - loss: 0.1462 - accuracy: 0.93 - ETA: 1:03 - loss: 0.1524 - accuracy: 0.92 - ETA: 1:00 - loss: 0.1475 - accuracy: 0.92 - ETA: 57s - loss: 0.1444 - accuracy: 0.9333 - ETA: 55s - loss: 0.1388 - accuracy: 0.936 - ETA: 52s - loss: 0.1429 - accuracy: 0.935 - ETA: 49s - loss: 0.1610 - accuracy: 0.928 - ETA: 46s - loss: 0.1569 - accuracy: 0.931 - ETA: 43s - loss: 0.1597 - accuracy: 0.934 - ETA: 40s - loss: 0.1593 - accuracy: 0.933 - ETA: 37s - loss: 0.1597 - accuracy: 0.932 - ETA: 34s - loss: 0.1720 - accuracy: 0.926 - ETA: 31s - loss: 0.1726 - accuracy: 0.925 - ETA: 28s - loss: 0.1692 - accuracy: 0.928 - ETA: 24s - loss: 0.1746 - accuracy: 0.920 - ETA: 21s - loss: 0.1789 - accuracy: 0.916 - ETA: 18s - loss: 0.1906 - accuracy: 0.916 - ETA: 15s - loss: 0.1877 - accuracy: 0.918 - ETA: 12s - loss: 0.1934 - accuracy: 0.909 - ETA: 9s - loss: 0.1902 - accuracy: 0.908 - ETA: 6s - loss: 0.1893 - accuracy: 0.90 - ETA: 3s - loss: 0.1982 - accuracy: 0.90 - ETA: 0s - loss: 0.1984 - accuracy: 0.90 - 120s 3s/step - loss: 0.1984 - accuracy: 0.9058 - val_loss: 0.7537 - val_accuracy: 0.7253\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 1.00 - ETA: 56s - loss: 0.0825 - accuracy: 1.000 - ETA: 1:14 - loss: 0.0935 - accuracy: 0.96 - ETA: 1:20 - loss: 0.1222 - accuracy: 0.95 - ETA: 1:22 - loss: 0.1203 - accuracy: 0.96 - ETA: 1:23 - loss: 0.1086 - accuracy: 0.96 - ETA: 1:23 - loss: 0.1284 - accuracy: 0.95 - ETA: 1:23 - loss: 0.1459 - accuracy: 0.95 - ETA: 1:21 - loss: 0.1359 - accuracy: 0.95 - ETA: 1:19 - loss: 0.1439 - accuracy: 0.95 - ETA: 1:17 - loss: 0.1672 - accuracy: 0.92 - ETA: 1:15 - loss: 0.1624 - accuracy: 0.92 - ETA: 1:12 - loss: 0.1618 - accuracy: 0.92 - ETA: 1:09 - loss: 0.1970 - accuracy: 0.92 - ETA: 1:07 - loss: 0.1936 - accuracy: 0.92 - ETA: 1:04 - loss: 0.1963 - accuracy: 0.91 - ETA: 1:01 - loss: 0.1947 - accuracy: 0.92 - ETA: 58s - loss: 0.1900 - accuracy: 0.9222 - ETA: 55s - loss: 0.1836 - accuracy: 0.926 - ETA: 52s - loss: 0.1870 - accuracy: 0.925 - ETA: 49s - loss: 0.1795 - accuracy: 0.928 - ETA: 46s - loss: 0.1883 - accuracy: 0.927 - ETA: 43s - loss: 0.1822 - accuracy: 0.930 - ETA: 40s - loss: 0.1951 - accuracy: 0.925 - ETA: 37s - loss: 0.1982 - accuracy: 0.920 - ETA: 34s - loss: 0.1970 - accuracy: 0.919 - ETA: 31s - loss: 0.1955 - accuracy: 0.914 - ETA: 28s - loss: 0.1946 - accuracy: 0.914 - ETA: 25s - loss: 0.2039 - accuracy: 0.913 - ETA: 22s - loss: 0.2028 - accuracy: 0.913 - ETA: 18s - loss: 0.2331 - accuracy: 0.912 - ETA: 15s - loss: 0.2310 - accuracy: 0.915 - ETA: 12s - loss: 0.2251 - accuracy: 0.918 - ETA: 9s - loss: 0.2203 - accuracy: 0.920 - ETA: 6s - loss: 0.2217 - accuracy: 0.92 - ETA: 3s - loss: 0.2194 - accuracy: 0.92 - ETA: 0s - loss: 0.2197 - accuracy: 0.92 - 122s 3s/step - loss: 0.2197 - accuracy: 0.9252 - val_loss: 0.7448 - val_accuracy: 0.6813\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0730 - accuracy: 1.00 - ETA: 59s - loss: 0.0876 - accuracy: 1.000 - ETA: 1:16 - loss: 0.1134 - accuracy: 1.00 - ETA: 1:22 - loss: 0.2926 - accuracy: 0.95 - ETA: 1:25 - loss: 0.3831 - accuracy: 0.94 - ETA: 1:25 - loss: 0.3594 - accuracy: 0.93 - ETA: 1:25 - loss: 0.3455 - accuracy: 0.92 - ETA: 1:24 - loss: 0.3278 - accuracy: 0.91 - ETA: 1:23 - loss: 0.3052 - accuracy: 0.91 - ETA: 1:21 - loss: 0.3059 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2874 - accuracy: 0.90 - ETA: 1:16 - loss: 0.2765 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2694 - accuracy: 0.90 - ETA: 1:11 - loss: 0.2607 - accuracy: 0.90 - ETA: 1:08 - loss: 0.2550 - accuracy: 0.90 - ETA: 1:05 - loss: 0.2442 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2372 - accuracy: 0.91 - ETA: 59s - loss: 0.2312 - accuracy: 0.9111 - ETA: 56s - loss: 0.2266 - accuracy: 0.910 - ETA: 53s - loss: 0.2208 - accuracy: 0.910 - ETA: 50s - loss: 0.2181 - accuracy: 0.909 - ETA: 47s - loss: 0.2124 - accuracy: 0.909 - ETA: 44s - loss: 0.2106 - accuracy: 0.908 - ETA: 41s - loss: 0.2048 - accuracy: 0.912 - ETA: 38s - loss: 0.2112 - accuracy: 0.912 - ETA: 35s - loss: 0.2094 - accuracy: 0.915 - ETA: 31s - loss: 0.2166 - accuracy: 0.914 - ETA: 28s - loss: 0.2230 - accuracy: 0.910 - ETA: 25s - loss: 0.2272 - accuracy: 0.906 - ETA: 22s - loss: 0.2243 - accuracy: 0.910 - ETA: 19s - loss: 0.2273 - accuracy: 0.909 - ETA: 16s - loss: 0.2240 - accuracy: 0.909 - ETA: 12s - loss: 0.2178 - accuracy: 0.912 - ETA: 9s - loss: 0.2160 - accuracy: 0.911 - ETA: 6s - loss: 0.2151 - accuracy: 0.91 - ETA: 3s - loss: 0.2131 - accuracy: 0.91 - ETA: 0s - loss: 0.2133 - accuracy: 0.91 - 123s 3s/step - loss: 0.2133 - accuracy: 0.9169 - val_loss: 0.7925 - val_accuracy: 0.6813\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.70 - ETA: 1:02 - loss: 0.1674 - accuracy: 0.85 - ETA: 1:16 - loss: 0.2106 - accuracy: 0.83 - ETA: 1:22 - loss: 0.1766 - accuracy: 0.87 - ETA: 1:24 - loss: 0.1775 - accuracy: 0.88 - ETA: 1:24 - loss: 0.3015 - accuracy: 0.88 - ETA: 1:24 - loss: 0.2692 - accuracy: 0.90 - ETA: 1:22 - loss: 0.2633 - accuracy: 0.90 - ETA: 1:21 - loss: 0.2541 - accuracy: 0.90 - ETA: 1:19 - loss: 0.2417 - accuracy: 0.90 - ETA: 1:17 - loss: 0.2247 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2132 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2018 - accuracy: 0.92 - ETA: 1:09 - loss: 0.2003 - accuracy: 0.92 - ETA: 1:07 - loss: 0.1917 - accuracy: 0.93 - ETA: 1:05 - loss: 0.1822 - accuracy: 0.93 - ETA: 1:02 - loss: 0.1768 - accuracy: 0.93 - ETA: 1:00 - loss: 0.1798 - accuracy: 0.93 - ETA: 57s - loss: 0.1742 - accuracy: 0.9368 - ETA: 54s - loss: 0.1757 - accuracy: 0.935 - ETA: 51s - loss: 0.1687 - accuracy: 0.938 - ETA: 49s - loss: 0.1708 - accuracy: 0.927 - ETA: 46s - loss: 0.1651 - accuracy: 0.930 - ETA: 43s - loss: 0.1683 - accuracy: 0.929 - ETA: 39s - loss: 0.1688 - accuracy: 0.924 - ETA: 36s - loss: 0.1713 - accuracy: 0.923 - ETA: 33s - loss: 0.1762 - accuracy: 0.922 - ETA: 29s - loss: 0.1775 - accuracy: 0.925 - ETA: 26s - loss: 0.1788 - accuracy: 0.920 - ETA: 23s - loss: 0.1764 - accuracy: 0.923 - ETA: 19s - loss: 0.1744 - accuracy: 0.922 - ETA: 16s - loss: 0.1725 - accuracy: 0.925 - ETA: 13s - loss: 0.1725 - accuracy: 0.924 - ETA: 9s - loss: 0.1720 - accuracy: 0.923 - ETA: 6s - loss: 0.1703 - accuracy: 0.92 - ETA: 3s - loss: 0.1755 - accuracy: 0.91 - ETA: 0s - loss: 0.1759 - accuracy: 0.91 - 126s 3s/step - loss: 0.1759 - accuracy: 0.9197 - val_loss: 0.8321 - val_accuracy: 0.6923\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.90 - ETA: 56s - loss: 0.1990 - accuracy: 0.850 - ETA: 1:13 - loss: 0.2074 - accuracy: 0.86 - ETA: 1:20 - loss: 0.1884 - accuracy: 0.87 - ETA: 1:22 - loss: 0.1848 - accuracy: 0.88 - ETA: 1:23 - loss: 0.1826 - accuracy: 0.88 - ETA: 1:23 - loss: 0.1904 - accuracy: 0.87 - ETA: 1:22 - loss: 0.1766 - accuracy: 0.88 - ETA: 1:20 - loss: 0.1633 - accuracy: 0.90 - ETA: 1:18 - loss: 0.1576 - accuracy: 0.91 - ETA: 1:16 - loss: 0.1538 - accuracy: 0.90 - ETA: 1:14 - loss: 0.1498 - accuracy: 0.90 - ETA: 1:12 - loss: 0.1533 - accuracy: 0.91 - ETA: 1:09 - loss: 0.1527 - accuracy: 0.92 - ETA: 1:07 - loss: 0.1508 - accuracy: 0.92 - ETA: 1:04 - loss: 0.1458 - accuracy: 0.91 - ETA: 1:01 - loss: 0.1461 - accuracy: 0.92 - ETA: 59s - loss: 0.1570 - accuracy: 0.9167 - ETA: 56s - loss: 0.1547 - accuracy: 0.921 - ETA: 53s - loss: 0.1515 - accuracy: 0.925 - ETA: 50s - loss: 0.1463 - accuracy: 0.928 - ETA: 47s - loss: 0.1451 - accuracy: 0.927 - ETA: 44s - loss: 0.1486 - accuracy: 0.917 - ETA: 41s - loss: 0.1523 - accuracy: 0.912 - ETA: 38s - loss: 0.1522 - accuracy: 0.916 - ETA: 35s - loss: 0.1515 - accuracy: 0.915 - ETA: 32s - loss: 0.1553 - accuracy: 0.914 - ETA: 29s - loss: 0.1574 - accuracy: 0.914 - ETA: 26s - loss: 0.1563 - accuracy: 0.917 - ETA: 22s - loss: 0.1647 - accuracy: 0.916 - ETA: 19s - loss: 0.1625 - accuracy: 0.919 - ETA: 16s - loss: 0.1603 - accuracy: 0.921 - ETA: 13s - loss: 0.1596 - accuracy: 0.921 - ETA: 9s - loss: 0.1559 - accuracy: 0.923 - ETA: 6s - loss: 0.1566 - accuracy: 0.92 - ETA: 3s - loss: 0.1563 - accuracy: 0.92 - ETA: 0s - loss: 0.1568 - accuracy: 0.92 - 125s 3s/step - loss: 0.1568 - accuracy: 0.9224 - val_loss: 0.7879 - val_accuracy: 0.7143\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.1252 - accuracy: 1.00 - ETA: 57s - loss: 0.1163 - accuracy: 1.000 - ETA: 1:13 - loss: 0.1466 - accuracy: 0.96 - ETA: 1:20 - loss: 0.1718 - accuracy: 0.95 - ETA: 1:23 - loss: 0.1853 - accuracy: 0.90 - ETA: 1:23 - loss: 0.1617 - accuracy: 0.91 - ETA: 1:23 - loss: 0.1935 - accuracy: 0.90 - ETA: 1:22 - loss: 0.1805 - accuracy: 0.90 - ETA: 1:20 - loss: 0.1744 - accuracy: 0.91 - ETA: 1:19 - loss: 0.1702 - accuracy: 0.91 - ETA: 1:17 - loss: 0.1722 - accuracy: 0.90 - ETA: 1:14 - loss: 0.1646 - accuracy: 0.90 - ETA: 1:12 - loss: 0.1662 - accuracy: 0.91 - ETA: 1:11 - loss: 0.1709 - accuracy: 0.91 - ETA: 1:08 - loss: 0.1659 - accuracy: 0.91 - ETA: 1:06 - loss: 0.1621 - accuracy: 0.91 - ETA: 1:03 - loss: 0.1634 - accuracy: 0.91 - ETA: 1:00 - loss: 0.1591 - accuracy: 0.92 - ETA: 58s - loss: 0.1566 - accuracy: 0.9211 - ETA: 55s - loss: 0.1611 - accuracy: 0.925 - ETA: 52s - loss: 0.1657 - accuracy: 0.923 - ETA: 49s - loss: 0.1624 - accuracy: 0.927 - ETA: 45s - loss: 0.1653 - accuracy: 0.921 - ETA: 42s - loss: 0.1740 - accuracy: 0.912 - ETA: 39s - loss: 0.2029 - accuracy: 0.908 - ETA: 36s - loss: 0.1986 - accuracy: 0.907 - ETA: 32s - loss: 0.1945 - accuracy: 0.911 - ETA: 29s - loss: 0.2168 - accuracy: 0.910 - ETA: 26s - loss: 0.2170 - accuracy: 0.910 - ETA: 22s - loss: 0.2142 - accuracy: 0.910 - ETA: 19s - loss: 0.2308 - accuracy: 0.906 - ETA: 16s - loss: 0.2408 - accuracy: 0.906 - ETA: 13s - loss: 0.2351 - accuracy: 0.909 - ETA: 9s - loss: 0.2340 - accuracy: 0.911 - ETA: 6s - loss: 0.2332 - accuracy: 0.90 - ETA: 3s - loss: 0.2349 - accuracy: 0.90 - ETA: 0s - loss: 0.2351 - accuracy: 0.90 - 125s 3s/step - loss: 0.2351 - accuracy: 0.9058 - val_loss: 0.7626 - val_accuracy: 0.6813\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3070 - accuracy: 1.00 - ETA: 56s - loss: 0.2475 - accuracy: 0.900 - ETA: 1:12 - loss: 0.2587 - accuracy: 0.83 - ETA: 1:19 - loss: 0.2304 - accuracy: 0.85 - ETA: 1:22 - loss: 0.2012 - accuracy: 0.86 - ETA: 1:23 - loss: 0.1749 - accuracy: 0.88 - ETA: 1:23 - loss: 0.1521 - accuracy: 0.90 - ETA: 1:22 - loss: 0.1391 - accuracy: 0.91 - ETA: 1:20 - loss: 0.1425 - accuracy: 0.92 - ETA: 1:18 - loss: 0.1415 - accuracy: 0.92 - ETA: 1:16 - loss: 0.1398 - accuracy: 0.92 - ETA: 1:14 - loss: 0.1377 - accuracy: 0.92 - ETA: 1:11 - loss: 0.1307 - accuracy: 0.93 - ETA: 1:09 - loss: 0.1396 - accuracy: 0.92 - ETA: 1:06 - loss: 0.1403 - accuracy: 0.92 - ETA: 1:03 - loss: 0.1455 - accuracy: 0.92 - ETA: 1:01 - loss: 0.1528 - accuracy: 0.92 - ETA: 58s - loss: 0.1547 - accuracy: 0.9278 - ETA: 55s - loss: 0.1490 - accuracy: 0.931 - ETA: 52s - loss: 0.1473 - accuracy: 0.930 - ETA: 49s - loss: 0.1562 - accuracy: 0.928 - ETA: 46s - loss: 0.1598 - accuracy: 0.922 - ETA: 43s - loss: 0.1706 - accuracy: 0.913 - ETA: 40s - loss: 0.1659 - accuracy: 0.916 - ETA: 37s - loss: 0.1746 - accuracy: 0.912 - ETA: 35s - loss: 0.1841 - accuracy: 0.911 - ETA: 32s - loss: 0.1832 - accuracy: 0.911 - ETA: 28s - loss: 0.1807 - accuracy: 0.914 - ETA: 25s - loss: 0.2034 - accuracy: 0.913 - ETA: 22s - loss: 0.2000 - accuracy: 0.916 - ETA: 19s - loss: 0.1971 - accuracy: 0.916 - ETA: 16s - loss: 0.1955 - accuracy: 0.915 - ETA: 13s - loss: 0.1906 - accuracy: 0.918 - ETA: 9s - loss: 0.1910 - accuracy: 0.914 - ETA: 6s - loss: 0.1908 - accuracy: 0.91 - ETA: 3s - loss: 0.1909 - accuracy: 0.91 - ETA: 0s - loss: 0.1911 - accuracy: 0.91 - 125s 3s/step - loss: 0.1911 - accuracy: 0.9141 - val_loss: 0.7492 - val_accuracy: 0.7033\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 1.00 - ETA: 57s - loss: 0.1049 - accuracy: 0.950 - ETA: 1:14 - loss: 0.6200 - accuracy: 0.90 - ETA: 1:21 - loss: 0.4922 - accuracy: 0.92 - ETA: 1:23 - loss: 0.4187 - accuracy: 0.94 - ETA: 1:24 - loss: 0.3894 - accuracy: 0.95 - ETA: 1:24 - loss: 0.3601 - accuracy: 0.94 - ETA: 1:22 - loss: 0.3439 - accuracy: 0.93 - ETA: 1:21 - loss: 0.3367 - accuracy: 0.93 - ETA: 1:19 - loss: 0.3386 - accuracy: 0.93 - ETA: 1:16 - loss: 0.3125 - accuracy: 0.93 - ETA: 1:14 - loss: 0.3039 - accuracy: 0.94 - ETA: 1:11 - loss: 0.3055 - accuracy: 0.93 - ETA: 1:09 - loss: 0.2903 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2749 - accuracy: 0.93 - ETA: 1:03 - loss: 0.2725 - accuracy: 0.93 - ETA: 1:01 - loss: 0.2657 - accuracy: 0.93 - ETA: 58s - loss: 0.2588 - accuracy: 0.9278 - ETA: 55s - loss: 0.2486 - accuracy: 0.931 - ETA: 52s - loss: 0.2492 - accuracy: 0.930 - ETA: 49s - loss: 0.2656 - accuracy: 0.923 - ETA: 46s - loss: 0.2581 - accuracy: 0.927 - ETA: 43s - loss: 0.2498 - accuracy: 0.930 - ETA: 40s - loss: 0.2433 - accuracy: 0.933 - ETA: 37s - loss: 0.2353 - accuracy: 0.936 - ETA: 34s - loss: 0.2317 - accuracy: 0.934 - ETA: 31s - loss: 0.2306 - accuracy: 0.933 - ETA: 28s - loss: 0.2317 - accuracy: 0.928 - ETA: 25s - loss: 0.2308 - accuracy: 0.931 - ETA: 22s - loss: 0.2277 - accuracy: 0.926 - ETA: 18s - loss: 0.2228 - accuracy: 0.929 - ETA: 15s - loss: 0.2211 - accuracy: 0.931 - ETA: 12s - loss: 0.2193 - accuracy: 0.930 - ETA: 9s - loss: 0.2238 - accuracy: 0.926 - ETA: 6s - loss: 0.2246 - accuracy: 0.92 - ETA: 3s - loss: 0.2226 - accuracy: 0.92 - ETA: 0s - loss: 0.2227 - accuracy: 0.92 - 122s 3s/step - loss: 0.2227 - accuracy: 0.9224 - val_loss: 0.8057 - val_accuracy: 0.6923\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1985 - accuracy: 0.80 - ETA: 57s - loss: 0.1873 - accuracy: 0.800 - ETA: 1:14 - loss: 0.1467 - accuracy: 0.86 - ETA: 1:23 - loss: 0.1987 - accuracy: 0.87 - ETA: 1:27 - loss: 0.1910 - accuracy: 0.88 - ETA: 1:28 - loss: 0.2192 - accuracy: 0.85 - ETA: 1:28 - loss: 0.2057 - accuracy: 0.87 - ETA: 1:27 - loss: 0.1904 - accuracy: 0.88 - ETA: 1:26 - loss: 0.1757 - accuracy: 0.90 - ETA: 1:24 - loss: 0.1651 - accuracy: 0.91 - ETA: 1:22 - loss: 0.1545 - accuracy: 0.91 - ETA: 1:21 - loss: 0.1557 - accuracy: 0.91 - ETA: 1:19 - loss: 0.1502 - accuracy: 0.92 - ETA: 1:16 - loss: 0.1630 - accuracy: 0.91 - ETA: 1:12 - loss: 0.1930 - accuracy: 0.90 - ETA: 1:09 - loss: 0.1890 - accuracy: 0.90 - ETA: 1:06 - loss: 0.1911 - accuracy: 0.90 - ETA: 1:02 - loss: 0.1920 - accuracy: 0.91 - ETA: 59s - loss: 0.1959 - accuracy: 0.9105 - ETA: 56s - loss: 0.1899 - accuracy: 0.910 - ETA: 52s - loss: 0.1820 - accuracy: 0.914 - ETA: 49s - loss: 0.1764 - accuracy: 0.918 - ETA: 46s - loss: 0.1769 - accuracy: 0.917 - ETA: 42s - loss: 0.1742 - accuracy: 0.920 - ETA: 39s - loss: 0.1701 - accuracy: 0.920 - ETA: 36s - loss: 0.1662 - accuracy: 0.923 - ETA: 33s - loss: 0.1815 - accuracy: 0.918 - ETA: 29s - loss: 0.1812 - accuracy: 0.917 - ETA: 26s - loss: 0.1771 - accuracy: 0.920 - ETA: 23s - loss: 0.1758 - accuracy: 0.920 - ETA: 19s - loss: 0.1793 - accuracy: 0.912 - ETA: 16s - loss: 0.1744 - accuracy: 0.915 - ETA: 13s - loss: 0.1755 - accuracy: 0.915 - ETA: 9s - loss: 0.1835 - accuracy: 0.908 - ETA: 6s - loss: 0.1901 - accuracy: 0.90 - ETA: 3s - loss: 0.1865 - accuracy: 0.91 - ETA: 0s - loss: 0.1867 - accuracy: 0.91 - 126s 3s/step - loss: 0.1867 - accuracy: 0.9114 - val_loss: 0.7772 - val_accuracy: 0.6374\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - ETA: 57s - loss: 0.0660 - accuracy: 0.950 - ETA: 1:15 - loss: 0.0760 - accuracy: 0.96 - ETA: 1:22 - loss: 0.0695 - accuracy: 0.97 - ETA: 1:25 - loss: 0.1077 - accuracy: 0.98 - ETA: 1:26 - loss: 0.2258 - accuracy: 0.95 - ETA: 1:25 - loss: 0.2069 - accuracy: 0.94 - ETA: 1:24 - loss: 0.2056 - accuracy: 0.92 - ETA: 1:22 - loss: 0.1967 - accuracy: 0.93 - ETA: 1:21 - loss: 0.1894 - accuracy: 0.94 - ETA: 1:19 - loss: 0.1763 - accuracy: 0.94 - ETA: 1:17 - loss: 0.1849 - accuracy: 0.93 - ETA: 1:15 - loss: 0.1783 - accuracy: 0.93 - ETA: 1:12 - loss: 0.1767 - accuracy: 0.94 - ETA: 1:09 - loss: 0.1746 - accuracy: 0.94 - ETA: 1:06 - loss: 0.1711 - accuracy: 0.95 - ETA: 1:03 - loss: 0.1797 - accuracy: 0.94 - ETA: 1:00 - loss: 0.2029 - accuracy: 0.93 - ETA: 57s - loss: 0.2013 - accuracy: 0.9421 - ETA: 54s - loss: 0.2035 - accuracy: 0.935 - ETA: 51s - loss: 0.2025 - accuracy: 0.938 - ETA: 47s - loss: 0.1990 - accuracy: 0.936 - ETA: 44s - loss: 0.1960 - accuracy: 0.934 - ETA: 41s - loss: 0.1901 - accuracy: 0.937 - ETA: 38s - loss: 0.1909 - accuracy: 0.936 - ETA: 35s - loss: 0.1891 - accuracy: 0.934 - ETA: 32s - loss: 0.1855 - accuracy: 0.933 - ETA: 28s - loss: 0.1867 - accuracy: 0.932 - ETA: 25s - loss: 0.1885 - accuracy: 0.927 - ETA: 22s - loss: 0.1868 - accuracy: 0.930 - ETA: 19s - loss: 0.1878 - accuracy: 0.922 - ETA: 16s - loss: 0.1882 - accuracy: 0.921 - ETA: 12s - loss: 0.1881 - accuracy: 0.924 - ETA: 9s - loss: 0.1833 - accuracy: 0.926 - ETA: 6s - loss: 0.1804 - accuracy: 0.92 - ETA: 3s - loss: 0.1773 - accuracy: 0.93 - ETA: 0s - loss: 0.1776 - accuracy: 0.93 - 124s 3s/step - loss: 0.1776 - accuracy: 0.9307 - val_loss: 0.7415 - val_accuracy: 0.6813\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4138 - accuracy: 0.90 - ETA: 57s - loss: 0.5817 - accuracy: 0.900 - ETA: 1:14 - loss: 0.4319 - accuracy: 0.93 - ETA: 1:21 - loss: 0.3716 - accuracy: 0.92 - ETA: 1:24 - loss: 0.3117 - accuracy: 0.94 - ETA: 1:24 - loss: 0.2978 - accuracy: 0.95 - ETA: 1:24 - loss: 0.2764 - accuracy: 0.94 - ETA: 1:23 - loss: 0.2584 - accuracy: 0.93 - ETA: 1:22 - loss: 0.2466 - accuracy: 0.94 - ETA: 1:20 - loss: 0.2288 - accuracy: 0.95 - ETA: 1:18 - loss: 0.2276 - accuracy: 0.93 - ETA: 1:15 - loss: 0.2148 - accuracy: 0.94 - ETA: 1:13 - loss: 0.2195 - accuracy: 0.93 - ETA: 1:10 - loss: 0.2248 - accuracy: 0.93 - ETA: 1:07 - loss: 0.2153 - accuracy: 0.94 - ETA: 1:04 - loss: 0.2422 - accuracy: 0.93 - ETA: 1:02 - loss: 0.2332 - accuracy: 0.93 - ETA: 59s - loss: 0.2297 - accuracy: 0.9278 - ETA: 57s - loss: 0.2198 - accuracy: 0.931 - ETA: 54s - loss: 0.2174 - accuracy: 0.930 - ETA: 51s - loss: 0.2157 - accuracy: 0.933 - ETA: 48s - loss: 0.2075 - accuracy: 0.936 - ETA: 45s - loss: 0.2085 - accuracy: 0.934 - ETA: 42s - loss: 0.2056 - accuracy: 0.933 - ETA: 39s - loss: 0.1995 - accuracy: 0.936 - ETA: 36s - loss: 0.2038 - accuracy: 0.934 - ETA: 33s - loss: 0.2003 - accuracy: 0.933 - ETA: 29s - loss: 0.1983 - accuracy: 0.932 - ETA: 26s - loss: 0.1993 - accuracy: 0.931 - ETA: 23s - loss: 0.1970 - accuracy: 0.933 - ETA: 20s - loss: 0.1918 - accuracy: 0.935 - ETA: 16s - loss: 0.1985 - accuracy: 0.934 - ETA: 13s - loss: 0.1942 - accuracy: 0.936 - ETA: 10s - loss: 0.1900 - accuracy: 0.938 - ETA: 6s - loss: 0.1887 - accuracy: 0.937 - ETA: 3s - loss: 0.1877 - accuracy: 0.93 - ETA: 0s - loss: 0.1879 - accuracy: 0.93 - 129s 3s/step - loss: 0.1879 - accuracy: 0.9391 - val_loss: 0.7727 - val_accuracy: 0.7033\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 1.00 - ETA: 1:01 - loss: 0.2165 - accuracy: 0.90 - ETA: 1:20 - loss: 0.1658 - accuracy: 0.93 - ETA: 1:28 - loss: 0.1644 - accuracy: 0.92 - ETA: 1:31 - loss: 0.2125 - accuracy: 0.90 - ETA: 1:32 - loss: 0.1850 - accuracy: 0.91 - ETA: 1:32 - loss: 0.1673 - accuracy: 0.92 - ETA: 1:30 - loss: 0.1658 - accuracy: 0.93 - ETA: 1:29 - loss: 0.1605 - accuracy: 0.92 - ETA: 1:26 - loss: 0.1529 - accuracy: 0.92 - ETA: 1:24 - loss: 0.1432 - accuracy: 0.92 - ETA: 1:22 - loss: 0.1395 - accuracy: 0.93 - ETA: 1:19 - loss: 0.1404 - accuracy: 0.93 - ETA: 1:16 - loss: 0.1339 - accuracy: 0.93 - ETA: 1:13 - loss: 0.1301 - accuracy: 0.94 - ETA: 1:10 - loss: 0.1348 - accuracy: 0.92 - ETA: 1:07 - loss: 0.1420 - accuracy: 0.92 - ETA: 1:04 - loss: 0.1594 - accuracy: 0.92 - ETA: 1:01 - loss: 0.1728 - accuracy: 0.91 - ETA: 58s - loss: 0.1671 - accuracy: 0.9200 - ETA: 54s - loss: 0.1647 - accuracy: 0.919 - ETA: 51s - loss: 0.1638 - accuracy: 0.922 - ETA: 48s - loss: 0.1673 - accuracy: 0.921 - ETA: 44s - loss: 0.1833 - accuracy: 0.920 - ETA: 41s - loss: 0.1801 - accuracy: 0.924 - ETA: 38s - loss: 0.1793 - accuracy: 0.923 - ETA: 34s - loss: 0.1754 - accuracy: 0.922 - ETA: 31s - loss: 0.1753 - accuracy: 0.925 - ETA: 27s - loss: 0.1701 - accuracy: 0.927 - ETA: 24s - loss: 0.1670 - accuracy: 0.930 - ETA: 20s - loss: 0.1643 - accuracy: 0.932 - ETA: 17s - loss: 0.1700 - accuracy: 0.934 - ETA: 14s - loss: 0.1719 - accuracy: 0.933 - ETA: 10s - loss: 0.1772 - accuracy: 0.932 - ETA: 7s - loss: 0.1736 - accuracy: 0.934 - ETA: 3s - loss: 0.1712 - accuracy: 0.93 - ETA: 0s - loss: 0.1714 - accuracy: 0.93 - 134s 4s/step - loss: 0.1714 - accuracy: 0.9363 - val_loss: 0.8163 - val_accuracy: 0.7253\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 1.00 - ETA: 1:02 - loss: 0.0628 - accuracy: 1.00 - ETA: 1:17 - loss: 0.2346 - accuracy: 0.93 - ETA: 1:23 - loss: 0.2373 - accuracy: 0.87 - ETA: 1:25 - loss: 0.2173 - accuracy: 0.90 - ETA: 1:25 - loss: 0.2012 - accuracy: 0.91 - ETA: 1:25 - loss: 0.1812 - accuracy: 0.92 - ETA: 1:23 - loss: 0.1623 - accuracy: 0.93 - ETA: 1:22 - loss: 0.1537 - accuracy: 0.94 - ETA: 1:20 - loss: 0.1535 - accuracy: 0.95 - ETA: 1:18 - loss: 0.1554 - accuracy: 0.95 - ETA: 1:15 - loss: 0.1499 - accuracy: 0.95 - ETA: 1:13 - loss: 0.1686 - accuracy: 0.95 - ETA: 1:10 - loss: 0.1627 - accuracy: 0.95 - ETA: 1:07 - loss: 0.1578 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1611 - accuracy: 0.96 - ETA: 1:02 - loss: 0.1578 - accuracy: 0.95 - ETA: 59s - loss: 0.1687 - accuracy: 0.9556 - ETA: 56s - loss: 0.1701 - accuracy: 0.947 - ETA: 53s - loss: 0.1711 - accuracy: 0.950 - ETA: 50s - loss: 0.1799 - accuracy: 0.938 - ETA: 47s - loss: 0.1743 - accuracy: 0.940 - ETA: 44s - loss: 0.1758 - accuracy: 0.943 - ETA: 41s - loss: 0.1730 - accuracy: 0.941 - ETA: 38s - loss: 0.1688 - accuracy: 0.944 - ETA: 35s - loss: 0.1677 - accuracy: 0.942 - ETA: 32s - loss: 0.1727 - accuracy: 0.940 - ETA: 29s - loss: 0.1686 - accuracy: 0.942 - ETA: 25s - loss: 0.1680 - accuracy: 0.944 - ETA: 22s - loss: 0.1876 - accuracy: 0.943 - ETA: 19s - loss: 0.1864 - accuracy: 0.941 - ETA: 16s - loss: 0.1849 - accuracy: 0.940 - ETA: 13s - loss: 0.1810 - accuracy: 0.942 - ETA: 9s - loss: 0.1798 - accuracy: 0.941 - ETA: 6s - loss: 0.1763 - accuracy: 0.94 - ETA: 3s - loss: 0.1728 - accuracy: 0.94 - ETA: 0s - loss: 0.1797 - accuracy: 0.94 - 125s 3s/step - loss: 0.1797 - accuracy: 0.9418 - val_loss: 0.7775 - val_accuracy: 0.7253\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 1.00 - ETA: 56s - loss: 0.1713 - accuracy: 0.900 - ETA: 1:13 - loss: 0.3675 - accuracy: 0.80 - ETA: 1:20 - loss: 0.3661 - accuracy: 0.82 - ETA: 1:23 - loss: 0.3337 - accuracy: 0.80 - ETA: 1:24 - loss: 0.2902 - accuracy: 0.83 - ETA: 1:24 - loss: 0.3572 - accuracy: 0.82 - ETA: 1:23 - loss: 0.3160 - accuracy: 0.85 - ETA: 1:21 - loss: 0.2849 - accuracy: 0.86 - ETA: 1:19 - loss: 0.2690 - accuracy: 0.87 - ETA: 1:17 - loss: 0.2461 - accuracy: 0.88 - ETA: 1:15 - loss: 0.3224 - accuracy: 0.87 - ETA: 1:12 - loss: 0.3091 - accuracy: 0.87 - ETA: 1:10 - loss: 0.3112 - accuracy: 0.87 - ETA: 1:07 - loss: 0.3068 - accuracy: 0.87 - ETA: 1:04 - loss: 0.2953 - accuracy: 0.87 - ETA: 1:01 - loss: 0.2794 - accuracy: 0.88 - ETA: 58s - loss: 0.2716 - accuracy: 0.8833 - ETA: 56s - loss: 0.2711 - accuracy: 0.884 - ETA: 53s - loss: 0.2881 - accuracy: 0.875 - ETA: 50s - loss: 0.2797 - accuracy: 0.881 - ETA: 47s - loss: 0.2715 - accuracy: 0.881 - ETA: 43s - loss: 0.2679 - accuracy: 0.882 - ETA: 40s - loss: 0.2589 - accuracy: 0.887 - ETA: 37s - loss: 0.2505 - accuracy: 0.892 - ETA: 34s - loss: 0.2430 - accuracy: 0.896 - ETA: 31s - loss: 0.2396 - accuracy: 0.900 - ETA: 28s - loss: 0.2331 - accuracy: 0.903 - ETA: 25s - loss: 0.2298 - accuracy: 0.903 - ETA: 22s - loss: 0.2243 - accuracy: 0.906 - ETA: 19s - loss: 0.2280 - accuracy: 0.906 - ETA: 15s - loss: 0.2271 - accuracy: 0.903 - ETA: 12s - loss: 0.2254 - accuracy: 0.903 - ETA: 9s - loss: 0.2207 - accuracy: 0.905 - ETA: 6s - loss: 0.2251 - accuracy: 0.90 - ETA: 3s - loss: 0.2231 - accuracy: 0.90 - ETA: 0s - loss: 0.2232 - accuracy: 0.90 - 124s 3s/step - loss: 0.2232 - accuracy: 0.9058 - val_loss: 0.8032 - val_accuracy: 0.6813\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4110 - accuracy: 0.90 - ETA: 1:00 - loss: 0.2541 - accuracy: 0.95 - ETA: 1:17 - loss: 0.2061 - accuracy: 0.93 - ETA: 1:25 - loss: 0.1691 - accuracy: 0.95 - ETA: 1:28 - loss: 0.1907 - accuracy: 0.94 - ETA: 1:29 - loss: 0.1733 - accuracy: 0.95 - ETA: 1:28 - loss: 0.1995 - accuracy: 0.94 - ETA: 1:27 - loss: 0.1918 - accuracy: 0.93 - ETA: 1:26 - loss: 0.1863 - accuracy: 0.92 - ETA: 1:24 - loss: 0.1921 - accuracy: 0.90 - ETA: 1:21 - loss: 0.1847 - accuracy: 0.90 - ETA: 1:18 - loss: 0.1720 - accuracy: 0.90 - ETA: 1:15 - loss: 0.1673 - accuracy: 0.90 - ETA: 1:12 - loss: 0.1581 - accuracy: 0.91 - ETA: 1:09 - loss: 0.1536 - accuracy: 0.91 - ETA: 1:06 - loss: 0.1483 - accuracy: 0.91 - ETA: 1:03 - loss: 0.1528 - accuracy: 0.91 - ETA: 1:00 - loss: 0.1574 - accuracy: 0.92 - ETA: 57s - loss: 0.1693 - accuracy: 0.9158 - ETA: 54s - loss: 0.1650 - accuracy: 0.920 - ETA: 51s - loss: 0.1629 - accuracy: 0.919 - ETA: 48s - loss: 0.1615 - accuracy: 0.918 - ETA: 45s - loss: 0.1616 - accuracy: 0.917 - ETA: 41s - loss: 0.1585 - accuracy: 0.920 - ETA: 38s - loss: 0.1841 - accuracy: 0.920 - ETA: 35s - loss: 0.1795 - accuracy: 0.919 - ETA: 32s - loss: 0.1775 - accuracy: 0.922 - ETA: 29s - loss: 0.1754 - accuracy: 0.925 - ETA: 25s - loss: 0.1743 - accuracy: 0.927 - ETA: 22s - loss: 0.1710 - accuracy: 0.930 - ETA: 19s - loss: 0.1726 - accuracy: 0.929 - ETA: 16s - loss: 0.1686 - accuracy: 0.931 - ETA: 13s - loss: 0.1800 - accuracy: 0.927 - ETA: 9s - loss: 0.1816 - accuracy: 0.929 - ETA: 6s - loss: 0.1866 - accuracy: 0.92 - ETA: 3s - loss: 0.1863 - accuracy: 0.93 - ETA: 0s - loss: 0.1864 - accuracy: 0.93 - 125s 3s/step - loss: 0.1864 - accuracy: 0.9307 - val_loss: 0.7968 - val_accuracy: 0.7253\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2676 - accuracy: 0.70 - ETA: 58s - loss: 0.2597 - accuracy: 0.750 - ETA: 1:15 - loss: 0.2510 - accuracy: 0.76 - ETA: 1:22 - loss: 0.2126 - accuracy: 0.80 - ETA: 1:24 - loss: 0.1758 - accuracy: 0.84 - ETA: 1:26 - loss: 0.1766 - accuracy: 0.86 - ETA: 1:25 - loss: 0.1947 - accuracy: 0.87 - ETA: 1:24 - loss: 0.1921 - accuracy: 0.87 - ETA: 1:22 - loss: 0.1740 - accuracy: 0.88 - ETA: 1:21 - loss: 0.1696 - accuracy: 0.88 - ETA: 1:21 - loss: 0.3008 - accuracy: 0.88 - ETA: 1:18 - loss: 0.2917 - accuracy: 0.89 - ETA: 1:16 - loss: 0.2749 - accuracy: 0.90 - ETA: 1:13 - loss: 0.2585 - accuracy: 0.90 - ETA: 1:10 - loss: 0.2467 - accuracy: 0.90 - ETA: 1:08 - loss: 0.2460 - accuracy: 0.90 - ETA: 1:05 - loss: 0.2445 - accuracy: 0.90 - ETA: 1:02 - loss: 0.2535 - accuracy: 0.89 - ETA: 59s - loss: 0.2415 - accuracy: 0.9000 - ETA: 56s - loss: 0.2304 - accuracy: 0.905 - ETA: 52s - loss: 0.2238 - accuracy: 0.909 - ETA: 49s - loss: 0.2249 - accuracy: 0.909 - ETA: 46s - loss: 0.2183 - accuracy: 0.908 - ETA: 42s - loss: 0.2130 - accuracy: 0.908 - ETA: 39s - loss: 0.2069 - accuracy: 0.912 - ETA: 36s - loss: 0.2019 - accuracy: 0.915 - ETA: 33s - loss: 0.1956 - accuracy: 0.918 - ETA: 29s - loss: 0.1926 - accuracy: 0.917 - ETA: 26s - loss: 0.1951 - accuracy: 0.913 - ETA: 23s - loss: 0.1962 - accuracy: 0.916 - ETA: 19s - loss: 0.2200 - accuracy: 0.912 - ETA: 16s - loss: 0.2159 - accuracy: 0.915 - ETA: 13s - loss: 0.2134 - accuracy: 0.912 - ETA: 9s - loss: 0.2086 - accuracy: 0.914 - ETA: 6s - loss: 0.2053 - accuracy: 0.91 - ETA: 3s - loss: 0.2025 - accuracy: 0.91 - ETA: 0s - loss: 0.2027 - accuracy: 0.91 - 127s 3s/step - loss: 0.2027 - accuracy: 0.9197 - val_loss: 0.8429 - val_accuracy: 0.6703\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 1.00 - ETA: 58s - loss: 0.1008 - accuracy: 0.900 - ETA: 1:15 - loss: 0.0896 - accuracy: 0.93 - ETA: 1:22 - loss: 0.0982 - accuracy: 0.92 - ETA: 1:24 - loss: 0.0978 - accuracy: 0.92 - ETA: 1:25 - loss: 0.0839 - accuracy: 0.93 - ETA: 1:25 - loss: 0.0972 - accuracy: 0.91 - ETA: 1:23 - loss: 0.1170 - accuracy: 0.91 - ETA: 1:22 - loss: 0.1225 - accuracy: 0.91 - ETA: 1:21 - loss: 0.1148 - accuracy: 0.92 - ETA: 1:19 - loss: 0.1179 - accuracy: 0.90 - ETA: 1:16 - loss: 0.1124 - accuracy: 0.91 - ETA: 1:14 - loss: 0.1067 - accuracy: 0.92 - ETA: 1:11 - loss: 0.1028 - accuracy: 0.92 - ETA: 1:08 - loss: 0.1019 - accuracy: 0.92 - ETA: 1:05 - loss: 0.1061 - accuracy: 0.92 - ETA: 1:02 - loss: 0.1020 - accuracy: 0.92 - ETA: 59s - loss: 0.1095 - accuracy: 0.9278 - ETA: 56s - loss: 0.1074 - accuracy: 0.926 - ETA: 53s - loss: 0.1126 - accuracy: 0.930 - ETA: 50s - loss: 0.1112 - accuracy: 0.933 - ETA: 47s - loss: 0.1225 - accuracy: 0.927 - ETA: 44s - loss: 0.1241 - accuracy: 0.921 - ETA: 41s - loss: 0.1263 - accuracy: 0.920 - ETA: 38s - loss: 0.1332 - accuracy: 0.916 - ETA: 35s - loss: 0.1307 - accuracy: 0.919 - ETA: 32s - loss: 0.1299 - accuracy: 0.918 - ETA: 28s - loss: 0.1457 - accuracy: 0.917 - ETA: 25s - loss: 0.1429 - accuracy: 0.920 - ETA: 22s - loss: 0.1399 - accuracy: 0.923 - ETA: 19s - loss: 0.1384 - accuracy: 0.925 - ETA: 16s - loss: 0.1363 - accuracy: 0.928 - ETA: 12s - loss: 0.1377 - accuracy: 0.930 - ETA: 9s - loss: 0.1457 - accuracy: 0.926 - ETA: 6s - loss: 0.1447 - accuracy: 0.92 - ETA: 3s - loss: 0.1421 - accuracy: 0.93 - ETA: 0s - loss: 0.1425 - accuracy: 0.93 - 124s 3s/step - loss: 0.1425 - accuracy: 0.9307 - val_loss: 0.7517 - val_accuracy: 0.6923\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 1.00 - ETA: 57s - loss: 0.1234 - accuracy: 0.950 - ETA: 1:13 - loss: 0.1628 - accuracy: 0.90 - ETA: 1:20 - loss: 0.1794 - accuracy: 0.90 - ETA: 1:23 - loss: 0.1724 - accuracy: 0.92 - ETA: 1:23 - loss: 0.1526 - accuracy: 0.93 - ETA: 1:23 - loss: 0.1477 - accuracy: 0.92 - ETA: 1:22 - loss: 0.1518 - accuracy: 0.92 - ETA: 1:20 - loss: 0.1480 - accuracy: 0.92 - ETA: 1:19 - loss: 0.1361 - accuracy: 0.93 - ETA: 1:17 - loss: 0.1311 - accuracy: 0.93 - ETA: 1:14 - loss: 0.1216 - accuracy: 0.94 - ETA: 1:13 - loss: 0.1232 - accuracy: 0.94 - ETA: 1:11 - loss: 0.1383 - accuracy: 0.94 - ETA: 1:08 - loss: 0.1420 - accuracy: 0.94 - ETA: 1:06 - loss: 0.1442 - accuracy: 0.93 - ETA: 1:03 - loss: 0.1409 - accuracy: 0.93 - ETA: 1:00 - loss: 0.1446 - accuracy: 0.93 - ETA: 58s - loss: 0.1385 - accuracy: 0.9421 - ETA: 55s - loss: 0.1391 - accuracy: 0.935 - ETA: 52s - loss: 0.1359 - accuracy: 0.938 - ETA: 50s - loss: 0.1319 - accuracy: 0.940 - ETA: 47s - loss: 0.1271 - accuracy: 0.943 - ETA: 43s - loss: 0.1267 - accuracy: 0.941 - ETA: 40s - loss: 0.1255 - accuracy: 0.940 - ETA: 36s - loss: 0.1253 - accuracy: 0.938 - ETA: 33s - loss: 0.1209 - accuracy: 0.940 - ETA: 30s - loss: 0.1201 - accuracy: 0.939 - ETA: 26s - loss: 0.1285 - accuracy: 0.937 - ETA: 23s - loss: 0.1278 - accuracy: 0.936 - ETA: 20s - loss: 0.1284 - accuracy: 0.935 - ETA: 16s - loss: 0.1315 - accuracy: 0.934 - ETA: 13s - loss: 0.1284 - accuracy: 0.936 - ETA: 10s - loss: 0.1274 - accuracy: 0.938 - ETA: 6s - loss: 0.1251 - accuracy: 0.940 - ETA: 3s - loss: 0.1233 - accuracy: 0.94 - ETA: 0s - loss: 0.1238 - accuracy: 0.94 - 128s 3s/step - loss: 0.1238 - accuracy: 0.9418 - val_loss: 0.7542 - val_accuracy: 0.7143\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 1.00 - ETA: 59s - loss: 0.1749 - accuracy: 0.950 - ETA: 1:14 - loss: 0.1296 - accuracy: 0.96 - ETA: 1:21 - loss: 0.1416 - accuracy: 0.97 - ETA: 1:23 - loss: 0.1319 - accuracy: 0.96 - ETA: 1:24 - loss: 0.2151 - accuracy: 0.93 - ETA: 1:23 - loss: 0.2042 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2547 - accuracy: 0.91 - ETA: 1:21 - loss: 0.2365 - accuracy: 0.92 - ETA: 1:19 - loss: 0.2383 - accuracy: 0.92 - ETA: 1:17 - loss: 0.2359 - accuracy: 0.91 - ETA: 1:14 - loss: 0.2383 - accuracy: 0.92 - ETA: 1:12 - loss: 0.2287 - accuracy: 0.92 - ETA: 1:10 - loss: 0.2256 - accuracy: 0.92 - ETA: 1:07 - loss: 0.2163 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2061 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2050 - accuracy: 0.91 - ETA: 58s - loss: 0.1957 - accuracy: 0.9222 - ETA: 56s - loss: 0.1880 - accuracy: 0.926 - ETA: 53s - loss: 0.1804 - accuracy: 0.930 - ETA: 50s - loss: 0.1767 - accuracy: 0.928 - ETA: 47s - loss: 0.1760 - accuracy: 0.927 - ETA: 44s - loss: 0.1865 - accuracy: 0.926 - ETA: 41s - loss: 0.2184 - accuracy: 0.916 - ETA: 37s - loss: 0.2121 - accuracy: 0.920 - ETA: 34s - loss: 0.2157 - accuracy: 0.915 - ETA: 31s - loss: 0.2149 - accuracy: 0.911 - ETA: 28s - loss: 0.2191 - accuracy: 0.907 - ETA: 25s - loss: 0.2180 - accuracy: 0.906 - ETA: 22s - loss: 0.2183 - accuracy: 0.903 - ETA: 19s - loss: 0.2132 - accuracy: 0.906 - ETA: 15s - loss: 0.2087 - accuracy: 0.909 - ETA: 12s - loss: 0.2032 - accuracy: 0.912 - ETA: 9s - loss: 0.2003 - accuracy: 0.914 - ETA: 6s - loss: 0.2104 - accuracy: 0.91 - ETA: 3s - loss: 0.2077 - accuracy: 0.91 - ETA: 0s - loss: 0.2078 - accuracy: 0.91 - 123s 3s/step - loss: 0.2078 - accuracy: 0.9114 - val_loss: 0.7800 - val_accuracy: 0.7033\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.90 - ETA: 57s - loss: 0.6629 - accuracy: 0.850 - ETA: 1:14 - loss: 0.4656 - accuracy: 0.90 - ETA: 1:21 - loss: 0.4642 - accuracy: 0.90 - ETA: 1:24 - loss: 0.4186 - accuracy: 0.90 - ETA: 1:25 - loss: 0.3678 - accuracy: 0.90 - ETA: 1:24 - loss: 0.3328 - accuracy: 0.90 - ETA: 1:23 - loss: 0.3468 - accuracy: 0.90 - ETA: 1:22 - loss: 0.3505 - accuracy: 0.88 - ETA: 1:20 - loss: 0.3801 - accuracy: 0.89 - ETA: 1:18 - loss: 0.3533 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3286 - accuracy: 0.90 - ETA: 1:13 - loss: 0.3165 - accuracy: 0.90 - ETA: 1:10 - loss: 0.2970 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2838 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2690 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2662 - accuracy: 0.91 - ETA: 59s - loss: 0.2581 - accuracy: 0.9222 - ETA: 56s - loss: 0.2465 - accuracy: 0.926 - ETA: 53s - loss: 0.2491 - accuracy: 0.925 - ETA: 50s - loss: 0.2622 - accuracy: 0.919 - ETA: 47s - loss: 0.2751 - accuracy: 0.904 - ETA: 44s - loss: 0.2765 - accuracy: 0.900 - ETA: 41s - loss: 0.2696 - accuracy: 0.904 - ETA: 38s - loss: 0.2690 - accuracy: 0.904 - ETA: 34s - loss: 0.2649 - accuracy: 0.903 - ETA: 31s - loss: 0.2623 - accuracy: 0.900 - ETA: 28s - loss: 0.2554 - accuracy: 0.903 - ETA: 25s - loss: 0.2830 - accuracy: 0.903 - ETA: 22s - loss: 0.2769 - accuracy: 0.906 - ETA: 19s - loss: 0.2742 - accuracy: 0.906 - ETA: 15s - loss: 0.2678 - accuracy: 0.909 - ETA: 12s - loss: 0.2633 - accuracy: 0.912 - ETA: 9s - loss: 0.2636 - accuracy: 0.908 - ETA: 6s - loss: 0.2603 - accuracy: 0.90 - ETA: 3s - loss: 0.2567 - accuracy: 0.90 - ETA: 0s - loss: 0.2568 - accuracy: 0.90 - 123s 3s/step - loss: 0.2568 - accuracy: 0.9086 - val_loss: 0.7718 - val_accuracy: 0.7033\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2992 - accuracy: 0.70 - ETA: 57s - loss: 0.1953 - accuracy: 0.800 - ETA: 1:14 - loss: 0.1558 - accuracy: 0.83 - ETA: 1:21 - loss: 0.1478 - accuracy: 0.87 - ETA: 1:24 - loss: 0.1467 - accuracy: 0.90 - ETA: 1:25 - loss: 0.1616 - accuracy: 0.88 - ETA: 1:25 - loss: 0.1682 - accuracy: 0.88 - ETA: 1:24 - loss: 0.1842 - accuracy: 0.88 - ETA: 1:22 - loss: 0.1725 - accuracy: 0.90 - ETA: 1:20 - loss: 0.1735 - accuracy: 0.89 - ETA: 1:18 - loss: 0.1678 - accuracy: 0.89 - ETA: 1:16 - loss: 0.1763 - accuracy: 0.89 - ETA: 1:13 - loss: 0.1775 - accuracy: 0.90 - ETA: 1:10 - loss: 0.1719 - accuracy: 0.90 - ETA: 1:08 - loss: 0.1663 - accuracy: 0.91 - ETA: 1:05 - loss: 0.1615 - accuracy: 0.91 - ETA: 1:02 - loss: 0.1717 - accuracy: 0.91 - ETA: 59s - loss: 0.1693 - accuracy: 0.9167 - ETA: 56s - loss: 0.1629 - accuracy: 0.921 - ETA: 53s - loss: 0.1591 - accuracy: 0.925 - ETA: 50s - loss: 0.1902 - accuracy: 0.919 - ETA: 47s - loss: 0.1876 - accuracy: 0.918 - ETA: 44s - loss: 0.1815 - accuracy: 0.921 - ETA: 41s - loss: 0.1785 - accuracy: 0.920 - ETA: 38s - loss: 0.1723 - accuracy: 0.924 - ETA: 35s - loss: 0.1694 - accuracy: 0.923 - ETA: 32s - loss: 0.1738 - accuracy: 0.922 - ETA: 28s - loss: 0.1716 - accuracy: 0.921 - ETA: 25s - loss: 0.1670 - accuracy: 0.924 - ETA: 22s - loss: 0.1625 - accuracy: 0.926 - ETA: 19s - loss: 0.1598 - accuracy: 0.925 - ETA: 16s - loss: 0.1560 - accuracy: 0.928 - ETA: 12s - loss: 0.1608 - accuracy: 0.924 - ETA: 9s - loss: 0.1622 - accuracy: 0.920 - ETA: 6s - loss: 0.1627 - accuracy: 0.92 - ETA: 3s - loss: 0.1590 - accuracy: 0.92 - ETA: 0s - loss: 0.1660 - accuracy: 0.91 - 124s 3s/step - loss: 0.1660 - accuracy: 0.9197 - val_loss: 0.7404 - val_accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "rede=model.fit(X_train, y_train, epochs=epochs, class_weight= {0:weights[0], 1:weights[1]}, validation_data=(X_valid, y_valid), batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e29e88cb70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "#plt.title(\"Curva de Aprendizado\")\n",
    "plt.plot(rede.history[\"loss\"])#, label=\"loss\")\n",
    "#plt.plot(rede.history[\"val_loss\"], label=\"val_loss\")\n",
    "#plt.plot( np.argmin(rede.history[\"val_loss\"]), np.min(rede.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"√âpocas\")\n",
    "plt.ylabel('Fun√ß√£o de Perda')\n",
    "plt.legend();\n",
    "\n",
    "#Plot Accuracy vs Epoch\n",
    "plt.figure(figsize=(6, 4))\n",
    "accuracy = rede.history['accuracy']\n",
    "#val_accuracy =rede.history['val_accuracy']\n",
    "\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'r')#, label='Acur√°cia de Treinamento')\n",
    "#plt.plot(epochs, val_accuracy, 'b', label='Acur√°cia de Valida√ß√£o')\n",
    "#plt.title('Acur√°cia de Treinamento e Valida√ß√£o')\n",
    "plt.xlabel('√âpocas')\n",
    "plt.ylabel('Acur√°cia')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC Teste (calc):71.42857142857143%\n",
      "Sensibilidade: 82.6086956521739%\n",
      "Especificidade: 36.36363636363637%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = model.predict(X_valid)\n",
    "y_pred = np.round(Y_pred)\n",
    "cmat=confusion_matrix(y_valid,y_pred,labels=[0,1])\n",
    "cm_df = pd.DataFrame(cmat)                      \n",
    "sns.heatmap(cm_df, annot=True,cmap='Blues',fmt=\"d\")\n",
    "plt.title('Teste')\n",
    "print('ACC Teste (calc):'+str(np.sum(np.diag(cmat))*100/np.sum(cmat))+'%')\n",
    "print('Sensibilidade: ' + str(cm_df.iloc[1][1]/(cm_df.iloc[0][1]+cm_df.iloc[1][1])*100)+'%')\n",
    "print('Especificidade: ' + str(cm_df.iloc[0][0]/(cm_df.iloc[1][0]+cm_df.iloc[0][0])*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
